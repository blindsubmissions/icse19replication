/*
 * This file was automatically generated by EvoSuite
 * Fri Aug 24 12:30:24 GMT 2018
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.File;
import java.net.URI;
import java.util.ArrayList;
import java.util.LinkedHashMap;
import java.util.Properties;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.Random;
import org.evosuite.runtime.System;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.mock.java.net.MockURI;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.evosuite.runtime.util.SystemInUtil;
import org.junit.runner.RunWith;
import weka.attributeSelection.CorrelationAttributeEval;
import weka.attributeSelection.PrincipalComponents;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.functions.SMO;
import weka.classifiers.functions.supportVector.PrecomputedKernelMatrixKernel;
import weka.classifiers.meta.CVParameterSelection;
import weka.classifiers.misc.InputMappedClassifier;
import weka.classifiers.misc.SerializedClassifier;
import weka.core.Attribute;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.ProtectedProperties;
import weka.core.SparseInstance;
import weka.core.Stopwords;
import weka.core.TestInstances;
import weka.core.neighboursearch.balltrees.BallNode;
import weka.core.stemmers.NullStemmer;
import weka.core.stemmers.SnowballStemmer;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.NGramTokenizer;
import weka.core.tokenizers.Tokenizer;
import weka.core.tokenizers.WordTokenizer;
import weka.filters.supervised.attribute.Discretize;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=2.0794415416798357
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseStopList(true);
      String[] stringArray0 = new String[0];
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, stringArray0);
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.getLowercaseTokens();
      boolean boolean0 = false;
      SparseInstance sparseInstance0 = null;
      try {
        sparseInstance0 = new SparseInstance((-3607));
        fail("Expecting exception: NegativeArraySizeException");
      
      } catch(NegativeArraySizeException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.SparseInstance", e);
      }
  }

  /**
  //Test case number: 1
  /*Coverage entropy=1.0986122886681096
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      File file0 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      naiveBayesMultinomialText0.setStopwords(file0);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      
      naiveBayesMultinomialText0.setMinWordFrequency(0.0);
      assertEquals(0.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 2
  /*Coverage entropy=2.0794415416798357
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "Co0qA:CS=M^";
      stringArray0[1] = "bx{&2j~3}isIG:3";
      stringArray0[2] = "\t";
      stringArray0[3] = "Gy-p";
      stringArray0[4] = "AttributeTest";
      stringArray0[5] = "-class-index <num>";
      stringArray0[6] = "4~w#:BN]V/uv?a";
      NaiveBayesMultinomialText.main(stringArray0);
      String string0 = naiveBayesMultinomialText0.toString();
      assertEquals("NaiveBayesMultinomialText: No model built yet.\n", string0);
      
      String string1 = naiveBayesMultinomialText0.getRevision();
      assertEquals("9122", string1);
      
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      String string2 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals("Use word frequencies rather than binary bag of words representation", string2);
      
      naiveBayesMultinomialText0.setUseWordFrequencies(false);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      
      naiveBayesMultinomialText0.pruneDictionary();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 3
  /*Coverage entropy=1.7917594692280547
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      WordTokenizer wordTokenizer0 = (WordTokenizer)naiveBayesMultinomialText0.m_tokenizer;
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.useStopListTipText();
      NullStemmer nullStemmer0 = (NullStemmer)naiveBayesMultinomialText0.m_stemmer;
      naiveBayesMultinomialText0.setStemmer(nullStemmer0);
      assertTrue(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 4
  /*Coverage entropy=2.5649493574615376
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setTokenizer((Tokenizer) null);
      naiveBayesMultinomialText0.getUseWordFrequencies();
      double double0 = naiveBayesMultinomialText0.getNorm();
      assertEquals(1.0, double0, 0.01);
      
      String[] stringArray0 = new String[8];
      stringArray0[0] = "";
      stringArray0[1] = "";
      stringArray0[2] = "'t~Z)'Z,51";
      naiveBayesMultinomialText0.setDebug(false);
      stringArray0[3] = "c8 ]";
      stringArray0[4] = "$Z<c04y";
      stringArray0[5] = ";DTFy{qpl{l49_";
      stringArray0[6] = "_pm[aP";
      stringArray0[7] = ")JFH4D6)@g/LC}J/";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      String string0 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertEquals("If true, ignores all words that are on the stoplist.", string0);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
  }

  /**
  //Test case number: 5
  /*Coverage entropy=3.178053830347946
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.LNormTipText();
      Stopwords stopwords0 = naiveBayesMultinomialText0.m_stopwords;
      naiveBayesMultinomialText0.m_stopwords = null;
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.setMinWordFrequency(1.0E10);
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      File file0 = serializedClassifier0.getModelFile();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.m_lnorm = 1.0E10;
      naiveBayesMultinomialText0.getTokenizer();
      boolean boolean0 = false;
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.stemmerTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.getLowercaseTokens();
      naiveBayesMultinomialText0.globalInfo();
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      Discretize discretize0 = new Discretize();
      // Undeclared exception!
      try { 
        discretize0.output();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // No output instance format defined
         //
         verifyException("weka.filters.Filter", e);
      }
  }

  /**
  //Test case number: 6
  /*Coverage entropy=3.332204510175204
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.listOptions();
      double[] doubleArray0 = new double[0];
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      SMO sMO0 = new SMO();
      AbstractClassifier.makeCopies(sMO0, 1);
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      naiveBayesMultinomialText0.setOptions((String[]) null);
      naiveBayesMultinomialText0.m_useStopList = true;
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.setMinWordFrequency(101.20714981493929);
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.getMinWordFrequency();
      naiveBayesMultinomialText0.setPeriodicPruning(0);
      AbstractClassifier.makeCopies(naiveBayesMultinomialText0, 10000);
  }

  /**
  //Test case number: 7
  /*Coverage entropy=3.332204510175204
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setUseStopList(false);
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      nGramTokenizer0.nextElement();
      Tokenizer.runTokenizer(nGramTokenizer0, stringArray0);
      naiveBayesMultinomialText0.setTokenizer(nGramTokenizer0);
      LinkedHashMap<String, NaiveBayesMultinomialText.Count> linkedHashMap0 = new LinkedHashMap<String, NaiveBayesMultinomialText.Count>();
      naiveBayesMultinomialText0.m_inputVector = linkedHashMap0;
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getUseStopList();
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.setPeriodicPruning(0);
      naiveBayesMultinomialText0.getCapabilities();
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      double[] doubleArray0 = new double[8];
      doubleArray0[0] = 985.330014;
      doubleArray0[1] = 0.0;
      doubleArray0[2] = (double) 0;
      doubleArray0[3] = 0.0;
      doubleArray0[4] = 3.0;
      doubleArray0[5] = 0.0;
      doubleArray0[6] = (double) 0;
      doubleArray0[7] = (double) 0;
      SparseInstance sparseInstance0 = null;
      try {
        sparseInstance0 = new SparseInstance(0.0, doubleArray0, (int[]) null, 0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.SparseInstance", e);
      }
  }

  /**
  //Test case number: 8
  /*Coverage entropy=1.7917594692280547
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_norm = (-2.0);
      naiveBayesMultinomialText0.m_useStopList = true;
      URI uRI0 = MockURI.aFileURI;
      MockFile mockFile0 = new MockFile(uRI0);
      naiveBayesMultinomialText0.m_stopwordsFile = (File) mockFile0;
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      String[] stringArray0 = new String[5];
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      stringArray0[0] = "*U>1";
      stringArray0[1] = "|s^dVdmli";
      stringArray0[2] = "All class and attribute options can be prefixed with 'not',\ne.g., '-not-numeric-class'. This makes sure that the returned\nschemes 'cannot' handle numeric classes.";
      stringArray0[3] = "[.>7W {>]mT9s>(6a-";
      stringArray0[4] = "G.hF{;n<%";
      Tokenizer.tokenize((Tokenizer) wordTokenizer0, stringArray0);
      naiveBayesMultinomialText0.setPeriodicPruning(1349);
      naiveBayesMultinomialText0.listOptions();
      wordTokenizer0.hasMoreElements();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      ArrayList<Attribute> arrayList0 = new ArrayList<Attribute>();
      Instances instances0 = new Instances("[.>7W {>]mT9s>(6a-", arrayList0, 1349);
      try { 
        BallNode.calcPivot((BallNode) null, (BallNode) null, instances0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.neighboursearch.balltrees.BallNode", e);
      }
  }

  /**
  //Test case number: 9
  /*Coverage entropy=2.488327743368588
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setDebug(false);
      naiveBayesMultinomialText0.LNormTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      LinkedHashMap<String, NaiveBayesMultinomialText.Count> linkedHashMap0 = naiveBayesMultinomialText1.m_inputVector;
      naiveBayesMultinomialText0.m_inputVector = null;
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      naiveBayesMultinomialText0.globalInfo();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText1.setTokenizer(wordTokenizer0);
      String[] stringArray0 = new String[8];
      stringArray0[0] = "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification";
      stringArray0[1] = "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification";
      stringArray0[2] = "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification";
      stringArray0[3] = " and ";
      stringArray0[4] = "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification";
      stringArray0[5] = "The LNorm to use for document length normalization.";
      stringArray0[6] = "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification";
      stringArray0[7] = "Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification";
      NaiveBayesMultinomialText.main(stringArray0);
      naiveBayesMultinomialText1.getMinWordFrequency();
      Capabilities capabilities0 = naiveBayesMultinomialText1.getCapabilities();
      naiveBayesMultinomialText1.getTokenizer();
      naiveBayesMultinomialText0.getNormalizeDocLength();
      naiveBayesMultinomialText0.getMinWordFrequency();
      int[] intArray0 = new int[5];
      intArray0[0] = 2119;
      intArray0[1] = 150;
      intArray0[2] = 267;
      intArray0[3] = 267;
      intArray0[4] = (-3670);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      Instance instance0 = BallNode.calcCentroidPivot(267, (-3670), intArray0, instances0);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(instance0, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 10
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) nGramTokenizer0;
      NullStemmer nullStemmer0 = new NullStemmer();
      naiveBayesMultinomialText0.setStemmer(nullStemmer0);
      String[] stringArray0 = new String[9];
      stringArray0[0] = "";
      stringArray0[1] = "The norm of the instances after normalization.";
      stringArray0[2] = "Node ";
      stringArray0[3] = "";
      stringArray0[4] = "j,T CQ:i,a[9cOV&'s";
      stringArray0[5] = "An adaptation of Relief for attribute estimation in regression";
      stringArray0[6] = "yVTMFo}Y)}W>;QtgOww";
      stringArray0[7] = "Px";
      stringArray0[8] = "]V&+_y?";
      NGramTokenizer.main(stringArray0);
      naiveBayesMultinomialText0.periodicPruningTipText();
      naiveBayesMultinomialText0.getStemmer();
  }

  /**
  //Test case number: 11
  /*Coverage entropy=3.332487767792379
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.listOptions();
      double[] doubleArray0 = new double[0];
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      SMO sMO0 = new SMO();
      AbstractClassifier.makeCopies(sMO0, 1);
      naiveBayesMultinomialText0.setNormalizeDocLength(false);
      naiveBayesMultinomialText0.setOptions((String[]) null);
      naiveBayesMultinomialText0.m_useStopList = true;
      naiveBayesMultinomialText0.setUseStopList(false);
      naiveBayesMultinomialText0.pruneDictionary();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.lowercaseTokensTipText();
      naiveBayesMultinomialText0.setMinWordFrequency(101.20714981493929);
      naiveBayesMultinomialText0.setLowercaseTokens(false);
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.toString();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      SparseInstance sparseInstance1 = new SparseInstance((Instance) sparseInstance0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(sparseInstance1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 12
  /*Coverage entropy=2.0982737395252498
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setDebug(false);
      naiveBayesMultinomialText0.LNormTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      LinkedHashMap<String, NaiveBayesMultinomialText.Count> linkedHashMap0 = naiveBayesMultinomialText1.m_inputVector;
      naiveBayesMultinomialText0.m_inputVector = null;
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.getUseWordFrequencies();
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText1.setTokenizer(wordTokenizer0);
      MockFile mockFile0 = (MockFile)naiveBayesMultinomialText1.m_stopwordsFile;
      MockFile mockFile1 = new MockFile(mockFile0, "The LNorm to use for document length normalization.");
      File file0 = MockFile.createTempFile("p[e2xMNo9", "p[e2xMNo9");
      naiveBayesMultinomialText1.setStopwords(file0);
      naiveBayesMultinomialText0.setNorm(0.0);
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.pruneDictionary();
  }

  /**
  //Test case number: 13
  /*Coverage entropy=3.3627410007370897
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setUseStopList(false);
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      nGramTokenizer0.tokenize("\tSet the number of neighbours used to set the kernel bandwidth.\n\t(default all)");
      nGramTokenizer0.nextElement();
      Tokenizer.runTokenizer(nGramTokenizer0, stringArray0);
      naiveBayesMultinomialText0.setTokenizer(nGramTokenizer0);
      LinkedHashMap<String, NaiveBayesMultinomialText.Count> linkedHashMap0 = new LinkedHashMap<String, NaiveBayesMultinomialText.Count>();
      naiveBayesMultinomialText0.m_inputVector = linkedHashMap0;
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      int[] intArray0 = new int[8];
      intArray0[0] = 3;
      intArray0[1] = 3;
      intArray0[2] = 3;
      intArray0[3] = 3;
      intArray0[4] = 3;
      intArray0[5] = 3;
      intArray0[6] = 3;
      intArray0[7] = 3;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0.0, intArray0, (-3465));
      SparseInstance sparseInstance0 = new SparseInstance((SparseInstance) binarySparseInstance0);
      BinarySparseInstance binarySparseInstance1 = new BinarySparseInstance((Instance) binarySparseInstance0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.tokenizeInstance(sparseInstance0, false);
      try { 
        naiveBayesMultinomialText0.updateClassifier(sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 14
  /*Coverage entropy=1.15374194270109
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.tokenizerTipText();
      naiveBayesMultinomialText0.pruneDictionary();
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance((-444.793), doubleArray0);
      SparseInstance sparseInstance1 = new SparseInstance(sparseInstance0);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(sparseInstance1, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 15
  /*Coverage entropy=2.995732273553991
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      WordTokenizer wordTokenizer0 = (WordTokenizer)naiveBayesMultinomialText0.m_tokenizer;
      naiveBayesMultinomialText0.m_tokenizer = (Tokenizer) wordTokenizer0;
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      wordTokenizer0.tokenize("z");
      naiveBayesMultinomialText0.getTokenizer();
      naiveBayesMultinomialText0.m_t = (-107.60956027239);
      naiveBayesMultinomialText0.normTipText();
      naiveBayesMultinomialText0.useStopListTipText();
      NullStemmer nullStemmer0 = (NullStemmer)naiveBayesMultinomialText0.m_stemmer;
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.stopwordsTipText();
      naiveBayesMultinomialText0.getOptions();
      try { 
        naiveBayesMultinomialText0.buildClassifier((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 16
  /*Coverage entropy=3.0646194052010944
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setUseStopList(false);
      NGramTokenizer nGramTokenizer0 = new NGramTokenizer();
      NGramTokenizer nGramTokenizer1 = new NGramTokenizer();
      nGramTokenizer1.nextElement();
      String[] stringArray0 = new String[0];
      Tokenizer.runTokenizer(nGramTokenizer0, stringArray0);
      naiveBayesMultinomialText0.setTokenizer(nGramTokenizer0);
      LinkedHashMap<String, NaiveBayesMultinomialText.Count> linkedHashMap0 = new LinkedHashMap<String, NaiveBayesMultinomialText.Count>();
      naiveBayesMultinomialText0.minWordFrequencyTipText();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      naiveBayesMultinomialText0.getStopwords();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      naiveBayesMultinomialText0.setMinWordFrequency(0.0);
      naiveBayesMultinomialText0.pruneDictionary();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.normalizeDocLengthTipText();
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.toString();
      NaiveBayesMultinomialText naiveBayesMultinomialText3 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText3.getOptions();
      naiveBayesMultinomialText0.getOptions();
      Random.setNextRandom((-520));
      Random.setNextRandom((-520));
  }

  /**
  //Test case number: 17
  /*Coverage entropy=2.1972245773362196
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      FileSystemHandling.shouldAllThrowIOExceptions();
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      TestInstances testInstances0 = new TestInstances();
      naiveBayesMultinomialText0.setLNorm((-2));
      Instances instances0 = testInstances0.generate("\"W3");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      Random.setNextRandom((-2));
      System.setCurrentTimeMillis(1196L);
  }

  /**
  //Test case number: 18
  /*Coverage entropy=2.582306344313967
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NullStemmer nullStemmer0 = (NullStemmer)naiveBayesMultinomialText0.m_stemmer;
      naiveBayesMultinomialText0.setUseStopList(true);
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) nullStemmer0;
      naiveBayesMultinomialText0.toString();
      naiveBayesMultinomialText0.getOptions();
  }

  /**
  //Test case number: 19
  /*Coverage entropy=2.1639556568820564
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int int0 = (-3396);
      double[] doubleArray0 = new double[2];
      SnowballStemmer snowballStemmer0 = new SnowballStemmer();
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) snowballStemmer0;
      doubleArray0[0] = 0.0;
      naiveBayesMultinomialText0.m_leplace = (double) (-3396);
      doubleArray0[1] = 3498.6355;
      naiveBayesMultinomialText0.m_wordsPerClass = doubleArray0;
      naiveBayesMultinomialText0.m_periodicP = (-3396);
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.getOptions();
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      double double0 = 0.0;
      int[] intArray0 = new int[5];
      intArray0[0] = (-3396);
      intArray0[1] = (-3396);
      intArray0[2] = (-3396);
      try { 
        inputMappedClassifier0.graph();
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Classifier: weka.classifiers.rules.ZeroR  cannot be graphed
         //
         verifyException("weka.classifiers.misc.InputMappedClassifier", e);
      }
  }

  /**
  //Test case number: 20
  /*Coverage entropy=2.86678126255389
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setUseStopList(false);
      TestInstances testInstances0 = new TestInstances();
      CVParameterSelection cVParameterSelection0 = new CVParameterSelection();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances1.generate("");
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      Random.setNextRandom((-2));
      naiveBayesMultinomialText0.toString();
  }

  /**
  //Test case number: 21
  /*Coverage entropy=2.9683918915419634
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.getOptions();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      CorrelationAttributeEval correlationAttributeEval0 = new CorrelationAttributeEval();
      naiveBayesMultinomialText1.setUseStopList(true);
      Capabilities capabilities0 = correlationAttributeEval0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Capabilities capabilities1 = capabilities0.getAttributeCapabilities();
      TestInstances.forCapabilities(capabilities1);
      Instances instances0 = testInstances0.generate((String) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.buildClassifier(instances0);
      Random.setNextRandom(29);
      naiveBayesMultinomialText1.toString();
  }

  /**
  //Test case number: 22
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.m_periodicP = 1;
      naiveBayesMultinomialText0.getCapabilities();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.pruneDictionary();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 23
  /*Coverage entropy=1.3321790402101223
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.m_periodicP = 24;
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.pruneDictionary();
  }

  /**
  //Test case number: 24
  /*Coverage entropy=1.7014128724388486
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.setUseStopList(true);
      TestInstances testInstances0 = new TestInstances();
      CVParameterSelection cVParameterSelection0 = new CVParameterSelection();
      Capabilities capabilities0 = naiveBayesMultinomialText1.getCapabilities();
      TestInstances.forCapabilities(capabilities0);
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances1.generate("yRk&#@F");
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText1.buildClassifier(instances0);
      Random.setNextRandom((-1));
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "05'%e}Z3U\"");
      naiveBayesMultinomialText0.toString();
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (double) (-1);
      doubleArray0[1] = (double) (-2);
      doubleArray0[2] = (double) (-1);
      doubleArray0[3] = (double) (-2);
      doubleArray0[4] = (double) (-2);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0.0, doubleArray0);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 25
  /*Coverage entropy=2.5240580773894714
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      Random.setNextRandom(1);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_norm = (double) 1;
      Stopwords stopwords0 = new Stopwords();
      naiveBayesMultinomialText0.m_stopwords = stopwords0;
      FileSystemHandling.setPermissions((EvoSuiteFile) null, true, true, true);
      naiveBayesMultinomialText0.m_useStopList = true;
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "jzY\u001Brf");
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      precomputedKernelMatrixKernel0.getOptions();
      File file0 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      precomputedKernelMatrixKernel0.getRevision();
      FileSystemHandling.appendLineToFile((EvoSuiteFile) null, "28;[#");
      naiveBayesMultinomialText0.m_stopwordsFile = file0;
      naiveBayesMultinomialText0.setDebug(true);
      naiveBayesMultinomialText0.m_periodicP = 1;
      naiveBayesMultinomialText0.getOptions();
      precomputedKernelMatrixKernel0.getCapabilities();
      naiveBayesMultinomialText0.toString();
      System.setCurrentTimeMillis((-1L));
      precomputedKernelMatrixKernel0.setDebug(false);
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.getOptions();
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.pruneDictionary();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }
}
