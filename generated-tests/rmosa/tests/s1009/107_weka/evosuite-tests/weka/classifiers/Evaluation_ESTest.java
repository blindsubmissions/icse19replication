/*
 * This file was automatically generated by EvoSuite
 * Thu Aug 23 09:22:03 GMT 2018
 */

package weka.classifiers;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.File;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.io.InputStream;
import java.io.PipedReader;
import java.io.StringReader;
import java.util.Collection;
import java.util.Enumeration;
import java.util.PriorityQueue;
import java.util.Vector;
import java.util.function.Predicate;
import java.util.stream.DoubleStream;
import javax.imageio.metadata.IIOMetadataNode;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.Random;
import org.evosuite.runtime.System;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.mock.java.io.MockFileInputStream;
import org.evosuite.runtime.mock.java.util.MockRandom;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;
import weka.attributeSelection.PrincipalComponents;
import weka.classifiers.Classifier;
import weka.classifiers.CostMatrix;
import weka.classifiers.Evaluation;
import weka.classifiers.bayes.NaiveBayes;
import weka.classifiers.evaluation.output.prediction.XML;
import weka.classifiers.functions.GaussianProcesses;
import weka.classifiers.functions.LinearRegression;
import weka.classifiers.functions.Logistic;
import weka.classifiers.functions.SGDText;
import weka.classifiers.functions.SimpleLinearRegression;
import weka.classifiers.functions.supportVector.Puk;
import weka.classifiers.lazy.LWL;
import weka.classifiers.meta.CVParameterSelection;
import weka.classifiers.meta.CostSensitiveClassifier;
import weka.classifiers.meta.LogitBoost;
import weka.classifiers.meta.MultiClassClassifier;
import weka.classifiers.meta.MultiClassClassifierUpdateable;
import weka.classifiers.meta.RegressionByDiscretization;
import weka.classifiers.meta.Stacking;
import weka.classifiers.meta.Vote;
import weka.classifiers.misc.SerializedClassifier;
import weka.classifiers.pmml.consumer.TreeModel;
import weka.classifiers.rules.M5Rules;
import weka.classifiers.rules.ZeroR;
import weka.classifiers.trees.DecisionStump;
import weka.classifiers.trees.J48;
import weka.classifiers.trees.REPTree;
import weka.core.AbstractInstance;
import weka.core.Attribute;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.DenseInstance;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.SparseInstance;
import weka.core.TestInstances;
import weka.core.Version;
import weka.core.converters.AbstractFileLoader;
import weka.core.converters.ArffLoader;
import weka.core.converters.C45Loader;
import weka.core.converters.CSVLoader;
import weka.core.converters.ConverterUtils;
import weka.core.converters.Loader;
import weka.core.converters.MatlabLoader;
import weka.core.converters.TextDirectoryLoader;
import weka.core.converters.XRFFLoader;
import weka.core.neighboursearch.CoverTree;
import weka.core.neighboursearch.balltrees.BallNode;
import weka.core.neighboursearch.balltrees.MiddleOutConstructor;
import weka.core.pmml.MiningSchema;
import weka.estimators.UnivariateKernelEstimator;
import weka.filters.AllFilter;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class Evaluation_ESTest extends Evaluation_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=-0.0
  */
  @Test(timeout = 4000)
  public void test000()  throws Throwable  {
      try { 
        Evaluation.handleCostOption("E", (-5421));
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't open file null.
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 1
  /*Coverage entropy=-0.0
  */
  @Test(timeout = 4000)
  public void test001()  throws Throwable  {
      DecisionStump decisionStump0 = new DecisionStump();
      String string0 = Evaluation.getGlobalInfo(decisionStump0);
      assertEquals("\nSynopsis for weka.classifiers.trees.DecisionStump:\n\nClass for building and using a decision stump. Usually used in conjunction with a boosting algorithm. Does regression (based on mean-squared error) or classification (based on entropy). Missing is treated as a separate value.", string0);
  }

  /**
  //Test case number: 2
  /*Coverage entropy=0.6931471805599453
  */
  @Test(timeout = 4000)
  public void test002()  throws Throwable  {
      String[] stringArray0 = new String[1];
      Evaluation.main(stringArray0);
      assertEquals(1, stringArray0.length);
  }

  /**
  //Test case number: 3
  /*Coverage entropy=0.649248354870898
  */
  @Test(timeout = 4000)
  public void test003()  throws Throwable  {
      MultiClassClassifierUpdateable multiClassClassifierUpdateable0 = new MultiClassClassifierUpdateable();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "JkOcu_Q";
      stringArray0[1] = "toSource";
      stringArray0[2] = "\tOutputs detailed information-retrieval";
      stringArray0[3] = "\tCorrelation Ranking Filter";
      stringArray0[4] = "|=b+OxCab~^9=/+";
      stringArray0[5] = "=== Error on test split ===\n";
      stringArray0[6] = "h ";
      MultiClassClassifierUpdateable.main(stringArray0);
      byte[] byteArray0 = new byte[6];
      byteArray0[0] = (byte)111;
      byteArray0[1] = (byte)111;
      byteArray0[2] = (byte)9;
      byteArray0[3] = (byte) (-120);
      byteArray0[4] = (byte) (-20);
      byteArray0[5] = (byte)31;
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      ArffLoader arffLoader0 = new ArffLoader();
      AbstractFileLoader.FILE_EXTENSION_COMPRESSED = "toSource";
      arffLoader0.setRetrieval(0);
      try { 
        arffLoader0.getDataSet();
        fail("Expecting exception: IOException");
      
      } catch(IOException e) {
         //
         // No source has been specified
         //
         verifyException("weka.core.converters.ArffLoader", e);
      }
  }

  /**
  //Test case number: 4
  /*Coverage entropy=0.6931471805599453
  */
  @Test(timeout = 4000)
  public void test004()  throws Throwable  {
      Vote vote0 = new Vote();
      Evaluation.makeOptionString(vote0, true);
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      textDirectoryLoader0.getStructure();
      try { 
        CostMatrix.parseMatlab((String) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.CostMatrix", e);
      }
  }

  /**
  //Test case number: 5
  /*Coverage entropy=-0.0
  */
  @Test(timeout = 4000)
  public void test005()  throws Throwable  {
      Stacking stacking0 = new Stacking();
      Classifier classifier0 = stacking0.getMetaClassifier();
      Evaluation.makeOptionString(classifier0, false);
      XML xML0 = new XML();
      xML0.getHeader();
      CostMatrix costMatrix0 = new CostMatrix(2113);
  }

  /**
  //Test case number: 6
  /*Coverage entropy=-0.0
  */
  @Test(timeout = 4000)
  public void test006()  throws Throwable  {
      REPTree rEPTree0 = new REPTree();
      Evaluation.makeOptionString(rEPTree0, false);
      byte[] byteArray0 = new byte[4];
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      CoverTree coverTree0 = new CoverTree();
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      PrincipalComponents principalComponents0 = new PrincipalComponents();
      XRFFLoader xRFFLoader0 = new XRFFLoader();
      try { 
        xRFFLoader0.getStructure();
        fail("Expecting exception: IOException");
      
      } catch(IOException e) {
         //
         // No source has been specified
         //
         verifyException("weka.core.converters.XRFFLoader", e);
      }
  }

  /**
  //Test case number: 7
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test007()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      CostMatrix costMatrix0 = new CostMatrix(39);
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.avgCost();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  /**
  //Test case number: 8
  /*Coverage entropy=-0.0
  */
  @Test(timeout = 4000)
  public void test008()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      CostMatrix costMatrix0 = costSensitiveClassifier0.getCostMatrix();
      Evaluation evaluation0 = null;
      try {
        evaluation0 = new Evaluation(instances0, costMatrix0);
        fail("Expecting exception: Exception");
      
      } catch(Throwable e) {
         //
         // Cost matrix not compatible with data!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 9
  /*Coverage entropy=-0.0
  */
  @Test(timeout = 4000)
  public void test009()  throws Throwable  {
      CostMatrix costMatrix0 = Evaluation.handleCostOption((String) null, (-5421));
      assertNull(costMatrix0);
  }

  /**
  //Test case number: 10
  /*Coverage entropy=1.2511559833636317
  */
  @Test(timeout = 4000)
  public void test010()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      SGDText sGDText0 = new SGDText();
      sGDText0.setNormalizeDocLength(false);
      Capabilities capabilities0 = sGDText0.getCapabilities();
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      testInstances1.generate();
      testInstances1.generate(".bsi");
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      evaluation0.toSummaryString("@data", true);
      String string0 = evaluation0.toSummaryString("$,gioLX]N@Qf.O2_FVd", false);
      assertEquals("$,gioLX]N@Qf.O2_FVd\nTotal Number of Instances                0     \n", string0);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
  }

  /**
  //Test case number: 11
  /*Coverage entropy=1.475076311054695
  */
  @Test(timeout = 4000)
  public void test011()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      Capabilities capabilities0 = sGDText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      capabilities0.enableAll();
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      instances0.getRandomNumberGenerator(0);
      GaussianProcesses gaussianProcesses0 = new GaussianProcesses();
      evaluation0.toSummaryString(false);
      try { 
        evaluation0.updateStatsForIntervalEstimator(gaussianProcesses0, (Instance) null, 0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.functions.GaussianProcesses", e);
      }
  }

  /**
  //Test case number: 12
  /*Coverage entropy=1.2047933096947843
  */
  @Test(timeout = 4000)
  public void test012()  throws Throwable  {
      DecisionStump decisionStump0 = new DecisionStump();
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate((String) null);
      PriorityQueue<CVParameterSelection> priorityQueue0 = new PriorityQueue<CVParameterSelection>();
      instances0.removeAll(priorityQueue0);
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      testInstances0.generate();
      FileSystemHandling.shouldThrowIOException((EvoSuiteFile) null);
      double double0 = evaluation0.KBMeanInformation();
      assertEquals(Double.NaN, double0, 0.01);
      
      evaluation0.areaUnderROC((-1));
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  /**
  //Test case number: 13
  /*Coverage entropy=1.310783678099714
  */
  @Test(timeout = 4000)
  public void test013()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      Capabilities capabilities0 = sGDText0.getCapabilities();
      capabilities0.capabilities();
      capabilities0.enableAll();
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/evosuite_readability_gen/projects/107_weka");
      FileSystemHandling.setPermissions(evoSuiteFile0, false, false, false);
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      double double0 = evaluation0.weightedAreaUnderPRC();
      double double1 = evaluation0.errorRate();
      assertEquals(double1, double0, 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, double1, 0.01);
  }

  /**
  //Test case number: 14
  /*Coverage entropy=1.3760552852604169
  */
  @Test(timeout = 4000)
  public void test014()  throws Throwable  {
      Evaluation.handleCostOption("", (-2268));
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      double[] doubleArray0 = evaluation0.makeDistribution(0.0);
      assertArrayEquals(new double[] {1.0, 0.0}, doubleArray0, 0.01);
      assertEquals(2, doubleArray0.length);
      assertNotNull(doubleArray0);
      
      evaluation0.setDiscardPredictions(false);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  /**
  //Test case number: 15
  /*Coverage entropy=1.0986122886681096
  */
  @Test(timeout = 4000)
  public void test015()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      double double0 = evaluation0.errorRate();
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
  }

  /**
  //Test case number: 16
  /*Coverage entropy=1.1269287948006759
  */
  @Test(timeout = 4000)
  public void test016()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      Capabilities capabilities0 = sGDText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      capabilities0.enableAll();
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      Instances instances1 = new Instances(instances0);
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (double) (-1);
      doubleArray0[2] = (double) 0;
      doubleArray0[3] = (double) 1;
      doubleArray0[4] = (double) 1;
      RegressionByDiscretization regressionByDiscretization0 = new RegressionByDiscretization();
      regressionByDiscretization0.setClassifier(sGDText0);
      DenseInstance denseInstance0 = new DenseInstance(0.0, doubleArray0);
      try { 
        evaluation0.updateStatsForConditionalDensityEstimator(regressionByDiscretization0, denseInstance0, (-2));
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.meta.RegressionByDiscretization", e);
      }
  }

  /**
  //Test case number: 17
  /*Coverage entropy=1.6674619334292948
  */
  @Test(timeout = 4000)
  public void test017()  throws Throwable  {
      Evaluation.handleCostOption("", (-2268));
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      evaluation0.rootRelativeSquaredError();
      double double0 = evaluation0.numInstances();
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, double0, 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  /**
  //Test case number: 18
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test018()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      testInstances0.generate();
      SGDText sGDText0 = new SGDText();
      Capabilities capabilities0 = sGDText0.getCapabilities();
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances1.generate();
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      evaluation0.getClassPriors();
      try { 
        evaluation0.updatePriors((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 19
  /*Coverage entropy=1.6094379124341005
  */
  @Test(timeout = 4000)
  public void test019()  throws Throwable  {
      DecisionStump decisionStump0 = new DecisionStump();
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getStructure();
      Evaluation evaluation0 = new Evaluation(instances0);
      boolean boolean0 = true;
      evaluation0.totalCost();
      evaluation0.KBInformation();
      Stacking stacking0 = new Stacking();
      stacking0.getMetaClassifier();
      MiddleOutConstructor middleOutConstructor0 = new MiddleOutConstructor();
      try { 
        middleOutConstructor0.buildTree();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.neighboursearch.balltrees.BallNode", e);
      }
  }

  /**
  //Test case number: 20
  /*Coverage entropy=1.6107743659691276
  */
  @Test(timeout = 4000)
  public void test020()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      
      byte[] byteArray0 = new byte[2];
      byteArray0[0] = (byte)4;
      byteArray0[1] = (byte)32;
      boolean boolean0 = FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      assertFalse(boolean0);
      assertEquals(2, byteArray0.length);
      assertArrayEquals(new byte[] {(byte)4, (byte)32}, byteArray0);
      
      Instances instances1 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances1);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, instances1.numInstances());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(1, instances1.classIndex());
      assertEquals(2, instances1.numClasses());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(20, instances1.size());
      assertEquals(2, instances1.numAttributes());
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(instances1, instances0);
      
      Evaluation evaluation0 = new Evaluation(instances1);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, instances1.numInstances());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(1, instances1.classIndex());
      assertEquals(2, instances1.numClasses());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(20, instances1.size());
      assertEquals(2, instances1.numAttributes());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertFalse(instances1.equals((Object)instances0));
      
      double double0 = evaluation0.unweightedMicroFmeasure();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, instances1.numInstances());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(1, instances1.classIndex());
      assertEquals(2, instances1.numClasses());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(20, instances1.size());
      assertEquals(2, instances1.numAttributes());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(instances1, instances0);
  }

  /**
  //Test case number: 21
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test021()  throws Throwable  {
      M5Rules m5Rules0 = new M5Rules();
      assertNotNull(m5Rules0);
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getUseUnsmoothed());
      
      Capabilities capabilities0 = m5Rules0.getCapabilities();
      assertNotNull(capabilities0);
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      
      capabilities0.enableAll();
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, instances0.numClasses());
      assertEquals(3, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(4, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      
      Instances instances1 = new Instances(instances0, (-1));
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances1);
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, instances0.numClasses());
      assertEquals(3, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(4, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, instances1.sumOfWeights(), 0.01);
      assertEquals(0, instances1.size());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(0, instances1.numInstances());
      assertEquals(4, instances1.numAttributes());
      assertEquals(3, instances1.classIndex());
      assertEquals(1, instances1.numClasses());
      assertFalse(instances1.checkForStringAttributes());
      assertFalse(instances1.equals((Object)instances0));
      
      Evaluation evaluation0 = new Evaluation(instances1, (CostMatrix) null);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, instances0.numClasses());
      assertEquals(3, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(4, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, instances1.sumOfWeights(), 0.01);
      assertEquals(0, instances1.size());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(0, instances1.numInstances());
      assertEquals(4, instances1.numAttributes());
      assertEquals(3, instances1.classIndex());
      assertEquals(1, instances1.numClasses());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertFalse(instances1.equals((Object)instances0));
      
      Instances instances2 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances2);
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(4, instances2.numAttributes());
      assertEquals("Testdata", instances2.relationName());
      assertEquals(1, instances2.numClasses());
      assertEquals(3, instances2.classIndex());
      assertEquals(20, instances2.numInstances());
      assertEquals(20.0, instances2.sumOfWeights(), 0.01);
      assertFalse(instances2.checkForStringAttributes());
      assertEquals(20, instances2.size());
      assertFalse(instances2.equals((Object)instances1));
      assertFalse(instances2.equals((Object)instances0));
      assertNotSame(instances2, instances1);
      assertNotSame(instances2, instances0);
      
      // Undeclared exception!
      try { 
        evaluation0.unweightedMacroFmeasure();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 22
  /*Coverage entropy=2.1972245773362196
  */
  @Test(timeout = 4000)
  public void test022()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      
      double double0 = evaluation0.KBRelativeInformation();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0.0, double0, 0.01);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      
      double double1 = evaluation0.weightedPrecision();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double1, 0.01);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertNotEquals(double1, double0, 0.01);
      
      double double2 = evaluation0.SFMeanSchemeEntropy();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double2, 0.01);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(double2, double1, 0.01);
      assertNotEquals(double2, double0, 0.01);
  }

  /**
  //Test case number: 23
  /*Coverage entropy=1.310783678099714
  */
  @Test(timeout = 4000)
  public void test023()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(sGDText0);
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(capabilities0);
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      capabilities0.enableAll();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/evosuite_readability_gen/projects/107_weka");
      boolean boolean0 = FileSystemHandling.setPermissions(evoSuiteFile0, false, false, false);
      assertTrue(boolean0);
      
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      
      double double0 = evaluation0.errorRate();
      assertEquals(Double.NaN, double0, 0.01);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      
      double double1 = evaluation0.precision(259);
      assertEquals(0.0, double1, 0.01);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertNotEquals(double1, double0, 0.01);
  }

  /**
  //Test case number: 24
  /*Coverage entropy=1.4695035720864686
  */
  @Test(timeout = 4000)
  public void test024()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      
      testInstances0.setMultiInstance(false);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (double) (-1);
      doubleArray0[1] = (double) (-1);
      doubleArray0[2] = (double) (-1);
      doubleArray0[3] = (double) (-1);
      doubleArray0[4] = (double) (-2);
      evaluation0.updateNumericScores(doubleArray0, doubleArray0, (-2));
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NEGATIVE_INFINITY, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(5, doubleArray0.length);
      assertArrayEquals(new double[] {(-1.0), (-1.0), (-1.0), (-1.0), (-2.0)}, doubleArray0, 0.01);
      
      String string0 = evaluation0.toMatrixString(" ");
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(string0);
      assertEquals(" \n a b   <-- classified as\n 0 0 | a = class1\n 0 0 | b = class2\n", string0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NEGATIVE_INFINITY, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      
      J48 j48_0 = new J48();
      assertNotNull(j48_0);
      assertEquals("The confidence factor used for pruning (smaller values incur more pruning).", j48_0.confidenceFactorTipText());
      assertTrue(j48_0.getSubtreeRaising());
      assertEquals("Whether MDL correction is used when finding splits on numeric attributes.", j48_0.useMDLcorrectionTipText());
      assertEquals(1, j48_0.graphType());
      assertFalse(j48_0.getDebug());
      assertEquals(3, j48_0.getNumFolds());
      assertEquals(1, j48_0.getSeed());
      assertEquals("If set to true, classifier may output additional info to the console.", j48_0.debugTipText());
      assertEquals("Whether reduced-error pruning is used instead of C.4.5 pruning.", j48_0.reducedErrorPruningTipText());
      assertFalse(j48_0.getBinarySplits());
      assertFalse(j48_0.getUseLaplace());
      assertEquals("Whether counts at leaves are smoothed based on Laplace.", j48_0.useLaplaceTipText());
      assertEquals("Whether pruning is performed.", j48_0.unprunedTipText());
      assertEquals("The seed used for randomizing the data when reduced-error pruning is used.", j48_0.seedTipText());
      assertEquals("Whether to consider the subtree raising operation when pruning.", j48_0.subtreeRaisingTipText());
      assertTrue(j48_0.getUseMDLcorrection());
      assertEquals("Whether to save the training data for visualization.", j48_0.saveInstanceDataTipText());
      assertEquals("The minimum number of instances per leaf.", j48_0.minNumObjTipText());
      assertTrue(j48_0.getCollapseTree());
      assertEquals(2, j48_0.getMinNumObj());
      assertFalse(j48_0.getUnpruned());
      assertEquals(0.25F, j48_0.getConfidenceFactor(), 0.01F);
      assertFalse(j48_0.getSaveInstanceData());
      assertEquals("Determines the amount of data used for reduced-error pruning.  One fold is used for pruning, the rest for growing the tree.", j48_0.numFoldsTipText());
      assertEquals("Whether to use binary splits on nominal attributes when building the trees.", j48_0.binarySplitsTipText());
      assertEquals("Whether parts are removed that do not reduce training error.", j48_0.collapseTreeTipText());
      assertFalse(j48_0.getReducedErrorPruning());
      
      MockRandom mockRandom0 = new MockRandom((-3575L));
      assertNotNull(mockRandom0);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation1);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertTrue(evaluation1.equals((Object)evaluation0));
      
      double double0 = evaluation1.SFMeanPriorEntropy();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotSame(evaluation1, evaluation0);
  }

  /**
  //Test case number: 25
  /*Coverage entropy=0.6931471805599453
  */
  @Test(timeout = 4000)
  public void test025()  throws Throwable  {
      Logistic logistic0 = new Logistic();
      assertNotNull(logistic0);
      assertEquals((-1), logistic0.getMaxIts());
      assertEquals("Use conjugate gradient descent rather than BFGS updates; faster for problems with many parameters.", logistic0.useConjugateGradientDescentTipText());
      assertEquals("Output debug information to the console.", logistic0.debugTipText());
      assertEquals("Set the Ridge value in the log-likelihood.", logistic0.ridgeTipText());
      assertFalse(logistic0.getDebug());
      assertEquals("Maximum number of iterations to perform.", logistic0.maxItsTipText());
      assertFalse(logistic0.getUseConjugateGradientDescent());
      assertEquals(1.0E-8, logistic0.getRidge(), 0.01);
      
      String string0 = logistic0.getRevision();
      assertNotNull(string0);
      assertEquals("8079", string0);
      assertEquals((-1), logistic0.getMaxIts());
      assertEquals("Use conjugate gradient descent rather than BFGS updates; faster for problems with many parameters.", logistic0.useConjugateGradientDescentTipText());
      assertEquals("Output debug information to the console.", logistic0.debugTipText());
      assertEquals("Set the Ridge value in the log-likelihood.", logistic0.ridgeTipText());
      assertFalse(logistic0.getDebug());
      assertEquals("Maximum number of iterations to perform.", logistic0.maxItsTipText());
      assertFalse(logistic0.getUseConjugateGradientDescent());
      assertEquals(1.0E-8, logistic0.getRidge(), 0.01);
      
      String string1 = logistic0.toString();
      assertNotNull(string1);
      assertEquals(": No model built yet.", string1);
      assertEquals((-1), logistic0.getMaxIts());
      assertEquals("Use conjugate gradient descent rather than BFGS updates; faster for problems with many parameters.", logistic0.useConjugateGradientDescentTipText());
      assertEquals("Output debug information to the console.", logistic0.debugTipText());
      assertEquals("Set the Ridge value in the log-likelihood.", logistic0.ridgeTipText());
      assertFalse(logistic0.getDebug());
      assertEquals("Maximum number of iterations to perform.", logistic0.maxItsTipText());
      assertFalse(logistic0.getUseConjugateGradientDescent());
      assertEquals(1.0E-8, logistic0.getRidge(), 0.01);
      assertFalse(string1.equals((Object)string0));
      
      Enumeration enumeration0 = logistic0.listOptions();
      assertNotNull(enumeration0);
      assertEquals((-1), logistic0.getMaxIts());
      assertEquals("Use conjugate gradient descent rather than BFGS updates; faster for problems with many parameters.", logistic0.useConjugateGradientDescentTipText());
      assertEquals("Output debug information to the console.", logistic0.debugTipText());
      assertEquals("Set the Ridge value in the log-likelihood.", logistic0.ridgeTipText());
      assertFalse(logistic0.getDebug());
      assertEquals("Maximum number of iterations to perform.", logistic0.maxItsTipText());
      assertFalse(logistic0.getUseConjugateGradientDescent());
      assertEquals(1.0E-8, logistic0.getRidge(), 0.01);
      
      String string2 = Evaluation.makeOptionString(logistic0, false);
      assertNotNull(string2);
      assertEquals((-1), logistic0.getMaxIts());
      assertEquals("Use conjugate gradient descent rather than BFGS updates; faster for problems with many parameters.", logistic0.useConjugateGradientDescentTipText());
      assertEquals("Output debug information to the console.", logistic0.debugTipText());
      assertEquals("Set the Ridge value in the log-likelihood.", logistic0.ridgeTipText());
      assertFalse(logistic0.getDebug());
      assertEquals("Maximum number of iterations to perform.", logistic0.maxItsTipText());
      assertFalse(logistic0.getUseConjugateGradientDescent());
      assertEquals(1.0E-8, logistic0.getRidge(), 0.01);
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      
      ZeroR zeroR0 = new ZeroR();
      assertNotNull(zeroR0);
      assertFalse(zeroR0.getDebug());
      assertEquals("Class for building and using a 0-R classifier. Predicts the mean (for a numeric class) or the mode (for a nominal class).", zeroR0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", zeroR0.debugTipText());
      
      String string3 = Evaluation.wekaStaticWrapper(zeroR0, "weka.classifiers.RandomizableParallelMultipleClassifiersCombiner");
      assertNotNull(string3);
      assertFalse(zeroR0.getDebug());
      assertEquals("Class for building and using a 0-R classifier. Predicts the mean (for a numeric class) or the mode (for a nominal class).", zeroR0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", zeroR0.debugTipText());
      assertFalse(string3.equals((Object)string1));
      assertFalse(string3.equals((Object)string2));
      assertFalse(string3.equals((Object)string0));
      
      StringReader stringReader0 = new StringReader(string2);
      assertNotNull(stringReader0);
      assertEquals((-1), logistic0.getMaxIts());
      assertEquals("Use conjugate gradient descent rather than BFGS updates; faster for problems with many parameters.", logistic0.useConjugateGradientDescentTipText());
      assertEquals("Output debug information to the console.", logistic0.debugTipText());
      assertEquals("Set the Ridge value in the log-likelihood.", logistic0.ridgeTipText());
      assertFalse(logistic0.getDebug());
      assertEquals("Maximum number of iterations to perform.", logistic0.maxItsTipText());
      assertFalse(logistic0.getUseConjugateGradientDescent());
      assertEquals(1.0E-8, logistic0.getRidge(), 0.01);
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertFalse(string2.equals((Object)string3));
      
      Instances instances0 = null;
      try {
        instances0 = new Instances(stringReader0);
        fail("Expecting exception: IOException");
      
      } catch(Throwable e) {
         //
         // keyword @relation expected, read Token[General], line 3
         //
         verifyException("weka.core.converters.ArffLoader$ArffReader", e);
      }
  }

  /**
  //Test case number: 26
  /*Coverage entropy=2.111630842505602
  */
  @Test(timeout = 4000)
  public void test026()  throws Throwable  {
      byte[] byteArray0 = new byte[2];
      byteArray0[0] = (byte) (-33);
      byteArray0[1] = (byte)69;
      boolean boolean0 = FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      assertFalse(boolean0);
      assertEquals(2, byteArray0.length);
      assertArrayEquals(new byte[] {(byte) (-33), (byte)69}, byteArray0);
      
      CostMatrix costMatrix0 = Evaluation.handleCostOption("", (-2268));
      assertNull(costMatrix0);
      
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      double double0 = evaluation0.rootRelativeSquaredError();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      double double1 = evaluation0.weightedFMeasure();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double1, 0.01);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(double1, double0, 0.01);
  }

  /**
  //Test case number: 27
  /*Coverage entropy=1.945910149055313
  */
  @Test(timeout = 4000)
  public void test027()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getStructure();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = (double) 295;
      doubleArray0[1] = (double) 295;
      evaluation0.updateNumericScores(doubleArray0, doubleArray0, 5.5);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(2, doubleArray0.length);
      assertArrayEquals(new double[] {295.0, 295.0}, doubleArray0, 0.01);
      
      double double0 = evaluation0.unweightedMacroFmeasure();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      
      evaluation0.setNumericPriorsFromBuffer();
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      
      double double1 = evaluation0.pctIncorrect();
      assertEquals(Double.NaN, double1, 0.01);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(double1, double0, 0.01);
  }

  /**
  //Test case number: 28
  /*Coverage entropy=1.6674619334292946
  */
  @Test(timeout = 4000)
  public void test028()  throws Throwable  {
      byte[] byteArray0 = new byte[2];
      byteArray0[0] = (byte) (-33);
      byteArray0[1] = (byte)69;
      boolean boolean0 = FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      assertFalse(boolean0);
      assertEquals(2, byteArray0.length);
      assertArrayEquals(new byte[] {(byte) (-33), (byte)69}, byteArray0);
      
      CostMatrix costMatrix0 = Evaluation.handleCostOption("", (-2268));
      assertNull(costMatrix0);
      
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      
      double double0 = evaluation0.rootRelativeSquaredError();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      
      double double1 = evaluation0.incorrect();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0.0, double1, 0.01);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertNotEquals(double1, double0, 0.01);
  }

  /**
  //Test case number: 29
  /*Coverage entropy=1.7917594692280547
  */
  @Test(timeout = 4000)
  public void test029()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      
      double double0 = evaluation0.weightedTrueNegativeRate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      
      evaluation0.addNumericTrainClass((-2), Double.NaN);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
  }

  /**
  //Test case number: 30
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test030()  throws Throwable  {
      DecisionStump decisionStump0 = new DecisionStump();
      assertNotNull(decisionStump0);
      assertEquals("Class for building and using a decision stump. Usually used in conjunction with a boosting algorithm. Does regression (based on mean-squared error) or classification (based on entropy). Missing is treated as a separate value.", decisionStump0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", decisionStump0.debugTipText());
      assertFalse(decisionStump0.getDebug());
      
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      assertNotNull(simpleLinearRegression0);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertFalse(simpleLinearRegression0.getDebug());
      
      boolean boolean0 = evaluation0.getDiscardPredictions();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertFalse(boolean0);
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      
      try { 
        Capabilities.main(testInstances0.DEFAULT_WORDS);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // No file provided with option '-file'!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 31
  /*Coverage entropy=1.6094379124341005
  */
  @Test(timeout = 4000)
  public void test031()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      
      Instances instances1 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances1);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(20, instances1.numInstances());
      assertEquals(20, instances1.size());
      assertEquals(1, instances1.classIndex());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(2, instances1.numClasses());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(2, instances1.numAttributes());
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(instances1, instances0);
      
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances2 = textDirectoryLoader0.getStructure();
      assertNotNull(instances2);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances2.numClasses());
      assertEquals(0.0, instances2.sumOfWeights(), 0.01);
      assertTrue(instances2.checkForStringAttributes());
      assertEquals(0, instances2.size());
      assertEquals(0, instances2.numInstances());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances2.relationName());
      assertEquals(2, instances2.numAttributes());
      assertEquals(1, instances2.classIndex());
      assertFalse(instances2.equals((Object)instances0));
      assertFalse(instances2.equals((Object)instances1));
      assertNotSame(instances2, instances0);
      assertNotSame(instances2, instances1);
      
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance((-2076.632451297817), doubleArray0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(sparseInstance0);
      assertEquals(0, sparseInstance0.numAttributes());
      assertEquals(0, sparseInstance0.numValues());
      assertEquals((-2076.632451297817), sparseInstance0.weight(), 0.01);
      assertEquals(0, doubleArray0.length);
      assertArrayEquals(new double[] {}, doubleArray0, 0.01);
      
      Evaluation evaluation0 = new Evaluation(instances1);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(20, instances1.numInstances());
      assertEquals(20, instances1.size());
      assertEquals(1, instances1.classIndex());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(2, instances1.numClasses());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(2, instances1.numAttributes());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertFalse(instances1.equals((Object)instances2));
      assertFalse(instances1.equals((Object)instances0));
      
      try { 
        evaluation0.evaluateModelOnce(doubleArray0, (Instance) sparseInstance0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 0
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 32
  /*Coverage entropy=1.6094379124341005
  */
  @Test(timeout = 4000)
  public void test032()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      
      testInstances0.setMultiInstance(false);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (double) (-1);
      doubleArray0[1] = (double) (-1);
      doubleArray0[2] = (double) (-1);
      SparseInstance sparseInstance0 = new SparseInstance(86);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(sparseInstance0);
      assertEquals(86, sparseInstance0.numAttributes());
      assertEquals(86, sparseInstance0.numValues());
      assertEquals(1.0, sparseInstance0.weight(), 0.01);
      
      try { 
        evaluation0.evaluationForSingleInstance(doubleArray0, sparseInstance0, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 33
  /*Coverage entropy=1.945910149055313
  */
  @Test(timeout = 4000)
  public void test033()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      
      String string0 = testInstances0.getRevision();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(string0);
      assertEquals("8034", string0);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      
      Integer integer0 = new Integer((-2));
      assertNotNull(integer0);
      assertEquals((-2), (int)integer0);
      
      evaluation0.setDiscardPredictions(true);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertTrue(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      
      double double0 = evaluation0.weightedRecall();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertTrue(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
  }

  /**
  //Test case number: 34
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test034()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getStructure();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = 2475.012575085;
      doubleArray0[2] = 2475.012575085;
      doubleArray0[3] = 2475.012575085;
      doubleArray0[4] = 2475.012575085;
      SparseInstance sparseInstance0 = new SparseInstance(2475.012575085, doubleArray0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(sparseInstance0);
      assertEquals(4, sparseInstance0.numValues());
      assertEquals(5, sparseInstance0.numAttributes());
      assertEquals(2475.012575085, sparseInstance0.weight(), 0.01);
      assertEquals(5, doubleArray0.length);
      assertArrayEquals(new double[] {2475.012575085, 0.0, 2475.012575085, 2475.012575085, 2475.012575085}, doubleArray0, 0.01);
      
      SparseInstance sparseInstance1 = new SparseInstance(sparseInstance0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(sparseInstance1);
      assertEquals(4, sparseInstance0.numValues());
      assertEquals(5, sparseInstance0.numAttributes());
      assertEquals(2475.012575085, sparseInstance0.weight(), 0.01);
      assertEquals(2475.012575085, sparseInstance1.weight(), 0.01);
      assertEquals(5, sparseInstance1.numAttributes());
      assertEquals(4, sparseInstance1.numValues());
      assertFalse(sparseInstance1.equals((Object)sparseInstance0));
      assertEquals(5, doubleArray0.length);
      assertArrayEquals(new double[] {2475.012575085, 0.0, 2475.012575085, 2475.012575085, 2475.012575085}, doubleArray0, 0.01);
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      
      evaluation0.setDiscardPredictions(true);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertTrue(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      
      double double0 = evaluation0.coverageOfTestCasesByPredictedRegions();
      assertEquals(Double.NaN, double0, 0.01);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertTrue(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      assertNotNull(serializedClassifier0);
      assertEquals("If set to true, classifier may output additional info to the console.", serializedClassifier0.debugTipText());
      assertFalse(serializedClassifier0.getDebug());
      assertEquals("A wrapper around a serialized classifier model. This classifier loads a serialized models and uses it to make predictions.\n\nWarning: since the serialized model doesn't get changed, cross-validation cannot bet used with this classifier.", serializedClassifier0.globalInfo());
      assertEquals("The serialized classifier model to use for predictions.", serializedClassifier0.modelFileTipText());
      
      Classifier classifier0 = serializedClassifier0.getCurrentModel();
      assertNull(classifier0);
      assertEquals("If set to true, classifier may output additional info to the console.", serializedClassifier0.debugTipText());
      assertFalse(serializedClassifier0.getDebug());
      assertEquals("A wrapper around a serialized classifier model. This classifier loads a serialized models and uses it to make predictions.\n\nWarning: since the serialized model doesn't get changed, cross-validation cannot bet used with this classifier.", serializedClassifier0.globalInfo());
      assertEquals("The serialized classifier model to use for predictions.", serializedClassifier0.modelFileTipText());
      
      byte[] byteArray0 = new byte[8];
      byteArray0[0] = (byte)93;
      byteArray0[1] = (byte) (-9);
      byteArray0[2] = (byte)41;
      byteArray0[3] = (byte)115;
      byteArray0[4] = (byte)93;
      byteArray0[5] = (byte) (-39);
      byteArray0[6] = (byte) (-96);
      boolean boolean0 = FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      assertFalse(boolean0);
      assertEquals(8, byteArray0.length);
      assertArrayEquals(new byte[] {(byte)93, (byte) (-9), (byte)41, (byte)115, (byte)93, (byte) (-39), (byte) (-96), (byte)0}, byteArray0);
      
      ArffLoader arffLoader0 = new ArffLoader();
      assertNotNull(arffLoader0);
      assertEquals("Use relative rather than absolute paths", arffLoader0.useRelativePathTipText());
      assertEquals("Arff data files", arffLoader0.getFileDescription());
      assertFalse(arffLoader0.getUseRelativePath());
      assertEquals(".arff", arffLoader0.getFileExtension());
      assertEquals("Reads a source that is in arff (attribute relation file format) format. ", arffLoader0.globalInfo());
      assertEquals("http://", arffLoader0.retrieveURL());
      
      arffLoader0.setRetrieval((byte)41);
      assertEquals("Use relative rather than absolute paths", arffLoader0.useRelativePathTipText());
      assertEquals("Arff data files", arffLoader0.getFileDescription());
      assertFalse(arffLoader0.getUseRelativePath());
      assertEquals(".arff", arffLoader0.getFileExtension());
      assertEquals("Reads a source that is in arff (attribute relation file format) format. ", arffLoader0.globalInfo());
      assertEquals("http://", arffLoader0.retrieveURL());
      
      try { 
        arffLoader0.getDataSet();
        fail("Expecting exception: IOException");
      
      } catch(IOException e) {
         //
         // No source has been specified
         //
         verifyException("weka.core.converters.ArffLoader", e);
      }
  }

  /**
  //Test case number: 35
  /*Coverage entropy=-0.0
  */
  @Test(timeout = 4000)
  public void test035()  throws Throwable  {
      M5Rules m5Rules0 = new M5Rules();
      assertNotNull(m5Rules0);
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      
      Capabilities capabilities0 = m5Rules0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(4, instances0.numAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      assertNotNull(costSensitiveClassifier0);
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      
      testInstances0.setNumNominal(2);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getClassType());
      
      CostMatrix costMatrix0 = costSensitiveClassifier0.getCostMatrix();
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      assertNotNull(costMatrix0);
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals(1, costMatrix0.numRows());
      assertEquals(1, costMatrix0.size());
      assertEquals(1, costMatrix0.numColumns());
      
      Evaluation evaluation0 = null;
      try {
        evaluation0 = new Evaluation(instances0, costMatrix0);
        fail("Expecting exception: Exception");
      
      } catch(Throwable e) {
         //
         // Class has to be nominal if cost matrix given!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 36
  /*Coverage entropy=1.0986122886681096
  */
  @Test(timeout = 4000)
  public void test036()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      
      SGDText sGDText0 = new SGDText();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(sGDText0);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(capabilities0);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances1);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(5, testInstances1.getNumAttributes());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(1, testInstances1.getClassType());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(1, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertFalse(testInstances1.getNoClass());
      assertEquals(1, testInstances1.getNumString());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      
      Instances instances0 = testInstances1.generate();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(5, testInstances1.getNumAttributes());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(1, testInstances1.getClassType());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(1, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertFalse(testInstances1.getNoClass());
      assertEquals(1, testInstances1.getNumString());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(5, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(4, instances0.classIndex());
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(5, testInstances1.getNumAttributes());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(1, testInstances1.getClassType());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(1, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertFalse(testInstances1.getNoClass());
      assertEquals(1, testInstances1.getNumString());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(5, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(4, instances0.classIndex());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertFalse(testInstances1.equals((Object)testInstances0));
      
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      evaluation0.addNumericTrainClass((-1), (-2));
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(5, testInstances1.getNumAttributes());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(1, testInstances1.getClassType());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(1, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertFalse(testInstances1.getNoClass());
      assertEquals(1, testInstances1.getNumString());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(5, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(4, instances0.classIndex());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      
      evaluation0.addNumericTrainClass(10.0, Double.NaN);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(5, testInstances1.getNumAttributes());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(1, testInstances1.getClassType());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(1, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertFalse(testInstances1.getNoClass());
      assertEquals(1, testInstances1.getNumString());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(5, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(4, instances0.classIndex());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
  }

  /**
  //Test case number: 37
  /*Coverage entropy=1.6094379124341005
  */
  @Test(timeout = 4000)
  public void test037()  throws Throwable  {
      M5Rules m5Rules0 = new M5Rules();
      assertNotNull(m5Rules0);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      
      Capabilities capabilities0 = m5Rules0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(4, testInstances0.getNumAttributes());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(4, testInstances0.getNumAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(4, instances0.numAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(4, testInstances0.getNumAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(4, instances0.numAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      try { 
        evaluation0.KBRelativeInformation();
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't compute K&B Info score: class numeric!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 38
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test038()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      
      String string0 = testInstances0.getRevision();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(string0);
      assertEquals("8034", string0);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      String string1 = evaluation0.getRevision();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(string1);
      assertEquals("9101", string1);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(string1.equals((Object)string0));
      
      CSVLoader cSVLoader0 = new CSVLoader();
      assertNotNull(cSVLoader0);
      assertEquals("The format to use for parsing date values.", cSVLoader0.dateFormatTipText());
      assertEquals("\",'", cSVLoader0.getEnclosureCharacters());
      assertEquals("The characters to use as enclosures for strings. E.g. \",'", cSVLoader0.enclosureCharactersTipText());
      assertEquals(".csv", cSVLoader0.getFileExtension());
      assertEquals("The range of attributes to force to be of type STRING, example ranges: 'first-last', '1,4,7-14,50-last'.", cSVLoader0.stringAttributesTipText());
      assertEquals("CSV data files", cSVLoader0.getFileDescription());
      assertEquals("The placeholder for missing values, default is '?'.", cSVLoader0.missingValueTipText());
      assertEquals("Use relative rather than absolute paths", cSVLoader0.useRelativePathTipText());
      assertFalse(cSVLoader0.getUseRelativePath());
      assertEquals("The range of attributes to force to be of type NOMINAL, example ranges: 'first-last', '1,4,7-14,50-last'.", cSVLoader0.nominalAttributesTipText());
      assertEquals("The character to use as separator for the columns/fields (use '\\t' for TAB).", cSVLoader0.fieldSeparatorTipText());
      assertEquals("?", cSVLoader0.getMissingValue());
      assertEquals("", cSVLoader0.getDateFormat());
      assertEquals("Reads a source that is in comma separated format (the default). One can also change the column separator from comma to tab or another character. Assumes that the first row in the file determines the number of and names of the attributes.", cSVLoader0.globalInfo());
      assertEquals("First row of data does not contain attribute names", cSVLoader0.noHeaderRowPresentTipText());
      assertEquals("The range of attributes to force to type STRING, example ranges: 'first-last', '1,4,7-14, 50-last'.", cSVLoader0.dateAttributesTipText());
      assertFalse(cSVLoader0.getNoHeaderRowPresent());
      
      CSVLoader cSVLoader1 = new CSVLoader();
      assertNotNull(cSVLoader1);
      assertEquals("The character to use as separator for the columns/fields (use '\\t' for TAB).", cSVLoader1.fieldSeparatorTipText());
      assertEquals(".csv", cSVLoader1.getFileExtension());
      assertEquals("The placeholder for missing values, default is '?'.", cSVLoader1.missingValueTipText());
      assertEquals("CSV data files", cSVLoader1.getFileDescription());
      assertEquals("Use relative rather than absolute paths", cSVLoader1.useRelativePathTipText());
      assertEquals("The characters to use as enclosures for strings. E.g. \",'", cSVLoader1.enclosureCharactersTipText());
      assertEquals("The format to use for parsing date values.", cSVLoader1.dateFormatTipText());
      assertEquals("", cSVLoader1.getDateFormat());
      assertEquals("Reads a source that is in comma separated format (the default). One can also change the column separator from comma to tab or another character. Assumes that the first row in the file determines the number of and names of the attributes.", cSVLoader1.globalInfo());
      assertEquals("\",'", cSVLoader1.getEnclosureCharacters());
      assertFalse(cSVLoader1.getUseRelativePath());
      assertEquals("?", cSVLoader1.getMissingValue());
      assertEquals("The range of attributes to force to type STRING, example ranges: 'first-last', '1,4,7-14, 50-last'.", cSVLoader1.dateAttributesTipText());
      assertEquals("First row of data does not contain attribute names", cSVLoader1.noHeaderRowPresentTipText());
      assertEquals("The range of attributes to force to be of type NOMINAL, example ranges: 'first-last', '1,4,7-14,50-last'.", cSVLoader1.nominalAttributesTipText());
      assertFalse(cSVLoader1.getNoHeaderRowPresent());
      assertEquals("The range of attributes to force to be of type STRING, example ranges: 'first-last', '1,4,7-14,50-last'.", cSVLoader1.stringAttributesTipText());
      assertFalse(cSVLoader1.equals((Object)cSVLoader0));
      
      try { 
        cSVLoader1.getStructure();
        fail("Expecting exception: IOException");
      
      } catch(IOException e) {
         //
         // No source has been specified
         //
         verifyException("weka.core.converters.CSVLoader", e);
      }
  }

  /**
  //Test case number: 39
  /*Coverage entropy=1.6094379124341005
  */
  @Test(timeout = 4000)
  public void test039()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      
      SGDText sGDText0 = new SGDText();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(sGDText0);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(capabilities0);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances1);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(testInstances1.getNoClass());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(1, testInstances1.getClassType());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(5, testInstances1.getNumAttributes());
      assertEquals(1, testInstances1.getNumString());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(1, testInstances1.getNumRelationalString());
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      
      Instances instances1 = testInstances1.generate();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances1);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(testInstances1.getNoClass());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(1, testInstances1.getClassType());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(5, testInstances1.getNumAttributes());
      assertEquals(1, testInstances1.getNumString());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(1, testInstances1.getNumRelationalString());
      assertEquals(4, instances1.classIndex());
      assertEquals(20, instances1.numInstances());
      assertEquals(5, instances1.numAttributes());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(20, instances1.size());
      assertEquals("Testdata", instances1.relationName());
      assertTrue(instances1.checkForStringAttributes());
      assertEquals(2, instances1.numClasses());
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(testInstances1, testInstances0);
      assertNotSame(instances1, instances0);
      
      Instances instances2 = testInstances1.generate(".bsi");
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances2);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(testInstances1.getNoClass());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(1, testInstances1.getClassType());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(5, testInstances1.getNumAttributes());
      assertEquals(1, testInstances1.getNumString());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(1, testInstances1.getNumRelationalString());
      assertEquals(4, instances2.classIndex());
      assertEquals(20, instances2.numInstances());
      assertEquals(20, instances2.size());
      assertEquals("Testdata", instances2.relationName());
      assertEquals(2, instances2.numClasses());
      assertEquals(20.0, instances2.sumOfWeights(), 0.01);
      assertTrue(instances2.checkForStringAttributes());
      assertEquals(5, instances2.numAttributes());
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertFalse(instances2.equals((Object)instances1));
      assertFalse(instances2.equals((Object)instances0));
      assertNotSame(testInstances1, testInstances0);
      assertNotSame(instances2, instances1);
      assertNotSame(instances2, instances0);
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(testInstances0.equals((Object)testInstances1));
      assertFalse(instances0.equals((Object)instances2));
      assertFalse(instances0.equals((Object)instances1));
      
      String string0 = evaluation0.toSummaryString();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(string0);
      assertEquals("\nTotal Number of Instances                0     \n", string0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(testInstances0.equals((Object)testInstances1));
      assertFalse(instances0.equals((Object)instances2));
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(testInstances0, testInstances1);
      assertNotSame(instances0, instances2);
      assertNotSame(instances0, instances1);
  }

  /**
  //Test case number: 40
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test040()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      
      MockRandom mockRandom0 = new MockRandom((-3228L));
      assertNotNull(mockRandom0);
      
      try { 
        evaluation0.crossValidateModel("globalInfo", instances0, 42, testInstances0.DEFAULT_WORDS, (java.util.Random) mockRandom0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't find class called: globalInfo
         //
         verifyException("weka.core.Utils", e);
      }
  }

  /**
  //Test case number: 41
  /*Coverage entropy=1.0986122886681096
  */
  @Test(timeout = 4000)
  public void test041()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      
      Instances instances0 = textDirectoryLoader0.getStructure();
      assertNotNull(instances0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      
      Puk puk0 = new Puk();
      assertNotNull(puk0);
      assertEquals(1.0, puk0.getOmega(), 0.01);
      assertEquals(0, puk0.numEvals());
      assertEquals(1.0, puk0.getSigma(), 0.01);
      assertFalse(puk0.getDebug());
      assertEquals("The size of the cache (a prime number), 0 for full cache and -1 to turn it off.", puk0.cacheSizeTipText());
      assertEquals("Puk kernel", puk0.toString());
      assertEquals("The Sigma value.", puk0.sigmaTipText());
      assertEquals("Turns on the output of debugging information.", puk0.debugTipText());
      assertFalse(puk0.getChecksTurnedOff());
      assertEquals("Turns time-consuming checks off - use with caution.", puk0.checksTurnedOffTipText());
      assertEquals(0, puk0.numCacheHits());
      assertEquals(250007, puk0.getCacheSize());
      assertEquals("The Omega value.", puk0.omegaTipText());
      
      Capabilities capabilities0 = puk0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals(1.0, puk0.getOmega(), 0.01);
      assertEquals(0, puk0.numEvals());
      assertEquals(1.0, puk0.getSigma(), 0.01);
      assertFalse(puk0.getDebug());
      assertEquals("The size of the cache (a prime number), 0 for full cache and -1 to turn it off.", puk0.cacheSizeTipText());
      assertEquals("Puk kernel", puk0.toString());
      assertEquals("The Sigma value.", puk0.sigmaTipText());
      assertEquals("Turns on the output of debugging information.", puk0.debugTipText());
      assertFalse(puk0.getChecksTurnedOff());
      assertEquals("Turns time-consuming checks off - use with caution.", puk0.checksTurnedOffTipText());
      assertEquals(0, puk0.numCacheHits());
      assertEquals(250007, puk0.getCacheSize());
      assertEquals("The Omega value.", puk0.omegaTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals(1.0, puk0.getOmega(), 0.01);
      assertEquals(0, puk0.numEvals());
      assertEquals(1.0, puk0.getSigma(), 0.01);
      assertFalse(puk0.getDebug());
      assertEquals("The size of the cache (a prime number), 0 for full cache and -1 to turn it off.", puk0.cacheSizeTipText());
      assertEquals("Puk kernel", puk0.toString());
      assertEquals("The Sigma value.", puk0.sigmaTipText());
      assertEquals("Turns on the output of debugging information.", puk0.debugTipText());
      assertFalse(puk0.getChecksTurnedOff());
      assertEquals("Turns time-consuming checks off - use with caution.", puk0.checksTurnedOffTipText());
      assertEquals(0, puk0.numCacheHits());
      assertEquals(250007, puk0.getCacheSize());
      assertEquals("The Omega value.", puk0.omegaTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      
      Instances instances1 = testInstances0.generate("@relation");
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances1);
      assertEquals(1.0, puk0.getOmega(), 0.01);
      assertEquals(0, puk0.numEvals());
      assertEquals(1.0, puk0.getSigma(), 0.01);
      assertFalse(puk0.getDebug());
      assertEquals("The size of the cache (a prime number), 0 for full cache and -1 to turn it off.", puk0.cacheSizeTipText());
      assertEquals("Puk kernel", puk0.toString());
      assertEquals("The Sigma value.", puk0.sigmaTipText());
      assertEquals("Turns on the output of debugging information.", puk0.debugTipText());
      assertFalse(puk0.getChecksTurnedOff());
      assertEquals("Turns time-consuming checks off - use with caution.", puk0.checksTurnedOffTipText());
      assertEquals(0, puk0.numCacheHits());
      assertEquals(250007, puk0.getCacheSize());
      assertEquals("The Omega value.", puk0.omegaTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, instances1.size());
      assertEquals(1, instances1.classIndex());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(4, instances1.numClasses());
      assertEquals(2, instances1.numAttributes());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(20, instances1.numInstances());
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(instances1, instances0);
      
      Evaluation evaluation0 = new Evaluation(instances1, (CostMatrix) null);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals(1.0, puk0.getOmega(), 0.01);
      assertEquals(0, puk0.numEvals());
      assertEquals(1.0, puk0.getSigma(), 0.01);
      assertFalse(puk0.getDebug());
      assertEquals("The size of the cache (a prime number), 0 for full cache and -1 to turn it off.", puk0.cacheSizeTipText());
      assertEquals("Puk kernel", puk0.toString());
      assertEquals("The Sigma value.", puk0.sigmaTipText());
      assertEquals("Turns on the output of debugging information.", puk0.debugTipText());
      assertFalse(puk0.getChecksTurnedOff());
      assertEquals("Turns time-consuming checks off - use with caution.", puk0.checksTurnedOffTipText());
      assertEquals(0, puk0.numCacheHits());
      assertEquals(250007, puk0.getCacheSize());
      assertEquals("The Omega value.", puk0.omegaTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, instances1.size());
      assertEquals(1, instances1.classIndex());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(4, instances1.numClasses());
      assertEquals(2, instances1.numAttributes());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(20, instances1.numInstances());
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertFalse(instances1.equals((Object)instances0));
      
      MockRandom mockRandom0 = new MockRandom((-1L));
      assertNotNull(mockRandom0);
      
      GaussianProcesses gaussianProcesses0 = new GaussianProcesses();
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertNotNull(gaussianProcesses0);
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      
      try { 
        evaluation0.crossValidateModel((Classifier) gaussianProcesses0, instances1, 2, (java.util.Random) mockRandom0, (Object[]) gaussianProcesses0.TAGS_FILTER);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // weka.core.Tag cannot be cast to weka.classifiers.evaluation.output.prediction.AbstractOutput
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 42
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test042()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      
      Instances instances0 = textDirectoryLoader0.getStructure();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      
      double[] doubleArray0 = new double[2];
      evaluation0.m_SumSchemeEntropy = (double) 294;
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.POSITIVE_INFINITY, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(294.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NEGATIVE_INFINITY, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals((-294.0), evaluation0.SFEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      
      doubleArray0[0] = (double) 294;
      int[] intArray0 = new int[2];
      intArray0[1] = 294;
      SparseInstance sparseInstance0 = new SparseInstance(294, doubleArray0, intArray0, 294);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(sparseInstance0);
      assertEquals(294.0, sparseInstance0.weight(), 0.01);
      assertEquals(1, sparseInstance0.numValues());
      assertEquals(294, sparseInstance0.numAttributes());
      assertEquals(2, doubleArray0.length);
      assertEquals(2, intArray0.length);
      assertArrayEquals(new double[] {294.0, 0.0}, doubleArray0, 0.01);
      assertArrayEquals(new int[] {0, 294}, intArray0);
      
      boolean boolean0 = instances0.add((Instance) sparseInstance0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertTrue(boolean0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(1, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(294.0, instances0.sumOfWeights(), 0.01);
      assertEquals(294.0, sparseInstance0.weight(), 0.01);
      assertEquals(1, sparseInstance0.numValues());
      assertEquals(294, sparseInstance0.numAttributes());
      assertEquals(2, doubleArray0.length);
      assertEquals(2, intArray0.length);
      assertArrayEquals(new double[] {294.0, 0.0}, doubleArray0, 0.01);
      assertArrayEquals(new int[] {0, 294}, intArray0);
      
      double double0 = evaluation0.m_ClassPriorsSum;
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.m_SumClass;
      assertEquals(0.0, double1, 0.01);
      assertEquals(double1, double0, 0.01);
      
      Instances instances1 = evaluation0.getHeader();
      assertNotNull(instances1);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(1, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(294.0, instances0.sumOfWeights(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.POSITIVE_INFINITY, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(294.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NEGATIVE_INFINITY, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals((-294.0), evaluation0.SFEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, instances1.sumOfWeights(), 0.01);
      assertEquals(0, instances1.size());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances1.relationName());
      assertEquals(1, instances1.classIndex());
      assertEquals(0, instances1.numClasses());
      assertEquals(0, instances1.numInstances());
      assertEquals(2, instances1.numAttributes());
      assertTrue(instances1.checkForStringAttributes());
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(instances0, instances1);
      assertNotSame(instances1, instances0);
  }

  /**
  //Test case number: 43
  /*Coverage entropy=1.7917594692280547
  */
  @Test(timeout = 4000)
  public void test043()  throws Throwable  {
      CostMatrix costMatrix0 = Evaluation.handleCostOption("", (-2286));
      assertNull(costMatrix0);
      
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      double double0 = evaluation0.weightedFalsePositiveRate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      try { 
        Evaluation.getGlobalInfo((Classifier) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 44
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test044()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      
      double double0 = evaluation0.pctCorrect();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  /**
  //Test case number: 45
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test045()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      
      SGDText sGDText0 = new SGDText();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(sGDText0);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      
      Enumeration enumeration0 = testInstances0.listOptions();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(enumeration0);
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(capabilities0);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      
      Object[] objectArray0 = new Object[4];
      objectArray0[0] = (Object) null;
      Object object0 = new Object();
      assertNotNull(object0);
      
      objectArray0[2] = (Object) evaluation0;
      try { 
        evaluation0.evaluateModelOnce((Classifier) sGDText0, (Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 46
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test046()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      
      SGDText sGDText0 = new SGDText();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(sGDText0);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(capabilities0);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      
      boolean boolean0 = FileSystemHandling.setPermissions((EvoSuiteFile) null, false, false, false);
      assertFalse(boolean0);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation1);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertTrue(evaluation1.equals((Object)evaluation0));
      
      double double0 = evaluation0.correct();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0.0, double0, 0.01);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotSame(evaluation0, evaluation1);
      
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      
      Instances instances1 = new Instances(instances0, 1, (-1));
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances1);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, instances1.sumOfWeights(), 0.01);
      assertEquals(0, instances1.size());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(1, instances1.classIndex());
      assertEquals(2, instances1.numAttributes());
      assertEquals(0, instances1.numInstances());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(2, instances1.numClasses());
      assertFalse(instances1.equals((Object)instances0));
      
      Evaluation evaluation2 = new Evaluation(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation2);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation2.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation2.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation2.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation2.errorRate(), 0.01);
      assertEquals(0.0, evaluation2.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation2.avgCost(), 0.01);
      assertEquals(0.0, evaluation2.numInstances(), 0.01);
      assertEquals(0.0, evaluation2.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation2.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation2.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation2.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation2.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation2.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation2.kappa(), 0.01);
      assertEquals(0.0, evaluation2.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation2.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation2.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation2.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation2.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation2.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation2.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation2.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation2.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation2.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation2.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation2.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation2.correct(), 0.01);
      assertFalse(evaluation2.getDiscardPredictions());
      assertFalse(instances0.equals((Object)instances1));
      assertTrue(evaluation2.equals((Object)evaluation0));
      assertTrue(evaluation2.equals((Object)evaluation1));
  }

  /**
  //Test case number: 47
  /*Coverage entropy=1.7917594692280547
  */
  @Test(timeout = 4000)
  public void test047()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getStructure();
      assertNotNull(instances0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      
      Instances instances1 = textDirectoryLoader0.getStructure();
      assertNotNull(instances1);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances1.relationName());
      assertEquals(0, instances1.numClasses());
      assertEquals(0.0, instances1.sumOfWeights(), 0.01);
      assertTrue(instances1.checkForStringAttributes());
      assertEquals(1, instances1.classIndex());
      assertEquals(0, instances1.numInstances());
      assertEquals(2, instances1.numAttributes());
      assertEquals(0, instances1.size());
      assertSame(instances1, instances0);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      double double0 = evaluation0.SFMeanSchemeEntropy();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertSame(instances0, instances1);
      
      double[][] doubleArray0 = evaluation0.confusionMatrix();
      assertNotNull(doubleArray0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertSame(instances0, instances1);
      assertEquals(0, doubleArray0.length);
      
      double double1 = evaluation0.SFPriorEntropy();
      assertEquals(0.0, double1, 0.01);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertNotEquals(double1, double0, 0.01);
      assertSame(instances0, instances1);
  }

  /**
  //Test case number: 48
  /*Coverage entropy=2.936495865746711
  */
  @Test(timeout = 4000)
  public void test048()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      
      double double0 = evaluation0.m_Correct;
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.kappa();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(1.0, double1, 0.01);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertNotEquals(double1, double0, 0.01);
      
      double double2 = evaluation0.priorEntropy();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0.9940302114769565, double2, 0.01);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(double2, double1, 0.01);
      assertNotEquals(double2, double0, 0.01);
      
      String string0 = evaluation0.toClassDetailsString("b?F[/!");
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(string0);
      assertEquals("b?F[/!\n                 TP Rate  FP Rate  Precision  Recall  F-Measure  MCC    ROC Area  PRC Area  Class\n                 0        0        0          0       0          0     ?         ?         class1\n                 0        0        0          0       0          0     ?         ?         class2\nWeighted Avg.  NaN      NaN      NaN        NaN     NaN        NaN    NaN       NaN    \n", string0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
  }

  /**
  //Test case number: 49
  /*Coverage entropy=1.985053187904615
  */
  @Test(timeout = 4000)
  public void test049()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(sGDText0);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(capabilities0);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      
      capabilities0.enableAll();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      Instances instances0 = testInstances0.generate();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(4, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(5, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(4, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(5, instances0.numAttributes());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      
      String string0 = instances0.getRevision();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(string0);
      assertEquals("9186", string0);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(4, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(5, instances0.numAttributes());
      
      Instances instances1 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances1);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances1.relationName());
      assertEquals(0, instances1.numInstances());
      assertEquals(0.0, instances1.sumOfWeights(), 0.01);
      assertEquals(0, instances1.size());
      assertEquals(2, instances1.numAttributes());
      assertTrue(instances1.checkForStringAttributes());
      assertEquals(1, instances1.classIndex());
      assertEquals(0, instances1.numClasses());
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(instances1, instances0);
      
      double double0 = evaluation0.rootRelativeSquaredError();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(4, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(5, instances0.numAttributes());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      
      System.setCurrentTimeMillis((-1));
      double double1 = evaluation0.matthewsCorrelationCoefficient((-2));
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0.0, double1, 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(4, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(5, instances0.numAttributes());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertNotEquals(double1, double0, 0.01);
      assertNotSame(instances0, instances1);
  }

  /**
  //Test case number: 50
  /*Coverage entropy=2.013805893852347
  */
  @Test(timeout = 4000)
  public void test050()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(sGDText0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(capabilities0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(5, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      
      capabilities0.enableAll();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(5, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(5, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      
      Instances instances1 = testInstances0.generate();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances1);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(5, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, instances1.numClasses());
      assertEquals(4, instances1.classIndex());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(20, instances1.numInstances());
      assertTrue(instances1.checkForStringAttributes());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(20, instances1.size());
      assertEquals(5, instances1.numAttributes());
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(instances1, instances0);
      
      double[] doubleArray0 = new double[0];
      double double0 = evaluation0.KBInformation();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0.0, double0, 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(5, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      
      SparseInstance sparseInstance0 = new SparseInstance(9);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(sparseInstance0);
      assertEquals(9, sparseInstance0.numAttributes());
      assertEquals(9, sparseInstance0.numValues());
      assertEquals(1.0, sparseInstance0.weight(), 0.01);
      
      boolean boolean0 = sparseInstance0.isMissing((-2));
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertFalse(boolean0);
      assertEquals(9, sparseInstance0.numAttributes());
      assertEquals(9, sparseInstance0.numValues());
      assertEquals(1.0, sparseInstance0.weight(), 0.01);
      
      double double1 = evaluation0.weightedMatthewsCorrelation();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double1, 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(5, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertNotEquals(double1, double0, 0.01);
      assertNotSame(instances0, instances1);
      
      try { 
        evaluation0.evaluationForSingleInstance(doubleArray0, sparseInstance0, false);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 0
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 51
  /*Coverage entropy=1.499030672979008
  */
  @Test(timeout = 4000)
  public void test051()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getStructure();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      
      String string0 = textDirectoryLoader0.getRevision();
      assertNotNull(string0);
      assertEquals("8034", string0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      boolean boolean0 = FileSystemHandling.shouldAllThrowIOExceptions();
      assertTrue(boolean0);
      
      LogitBoost logitBoost0 = new LogitBoost();
      assertNotNull(logitBoost0);
      assertFalse(logitBoost0.getDebug());
      assertEquals("Number of runs for internal cross-validation.", logitBoost0.numRunsTipText());
      assertEquals(1.0, logitBoost0.getShrinkage(), 0.01);
      assertEquals("The number of iterations to be performed.", logitBoost0.numIterationsTipText());
      assertEquals("Weight threshold for weight pruning (reduce to 90 for speeding up learning process).", logitBoost0.weightThresholdTipText());
      assertEquals(100, logitBoost0.getWeightThreshold());
      assertEquals((-1.7976931348623157E308), logitBoost0.getLikelihoodThreshold(), 0.01);
      assertEquals("Shrinkage parameter (use small value like 0.1 to reduce overfitting).", logitBoost0.shrinkageTipText());
      assertEquals("Number of folds for internal cross-validation (default 0 means no cross-validation is performed).", logitBoost0.numFoldsTipText());
      assertEquals("The random number seed to be used.", logitBoost0.seedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", logitBoost0.debugTipText());
      assertEquals("Threshold on improvement in likelihood.", logitBoost0.likelihoodThresholdTipText());
      assertEquals(1, logitBoost0.getSeed());
      assertEquals("The base classifier to be used.", logitBoost0.classifierTipText());
      assertFalse(logitBoost0.getUseResampling());
      assertEquals(1, logitBoost0.getNumRuns());
      assertEquals(10, logitBoost0.getNumIterations());
      assertEquals("Whether resampling is used instead of reweighting.", logitBoost0.useResamplingTipText());
      assertEquals(0, logitBoost0.getNumFolds());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      
      int int0 = 475;
      Object[] objectArray0 = new Object[0];
      double[] doubleArray0 = evaluation0.m_TrainClassVals;
      assertNull(doubleArray0);
      
      String string1 = logitBoost0.getRevision();
      assertNotNull(string1);
      assertEquals("9186", string1);
      assertFalse(logitBoost0.getDebug());
      assertEquals("Number of runs for internal cross-validation.", logitBoost0.numRunsTipText());
      assertEquals(1.0, logitBoost0.getShrinkage(), 0.01);
      assertEquals("The number of iterations to be performed.", logitBoost0.numIterationsTipText());
      assertEquals("Weight threshold for weight pruning (reduce to 90 for speeding up learning process).", logitBoost0.weightThresholdTipText());
      assertEquals(100, logitBoost0.getWeightThreshold());
      assertEquals((-1.7976931348623157E308), logitBoost0.getLikelihoodThreshold(), 0.01);
      assertEquals("Shrinkage parameter (use small value like 0.1 to reduce overfitting).", logitBoost0.shrinkageTipText());
      assertEquals("Number of folds for internal cross-validation (default 0 means no cross-validation is performed).", logitBoost0.numFoldsTipText());
      assertEquals("The random number seed to be used.", logitBoost0.seedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", logitBoost0.debugTipText());
      assertEquals("Threshold on improvement in likelihood.", logitBoost0.likelihoodThresholdTipText());
      assertEquals(1, logitBoost0.getSeed());
      assertEquals("The base classifier to be used.", logitBoost0.classifierTipText());
      assertFalse(logitBoost0.getUseResampling());
      assertEquals(1, logitBoost0.getNumRuns());
      assertEquals(10, logitBoost0.getNumIterations());
      assertEquals("Whether resampling is used instead of reweighting.", logitBoost0.useResamplingTipText());
      assertEquals(0, logitBoost0.getNumFolds());
      assertFalse(string1.equals((Object)string0));
      
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      double double0 = evaluation0.weightedMatthewsCorrelation();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      
      try { 
        evaluation0.crossValidateModel((Classifier) logitBoost0, instances0, 475, (java.util.Random) mockRandom0, objectArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Can't have more folds than instances!
         //
         verifyException("weka.core.Instances", e);
      }
  }

  /**
  //Test case number: 52
  /*Coverage entropy=1.7917594692280547
  */
  @Test(timeout = 4000)
  public void test052()  throws Throwable  {
      CostMatrix costMatrix0 = Evaluation.handleCostOption("", (-2268));
      assertNull(costMatrix0);
      
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance(2475.012575085, doubleArray0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(sparseInstance0);
      assertEquals(0, sparseInstance0.numValues());
      assertEquals(0, sparseInstance0.numAttributes());
      assertEquals(2475.012575085, sparseInstance0.weight(), 0.01);
      assertEquals(0, doubleArray0.length);
      assertArrayEquals(new double[] {}, doubleArray0, 0.01);
      
      double double0 = evaluation0.SFMeanSchemeEntropy();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      
      double[][] doubleArray1 = evaluation0.confusionMatrix();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(doubleArray1);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(2, doubleArray1.length);
      
      double double1 = evaluation0.SFPriorEntropy();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0.0, double1, 0.01);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertNotEquals(double1, double0, 0.01);
  }

  /**
  //Test case number: 53
  /*Coverage entropy=1.6094379124341005
  */
  @Test(timeout = 4000)
  public void test053()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      
      SGDText sGDText0 = new SGDText();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(sGDText0);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(capabilities0);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances1);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(1, testInstances1.getSeed());
      assertEquals((-1), testInstances1.getClassIndex());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(1, testInstances1.getNumString());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(1, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(1, testInstances1.getNumNumeric());
      assertFalse(testInstances1.getNoClass());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(5, testInstances1.getNumAttributes());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(1, testInstances1.getClassType());
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      
      Instances instances1 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances1);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, instances1.numAttributes());
      assertEquals(20, instances1.numInstances());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(20, instances1.size());
      assertEquals(1, instances1.classIndex());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(2, instances1.numClasses());
      assertFalse(testInstances0.equals((Object)testInstances1));
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(testInstances0, testInstances1);
      assertNotSame(instances1, instances0);
      
      TestInstances testInstances2 = TestInstances.forCapabilities(capabilities0);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances2);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances2.getNumRelationalNominal());
      assertEquals(1, testInstances2.getClassType());
      assertEquals((-1), testInstances2.getClassIndex());
      assertEquals(5, testInstances2.getNumAttributes());
      assertEquals(1, testInstances2.getSeed());
      assertEquals(1, testInstances2.getNumRelationalString());
      assertEquals(1, testInstances2.getNumNumeric());
      assertEquals(1, testInstances2.getNumString());
      assertEquals(1, testInstances2.getNumRelationalNumeric());
      assertEquals(2, testInstances2.getNumRelationalNominalValues());
      assertFalse(testInstances2.getMultiInstance());
      assertEquals(10, testInstances2.getNumInstancesRelational());
      assertFalse(testInstances2.getNoClass());
      assertEquals(1, testInstances2.getNumDate());
      assertEquals(2, testInstances2.getNumClasses());
      assertEquals(1, testInstances2.getNumNominal());
      assertEquals(2, testInstances2.getNumNominalValues());
      assertEquals(20, testInstances2.getNumInstances());
      assertEquals(0, testInstances2.getNumRelational());
      assertEquals(1, testInstances2.getNumRelationalDate());
      assertEquals("Testdata", testInstances2.getRelation());
      assertEquals(" ", testInstances2.getWordSeparators());
      assertFalse(testInstances2.equals((Object)testInstances0));
      assertFalse(testInstances2.equals((Object)testInstances1));
      assertNotSame(testInstances2, testInstances0);
      assertNotSame(testInstances2, testInstances1);
      
      testInstances2.setNumRelationalNumeric(22);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances2.getNumRelationalNominal());
      assertEquals(1, testInstances2.getClassType());
      assertEquals((-1), testInstances2.getClassIndex());
      assertEquals(5, testInstances2.getNumAttributes());
      assertEquals(22, testInstances2.getNumRelationalNumeric());
      assertEquals(1, testInstances2.getSeed());
      assertEquals(1, testInstances2.getNumRelationalString());
      assertEquals(1, testInstances2.getNumNumeric());
      assertEquals(1, testInstances2.getNumString());
      assertEquals(2, testInstances2.getNumRelationalNominalValues());
      assertFalse(testInstances2.getMultiInstance());
      assertEquals(10, testInstances2.getNumInstancesRelational());
      assertFalse(testInstances2.getNoClass());
      assertEquals(1, testInstances2.getNumDate());
      assertEquals(2, testInstances2.getNumClasses());
      assertEquals(1, testInstances2.getNumNominal());
      assertEquals(2, testInstances2.getNumNominalValues());
      assertEquals(20, testInstances2.getNumInstances());
      assertEquals(0, testInstances2.getNumRelational());
      assertEquals(1, testInstances2.getNumRelationalDate());
      assertEquals("Testdata", testInstances2.getRelation());
      assertEquals(" ", testInstances2.getWordSeparators());
      assertFalse(testInstances2.equals((Object)testInstances0));
      assertFalse(testInstances2.equals((Object)testInstances1));
      assertNotSame(testInstances2, testInstances0);
      assertNotSame(testInstances2, testInstances1);
      
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = (double) 1;
      doubleArray0[1] = (double) 22;
      doubleArray0[2] = (double) (-1);
      doubleArray0[3] = (double) (-2);
      SparseInstance sparseInstance0 = new SparseInstance((-2), doubleArray0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(sparseInstance0);
      assertEquals(4, sparseInstance0.numAttributes());
      assertEquals((-2.0), sparseInstance0.weight(), 0.01);
      assertEquals(4, sparseInstance0.numValues());
      assertEquals(4, doubleArray0.length);
      assertArrayEquals(new double[] {1.0, 22.0, (-1.0), (-2.0)}, doubleArray0, 0.01);
      
      Evaluation evaluation0 = new Evaluation(instances1);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, instances1.numAttributes());
      assertEquals(20, instances1.numInstances());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(20, instances1.size());
      assertEquals(1, instances1.classIndex());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(2, instances1.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertFalse(testInstances0.equals((Object)testInstances2));
      assertFalse(testInstances0.equals((Object)testInstances1));
      assertFalse(instances1.equals((Object)instances0));
      
      double double0 = evaluation0.weightedFalseNegativeRate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, instances1.numAttributes());
      assertEquals(20, instances1.numInstances());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(20, instances1.size());
      assertEquals(1, instances1.classIndex());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(2, instances1.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertFalse(testInstances0.equals((Object)testInstances2));
      assertFalse(testInstances0.equals((Object)testInstances1));
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(testInstances0, testInstances2);
      assertNotSame(testInstances0, testInstances1);
      assertNotSame(instances1, instances0);
  }

  /**
  //Test case number: 54
  /*Coverage entropy=1.6094379124341005
  */
  @Test(timeout = 4000)
  public void test054()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      
      Instances instances0 = textDirectoryLoader0.getStructure();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      
      String string0 = textDirectoryLoader0.getRevision();
      assertNotNull(string0);
      assertEquals("8034", string0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      
      LogitBoost logitBoost0 = new LogitBoost();
      assertNotNull(logitBoost0);
      assertEquals(10, logitBoost0.getNumIterations());
      assertEquals("Number of runs for internal cross-validation.", logitBoost0.numRunsTipText());
      assertEquals(1.0, logitBoost0.getShrinkage(), 0.01);
      assertEquals("Weight threshold for weight pruning (reduce to 90 for speeding up learning process).", logitBoost0.weightThresholdTipText());
      assertFalse(logitBoost0.getDebug());
      assertEquals(100, logitBoost0.getWeightThreshold());
      assertEquals("The base classifier to be used.", logitBoost0.classifierTipText());
      assertEquals("Number of folds for internal cross-validation (default 0 means no cross-validation is performed).", logitBoost0.numFoldsTipText());
      assertEquals("Shrinkage parameter (use small value like 0.1 to reduce overfitting).", logitBoost0.shrinkageTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", logitBoost0.debugTipText());
      assertEquals("The random number seed to be used.", logitBoost0.seedTipText());
      assertEquals(1, logitBoost0.getSeed());
      assertEquals("Threshold on improvement in likelihood.", logitBoost0.likelihoodThresholdTipText());
      assertEquals((-1.7976931348623157E308), logitBoost0.getLikelihoodThreshold(), 0.01);
      assertEquals("The number of iterations to be performed.", logitBoost0.numIterationsTipText());
      assertEquals(1, logitBoost0.getNumRuns());
      assertEquals(0, logitBoost0.getNumFolds());
      assertFalse(logitBoost0.getUseResampling());
      assertEquals("Whether resampling is used instead of reweighting.", logitBoost0.useResamplingTipText());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      double[] doubleArray0 = evaluation0.m_TrainClassVals;
      assertNull(doubleArray0);
      
      String string1 = evaluation0.toMatrixString();
      assertNotNull(string1);
      assertEquals("=== Confusion Matrix ===\n\n   <-- classified as\n", string1);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(string1.equals((Object)string0));
      
      MockRandom mockRandom0 = new MockRandom(0L);
      assertNotNull(mockRandom0);
      
      PipedReader pipedReader0 = new PipedReader();
      assertNotNull(pipedReader0);
      
      CostMatrix costMatrix0 = null;
      try {
        costMatrix0 = new CostMatrix(pipedReader0);
        fail("Expecting exception: IOException");
      
      } catch(Throwable e) {
         //
         // Pipe not connected
         //
         verifyException("java.io.PipedReader", e);
      }
  }

  /**
  //Test case number: 55
  /*Coverage entropy=1.6094379124341005
  */
  @Test(timeout = 4000)
  public void test055()  throws Throwable  {
      M5Rules m5Rules0 = new M5Rules();
      assertNotNull(m5Rules0);
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getUseUnsmoothed());
      
      Capabilities capabilities0 = m5Rules0.getCapabilities();
      assertNotNull(capabilities0);
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(4, instances0.numAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(4, instances0.numAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numClasses());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      try { 
        evaluation0.crossValidateModel((Classifier) m5Rules0, instances0, (-2), (java.util.Random) mockRandom0, (Object[]) testInstances0.DEFAULT_WORDS);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // java.lang.String cannot be cast to weka.classifiers.evaluation.output.prediction.AbstractOutput
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 56
  /*Coverage entropy=1.7917594692280547
  */
  @Test(timeout = 4000)
  public void test056()  throws Throwable  {
      M5Rules m5Rules0 = new M5Rules();
      assertNotNull(m5Rules0);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      
      Capabilities capabilities0 = m5Rules0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      Capabilities capabilities1 = m5Rules0.getCapabilities();
      assertNotNull(capabilities1);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals(1, capabilities1.getMinimumNumberInstances());
      assertFalse(capabilities1.hasDependencies());
      assertFalse(capabilities1.equals((Object)capabilities0));
      assertNotSame(capabilities1, capabilities0);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(capabilities0.equals((Object)capabilities1));
      assertNotSame(capabilities0, capabilities1);
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(3, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(4, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertFalse(capabilities0.equals((Object)capabilities1));
      assertNotSame(capabilities0, capabilities1);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(3, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(4, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertFalse(capabilities0.equals((Object)capabilities1));
      
      evaluation0.setNumericPriorsFromBuffer();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(3, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(4, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertFalse(capabilities0.equals((Object)capabilities1));
      assertNotSame(capabilities0, capabilities1);
      
      boolean boolean0 = evaluation0.equals((Object) null);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertFalse(boolean0);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(3, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(4, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertFalse(capabilities0.equals((Object)capabilities1));
      assertNotSame(capabilities0, capabilities1);
      
      int int0 = 67;
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      // Undeclared exception!
      try { 
        mockRandom0.ints((long) (-2));
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // size must be non-negative
         //
         verifyException("java.util.Random", e);
      }
  }

  /**
  //Test case number: 57
  /*Coverage entropy=1.0986122886681096
  */
  @Test(timeout = 4000)
  public void test057()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(sGDText0);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(capabilities0);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(5, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      
      capabilities0.enableAll();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(5, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(5, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(4, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(5, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(5, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(4, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      
      boolean boolean0 = evaluation0.equals((Object) null);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertFalse(boolean0);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(5, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(5, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(4, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      
      try { 
        Capabilities.main(testInstances0.DEFAULT_WORDS);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // No file provided with option '-file'!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 58
  /*Coverage entropy=0.9164648855394713
  */
  @Test(timeout = 4000)
  public void test058()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(sGDText0);
      assertFalse(sGDText0.getDebug());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(capabilities0);
      assertFalse(sGDText0.getDebug());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertFalse(sGDText0.getDebug());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      
      capabilities0.enableAll();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertFalse(sGDText0.getDebug());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertFalse(sGDText0.getDebug());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(5, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertFalse(sGDText0.getDebug());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(5, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      
      Instances instances1 = testInstances0.generate();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances1);
      assertFalse(sGDText0.getDebug());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertTrue(instances1.checkForStringAttributes());
      assertEquals(5, instances1.numAttributes());
      assertEquals(4, instances1.classIndex());
      assertEquals(20, instances1.size());
      assertEquals(2, instances1.numClasses());
      assertEquals(20, instances1.numInstances());
      assertEquals("Testdata", instances1.relationName());
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(instances1, instances0);
      
      try { 
        evaluation0.correlationCoefficient();
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't compute correlation coefficient: class is nominal!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 59
  /*Coverage entropy=1.0986122886681096
  */
  @Test(timeout = 4000)
  public void test059()  throws Throwable  {
      MultiClassClassifierUpdateable multiClassClassifierUpdateable0 = new MultiClassClassifierUpdateable();
      assertEquals(0, MultiClassClassifier.METHOD_1_AGAINST_ALL);
      assertEquals(2, MultiClassClassifier.METHOD_ERROR_EXHAUSTIVE);
      assertEquals(3, MultiClassClassifier.METHOD_1_AGAINST_1);
      assertEquals(1, MultiClassClassifier.METHOD_ERROR_RANDOM);
      assertNotNull(multiClassClassifierUpdateable0);
      assertEquals("The random number seed to be used.", multiClassClassifierUpdateable0.seedTipText());
      assertEquals("Sets the width multiplier when using random codes. The number of codes generated will be thus number multiplied by the number of classes.", multiClassClassifierUpdateable0.randomWidthFactorTipText());
      assertEquals(1, multiClassClassifierUpdateable0.getSeed());
      assertEquals("If set to true, classifier may output additional info to the console.", multiClassClassifierUpdateable0.debugTipText());
      assertEquals(2.0, multiClassClassifierUpdateable0.getRandomWidthFactor(), 0.01);
      assertFalse(multiClassClassifierUpdateable0.getUsePairwiseCoupling());
      assertEquals("The base classifier to be used.", multiClassClassifierUpdateable0.classifierTipText());
      assertEquals("Sets the method to use for transforming the multi-class problem into several 2-class ones.", multiClassClassifierUpdateable0.methodTipText());
      assertFalse(multiClassClassifierUpdateable0.getDebug());
      assertEquals("Use pairwise coupling (only has an effect for 1-against-1).", multiClassClassifierUpdateable0.usePairwiseCouplingTipText());
      assertEquals("A metaclassifier for handling multi-class datasets with 2-class classifiers. This classifier is also capable of applying error correcting output codes for increased accuracy. The base classifier must be an updateable classifier", multiClassClassifierUpdateable0.globalInfo());
      
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      
      SGDText sGDText0 = new SGDText();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(sGDText0);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(capabilities0);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      
      Object object0 = new Object();
      assertNotNull(object0);
      
      boolean boolean0 = FileSystemHandling.createFolder((EvoSuiteFile) null);
      assertFalse(boolean0);
      
      try { 
        evaluation0.evaluateModel((Classifier) multiClassClassifierUpdateable0, instances0, (Object[]) sGDText0.TAGS_SELECTION);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // weka.core.Tag cannot be cast to weka.classifiers.evaluation.output.prediction.AbstractOutput
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 60
  /*Coverage entropy=1.6094379124341005
  */
  @Test(timeout = 4000)
  public void test060()  throws Throwable  {
      M5Rules m5Rules0 = new M5Rules();
      assertNotNull(m5Rules0);
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      
      Capabilities capabilities0 = m5Rules0.getCapabilities();
      assertNotNull(capabilities0);
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numClasses());
      assertEquals(3, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numClasses());
      assertEquals(3, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      
      evaluation0.addNumericTrainClass((-2), 1643.091471337);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numClasses());
      assertEquals(3, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      
      double[] doubleArray0 = evaluation0.makeDistribution(6.0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(doubleArray0);
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numClasses());
      assertEquals(3, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(1, doubleArray0.length);
      assertArrayEquals(new double[] {6.0}, doubleArray0, 0.01);
  }

  /**
  //Test case number: 61
  /*Coverage entropy=1.7917594692280547
  */
  @Test(timeout = 4000)
  public void test061()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      
      double double0 = evaluation0.sizeOfPredictedRegions();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      
      try { 
        evaluation0.evaluateModelOnce((double) (-2), (Instance) null);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // -2
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 62
  /*Coverage entropy=2.4849066497880012
  */
  @Test(timeout = 4000)
  public void test062()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      
      Instances instances1 = textDirectoryLoader0.getStructure();
      assertNotNull(instances1);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(2, instances1.numAttributes());
      assertEquals(0.0, instances1.sumOfWeights(), 0.01);
      assertEquals(0, instances1.size());
      assertEquals(0, instances1.numInstances());
      assertEquals(1, instances1.classIndex());
      assertTrue(instances1.checkForStringAttributes());
      assertEquals(0, instances1.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances1.relationName());
      assertSame(instances1, instances0);
      
      SGDText sGDText0 = new SGDText();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(sGDText0);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getUseStopList());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(capabilities0);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      instances1.delete();
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(2, instances1.numAttributes());
      assertEquals(0.0, instances1.sumOfWeights(), 0.01);
      assertEquals(0, instances1.size());
      assertEquals(0, instances1.numInstances());
      assertEquals(1, instances1.classIndex());
      assertTrue(instances1.checkForStringAttributes());
      assertEquals(0, instances1.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances1.relationName());
      assertSame(instances1, instances0);
      
      CostMatrix costMatrix0 = new CostMatrix(0);
      assertNotNull(costMatrix0);
      assertEquals(0, costMatrix0.numColumns());
      assertEquals(0, costMatrix0.size());
      assertEquals(0, costMatrix0.numRows());
      
      Evaluation evaluation0 = new Evaluation(instances1, costMatrix0);
      assertNotNull(evaluation0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(2, instances1.numAttributes());
      assertEquals(0.0, instances1.sumOfWeights(), 0.01);
      assertEquals(0, instances1.size());
      assertEquals(0, instances1.numInstances());
      assertEquals(1, instances1.classIndex());
      assertTrue(instances1.checkForStringAttributes());
      assertEquals(0, instances1.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances1.relationName());
      assertEquals(0, costMatrix0.numColumns());
      assertEquals(0, costMatrix0.size());
      assertEquals(0, costMatrix0.numRows());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      
      String string0 = evaluation0.toClassDetailsString();
      assertNotNull(string0);
      assertEquals("=== Detailed Accuracy By Class ===\n\n                 TP Rate  FP Rate  Precision  Recall  F-Measure  MCC    ROC Area  PRC Area  Class\nWeighted Avg.  NaN      NaN      NaN        NaN     NaN        NaN    NaN       NaN    \n", string0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(2, instances1.numAttributes());
      assertEquals(0.0, instances1.sumOfWeights(), 0.01);
      assertEquals(0, instances1.size());
      assertEquals(0, instances1.numInstances());
      assertEquals(1, instances1.classIndex());
      assertTrue(instances1.checkForStringAttributes());
      assertEquals(0, instances1.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances1.relationName());
      assertEquals(0, costMatrix0.numColumns());
      assertEquals(0, costMatrix0.size());
      assertEquals(0, costMatrix0.numRows());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertSame(instances1, instances0);
  }

  /**
  //Test case number: 63
  /*Coverage entropy=1.464816384890813
  */
  @Test(timeout = 4000)
  public void test063()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      
      Instances instances0 = textDirectoryLoader0.getStructure();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      
      double[] doubleArray0 = new double[0];
      try { 
        evaluation0.evaluateModelOnceAndRecordPrediction(doubleArray0, (Instance) null);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 0
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 64
  /*Coverage entropy=1.0821955300387673
  */
  @Test(timeout = 4000)
  public void test064()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      
      Instances instances0 = testInstances0.generate("  public String getRevision() {\n");
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numAttributes());
      
      int int0 = 234;
      testInstances0.setNumString(234);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(234, testInstances0.getNumString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(236, testInstances0.getNumAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(234, testInstances0.getNumString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(236, testInstances0.getNumAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      
      evaluation0.m_Incorrect = (double) (-2);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(234, testInstances0.getNumString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(236, testInstances0.getNumAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NEGATIVE_INFINITY, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NEGATIVE_INFINITY, evaluation0.pctIncorrect(), 0.01);
      assertEquals((-2.0), evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      
      String string0 = evaluation0.toCumulativeMarginDistributionString();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(string0);
      assertEquals(" -1       0    \n", string0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(234, testInstances0.getNumString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(236, testInstances0.getNumAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NEGATIVE_INFINITY, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NEGATIVE_INFINITY, evaluation0.pctIncorrect(), 0.01);
      assertEquals((-2.0), evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      
      testInstances0.generate();
  }

  /**
  //Test case number: 65
  /*Coverage entropy=1.945910149055313
  */
  @Test(timeout = 4000)
  public void test065()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      boolean boolean0 = evaluation0.equals(testInstances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertFalse(boolean0);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      double double0 = evaluation0.weightedAreaUnderROC();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      double double1 = evaluation0.pctUnclassified();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double1, 0.01);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(double1, double0, 0.01);
  }

  /**
  //Test case number: 66
  /*Coverage entropy=-0.0
  */
  @Test(timeout = 4000)
  public void test066()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      
      String[] stringArray0 = new String[0];
      Evaluation.main(stringArray0);
      assertEquals(0, stringArray0.length);
      
      CSVLoader cSVLoader0 = new CSVLoader();
      assertNotNull(cSVLoader0);
      assertEquals("The range of attributes to force to be of type STRING, example ranges: 'first-last', '1,4,7-14,50-last'.", cSVLoader0.stringAttributesTipText());
      assertEquals("Use relative rather than absolute paths", cSVLoader0.useRelativePathTipText());
      assertEquals("The range of attributes to force to type STRING, example ranges: 'first-last', '1,4,7-14, 50-last'.", cSVLoader0.dateAttributesTipText());
      assertFalse(cSVLoader0.getUseRelativePath());
      assertEquals("CSV data files", cSVLoader0.getFileDescription());
      assertEquals("", cSVLoader0.getDateFormat());
      assertEquals(".csv", cSVLoader0.getFileExtension());
      assertEquals("Reads a source that is in comma separated format (the default). One can also change the column separator from comma to tab or another character. Assumes that the first row in the file determines the number of and names of the attributes.", cSVLoader0.globalInfo());
      assertEquals("The placeholder for missing values, default is '?'.", cSVLoader0.missingValueTipText());
      assertEquals("The range of attributes to force to be of type NOMINAL, example ranges: 'first-last', '1,4,7-14,50-last'.", cSVLoader0.nominalAttributesTipText());
      assertEquals("The character to use as separator for the columns/fields (use '\\t' for TAB).", cSVLoader0.fieldSeparatorTipText());
      assertEquals("First row of data does not contain attribute names", cSVLoader0.noHeaderRowPresentTipText());
      assertEquals("?", cSVLoader0.getMissingValue());
      assertFalse(cSVLoader0.getNoHeaderRowPresent());
      assertEquals("\",'", cSVLoader0.getEnclosureCharacters());
      assertEquals("The format to use for parsing date values.", cSVLoader0.dateFormatTipText());
      assertEquals("The characters to use as enclosures for strings. E.g. \",'", cSVLoader0.enclosureCharactersTipText());
  }

  /**
  //Test case number: 67
  /*Coverage entropy=2.0794415416798357
  */
  @Test(timeout = 4000)
  public void test067()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(sGDText0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(capabilities0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      
      capabilities0.enableAll();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.numAttributes());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.numAttributes());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      Instances instances1 = testInstances0.generate();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances1);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(5, instances1.numAttributes());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(20, instances1.size());
      assertEquals(20, instances1.numInstances());
      assertEquals(2, instances1.numClasses());
      assertEquals(4, instances1.classIndex());
      assertTrue(instances1.checkForStringAttributes());
      assertEquals("Testdata", instances1.relationName());
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(instances1, instances0);
      
      double double0 = evaluation0.unweightedMacroFmeasure();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.numAttributes());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      
      CoverTree coverTree0 = new CoverTree();
      assertNotNull(coverTree0);
      assertEquals("The distance function to use for finding neighbours (default: weka.core.EuclideanDistance). ", coverTree0.distanceFunctionTipText());
      assertEquals("Whether to calculate performance statistics for the NN search or not", coverTree0.measurePerformanceTipText());
      assertEquals(1.3, coverTree0.getBase(), 0.01);
      assertEquals("The base for the expansion constant.", coverTree0.baseTipText());
      assertEquals(0.0, coverTree0.measureNumLeaves(), 0.01);
      assertEquals(0.0, coverTree0.measureMaxDepth(), 0.01);
      assertEquals(0.0, coverTree0.measureTreeSize(), 0.01);
      assertFalse(coverTree0.getMeasurePerformance());
      
      int[] intArray0 = new int[8];
      intArray0[0] = 0;
      intArray0[1] = 0;
      intArray0[2] = (-1);
      intArray0[3] = 1;
      evaluation0.useNoPriors();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.numAttributes());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      
      DenseInstance denseInstance0 = new DenseInstance((-1), (double[]) null);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(denseInstance0);
      assertEquals((-1.0), denseInstance0.weight(), 0.01);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation1);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.numAttributes());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertFalse(instances0.equals((Object)instances1));
      
      double double1 = evaluation0.KBMeanInformation();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(Double.NaN, double1, 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.numAttributes());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(double1, double0, 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotSame(instances0, instances1);
      assertNotSame(evaluation0, evaluation1);
      
      evaluation0.setPriors(instances0);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.numAttributes());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertTrue(evaluation0.equals((Object)evaluation1));
      assertNotSame(instances0, instances1);
      assertNotSame(evaluation0, evaluation1);
  }

  /**
  //Test case number: 68
  /*Coverage entropy=0.6931471805599453
  */
  @Test(timeout = 4000)
  public void test068()  throws Throwable  {
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      assertNotNull(serializedClassifier0);
      assertFalse(serializedClassifier0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", serializedClassifier0.debugTipText());
      assertEquals("A wrapper around a serialized classifier model. This classifier loads a serialized models and uses it to make predictions.\n\nWarning: since the serialized model doesn't get changed, cross-validation cannot bet used with this classifier.", serializedClassifier0.globalInfo());
      assertEquals("The serialized classifier model to use for predictions.", serializedClassifier0.modelFileTipText());
      
      Classifier classifier0 = serializedClassifier0.getCurrentModel();
      assertNull(classifier0);
      assertFalse(serializedClassifier0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", serializedClassifier0.debugTipText());
      assertEquals("A wrapper around a serialized classifier model. This classifier loads a serialized models and uses it to make predictions.\n\nWarning: since the serialized model doesn't get changed, cross-validation cannot bet used with this classifier.", serializedClassifier0.globalInfo());
      assertEquals("The serialized classifier model to use for predictions.", serializedClassifier0.modelFileTipText());
      
      String[] stringArray0 = new String[0];
      try { 
        Evaluation.evaluateModel((Classifier) null, stringArray0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // 
         // Weka exception: No training file and no object input file given.
         // 
         // General options:
         // 
         // -h or -help
         // \tOutput help information.
         // -synopsis or -info
         // \tOutput synopsis for classifier (use in conjunction  with -h)
         // -t <name of training file>
         // \tSets training file.
         // -T <name of test file>
         // \tSets test file. If missing, a cross-validation will be performed
         // \ton the training data.
         // -c <class index>
         // \tSets index of class attribute (default: last).
         // -x <number of folds>
         // \tSets number of folds for cross-validation (default: 10).
         // -no-cv
         // \tDo not perform any cross validation.
         // -split-percentage <percentage>
         // \tSets the percentage for the train/test set split, e.g., 66.
         // -preserve-order
         // \tPreserves the order in the percentage split.
         // -s <random number seed>
         // \tSets random number seed for cross-validation or percentage split
         // \t(default: 1).
         // -m <name of file with cost matrix>
         // \tSets file with cost matrix.
         // -l <name of input file>
         // \tSets model input file. In case the filename ends with '.xml',
         // \ta PMML file is loaded or, if that fails, options are loaded
         // \tfrom the XML file.
         // -d <name of output file>
         // \tSets model output file. In case the filename ends with '.xml',
         // \tonly the options are saved to the XML file, not the model.
         // -v
         // \tOutputs no statistics for training data.
         // -o
         // \tOutputs statistics only, not the classifier.
         // -i
         // \tOutputs detailed information-retrieval statistics for each class.
         // -k
         // \tOutputs information-theoretic statistics.
         // -classifications \"weka.classifiers.evaluation.output.prediction.AbstractOutput + options\"
         // \tUses the specified class for generating the classification output.
         // \tE.g.: weka.classifiers.evaluation.output.prediction.PlainText
         // -p range
         // \tOutputs predictions for test instances (or the train instances if
         // \tno test instances provided and -no-cv is used), along with the 
         // \tattributes in the specified range (and nothing else). 
         // \tUse '-p 0' if no attributes are desired.
         // \tDeprecated: use \"-classifications ...\" instead.
         // -distribution
         // \tOutputs the distribution instead of only the prediction
         // \tin conjunction with the '-p' option (only nominal classes).
         // \tDeprecated: use \"-classifications ...\" instead.
         // -r
         // \tOnly outputs cumulative margin distribution.
         // -xml filename | xml-string
         // \tRetrieves the options from the XML-data instead of the command line.
         // -threshold-file <file>
         // \tThe file to save the threshold data to.
         // \tThe format is determined by the extensions, e.g., '.arff' for ARFF 
         // \tformat or '.csv' for CSV.
         // -threshold-label <label>
         // \tThe class label to determine the threshold data for
         // \t(default is the first label)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 69
  /*Coverage entropy=1.6094379124341005
  */
  @Test(timeout = 4000)
  public void test069()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(sGDText0);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(capabilities0);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      
      capabilities0.enableAll();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      Instances instances0 = testInstances0.generate("9v{");
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      
      Evaluation evaluation1 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation1);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertTrue(evaluation1.equals((Object)evaluation0));
      
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = (double) 1;
      doubleArray0[1] = (double) 0;
      doubleArray0[2] = (double) 0;
      evaluation1.updateMargins(doubleArray0, 0, 0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotSame(evaluation1, evaluation0);
      assertEquals(3, doubleArray0.length);
      assertArrayEquals(new double[] {1.0, 0.0, 0.0}, doubleArray0, 0.01);
      
      LWL lWL0 = new LWL();
      assertEquals(3, LWL.INVERSE);
      assertEquals(0, LWL.LINEAR);
      assertEquals(2, LWL.TRICUBE);
      assertEquals(4, LWL.GAUSS);
      assertEquals(5, LWL.CONSTANT);
      assertEquals(1, LWL.EPANECHNIKOV);
      assertNotNull(lWL0);
      assertEquals("The base classifier to be used.", lWL0.classifierTipText());
      assertEquals("Determines weighting function. [0 = Linear, 1 = Epnechnikov,2 = Tricube, 3 = Inverse, 4 = Gaussian and 5 = Constant. (default 0 = Linear)].", lWL0.weightingKernelTipText());
      assertEquals((-1), lWL0.getKNN());
      assertEquals(0, lWL0.getWeightingKernel());
      assertEquals("How many neighbours are used to determine the width of the weighting function (<= 0 means all neighbours).", lWL0.KNNTipText());
      assertFalse(lWL0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", lWL0.debugTipText());
      assertEquals("The nearest neighbour search algorithm to use (Default: LinearNN).", lWL0.nearestNeighbourSearchAlgorithmTipText());
      
      ArffLoader arffLoader0 = new ArffLoader();
      assertNotNull(arffLoader0);
      assertEquals(".arff", arffLoader0.getFileExtension());
      assertEquals("Use relative rather than absolute paths", arffLoader0.useRelativePathTipText());
      assertEquals("Arff data files", arffLoader0.getFileDescription());
      assertFalse(arffLoader0.getUseRelativePath());
      assertEquals("Reads a source that is in arff (attribute relation file format) format. ", arffLoader0.globalInfo());
      assertEquals("http://", arffLoader0.retrieveURL());
      
      double double0 = evaluation1.weightedAreaUnderPRC();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertNotSame(evaluation1, evaluation0);
      
      try { 
        arffLoader0.getDataSet();
        fail("Expecting exception: IOException");
      
      } catch(IOException e) {
         //
         // No source has been specified
         //
         verifyException("weka.core.converters.ArffLoader", e);
      }
  }

  /**
  //Test case number: 70
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test070()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getStructure();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      
      String string0 = textDirectoryLoader0.getRevision();
      assertNotNull(string0);
      assertEquals("8034", string0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      boolean boolean0 = FileSystemHandling.shouldAllThrowIOExceptions();
      assertTrue(boolean0);
      
      LogitBoost logitBoost0 = new LogitBoost();
      assertNotNull(logitBoost0);
      assertEquals(1, logitBoost0.getSeed());
      assertEquals("Threshold on improvement in likelihood.", logitBoost0.likelihoodThresholdTipText());
      assertEquals((-1.7976931348623157E308), logitBoost0.getLikelihoodThreshold(), 0.01);
      assertEquals("Number of folds for internal cross-validation (default 0 means no cross-validation is performed).", logitBoost0.numFoldsTipText());
      assertEquals("Shrinkage parameter (use small value like 0.1 to reduce overfitting).", logitBoost0.shrinkageTipText());
      assertEquals("The random number seed to be used.", logitBoost0.seedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", logitBoost0.debugTipText());
      assertEquals(10, logitBoost0.getNumIterations());
      assertEquals("Number of runs for internal cross-validation.", logitBoost0.numRunsTipText());
      assertEquals(1.0, logitBoost0.getShrinkage(), 0.01);
      assertEquals("Weight threshold for weight pruning (reduce to 90 for speeding up learning process).", logitBoost0.weightThresholdTipText());
      assertEquals(100, logitBoost0.getWeightThreshold());
      assertFalse(logitBoost0.getDebug());
      assertEquals("The base classifier to be used.", logitBoost0.classifierTipText());
      assertFalse(logitBoost0.getUseResampling());
      assertEquals("The number of iterations to be performed.", logitBoost0.numIterationsTipText());
      assertEquals(1, logitBoost0.getNumRuns());
      assertEquals(0, logitBoost0.getNumFolds());
      assertEquals("Whether resampling is used instead of reweighting.", logitBoost0.useResamplingTipText());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      int int0 = 487;
      Object[] objectArray0 = new Object[0];
      double[] doubleArray0 = evaluation0.evaluateModel((Classifier) logitBoost0, instances0, objectArray0);
      assertNotNull(doubleArray0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, logitBoost0.getSeed());
      assertEquals("Threshold on improvement in likelihood.", logitBoost0.likelihoodThresholdTipText());
      assertEquals((-1.7976931348623157E308), logitBoost0.getLikelihoodThreshold(), 0.01);
      assertEquals("Number of folds for internal cross-validation (default 0 means no cross-validation is performed).", logitBoost0.numFoldsTipText());
      assertEquals("Shrinkage parameter (use small value like 0.1 to reduce overfitting).", logitBoost0.shrinkageTipText());
      assertEquals("The random number seed to be used.", logitBoost0.seedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", logitBoost0.debugTipText());
      assertEquals(10, logitBoost0.getNumIterations());
      assertEquals("Number of runs for internal cross-validation.", logitBoost0.numRunsTipText());
      assertEquals(1.0, logitBoost0.getShrinkage(), 0.01);
      assertEquals("Weight threshold for weight pruning (reduce to 90 for speeding up learning process).", logitBoost0.weightThresholdTipText());
      assertEquals(100, logitBoost0.getWeightThreshold());
      assertFalse(logitBoost0.getDebug());
      assertEquals("The base classifier to be used.", logitBoost0.classifierTipText());
      assertFalse(logitBoost0.getUseResampling());
      assertEquals("The number of iterations to be performed.", logitBoost0.numIterationsTipText());
      assertEquals(1, logitBoost0.getNumRuns());
      assertEquals(0, logitBoost0.getNumFolds());
      assertEquals("Whether resampling is used instead of reweighting.", logitBoost0.useResamplingTipText());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0, objectArray0.length);
      assertEquals(0, doubleArray0.length);
      assertArrayEquals(new double[] {}, doubleArray0, 0.01);
      
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      DoubleStream doubleStream0 = mockRandom0.doubles(0L);
      assertNotNull(doubleStream0);
      
      MockFileInputStream mockFileInputStream0 = null;
      try {
        mockFileInputStream0 = new MockFileInputStream("i<]&F");
        fail("Expecting exception: FileNotFoundException");
      
      } catch(Throwable e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.evosuite.runtime.mock.java.io.MockFileInputStream", e);
      }
  }

  /**
  //Test case number: 71
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test071()  throws Throwable  {
      M5Rules m5Rules0 = new M5Rules();
      assertNotNull(m5Rules0);
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      
      Capabilities capabilities0 = m5Rules0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(4, testInstances0.getNumAttributes());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(4, instances0.numAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(4, instances0.numAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      
      double double0 = evaluation0.m_TotalCost;
      assertEquals(0.0, double0, 0.01);
      
      try { 
        evaluation0.toClassDetailsString("@relation");
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Evaluation: No per class statistics possible!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 72
  /*Coverage entropy=1.0986122886681096
  */
  @Test(timeout = 4000)
  public void test072()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(sGDText0);
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getDebug());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getLowercaseTokens());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(capabilities0);
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getDebug());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      
      capabilities0.enableAll();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getDebug());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      
      Instances instances1 = new Instances(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances1);
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(1, instances1.classIndex());
      assertEquals(20, instances1.numInstances());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(20, instances1.size());
      assertEquals(2, instances1.numAttributes());
      assertEquals(2, instances1.numClasses());
      assertFalse(instances1.equals((Object)instances0));
      
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (double) (-1);
      doubleArray0[2] = (double) 0;
      doubleArray0[3] = (double) 1;
      doubleArray0[4] = (double) 1;
      UnivariateKernelEstimator univariateKernelEstimator0 = new UnivariateKernelEstimator();
      assertEquals((-0.9189385332046727), UnivariateKernelEstimator.CONST, 0.01);
      assertNotNull(univariateKernelEstimator0);
      
      evaluation0.m_PriorEstimator = univariateKernelEstimator0;
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      
      RegressionByDiscretization regressionByDiscretization0 = new RegressionByDiscretization();
      assertEquals(1, RegressionByDiscretization.ESTIMATOR_KERNEL);
      assertEquals(0, RegressionByDiscretization.ESTIMATOR_HISTOGRAM);
      assertEquals(2, RegressionByDiscretization.ESTIMATOR_NORMAL);
      assertNotNull(regressionByDiscretization0);
      assertFalse(regressionByDiscretization0.getDeleteEmptyBins());
      assertFalse(regressionByDiscretization0.getMinimizeAbsoluteError());
      assertEquals("The density estimator to use.", regressionByDiscretization0.estimatorTypeTipText());
      assertEquals("Whether to delete empty bins after discretization.", regressionByDiscretization0.deleteEmptyBinsTipText());
      assertFalse(regressionByDiscretization0.getUseEqualFrequency());
      assertFalse(regressionByDiscretization0.getDebug());
      assertEquals("The base classifier to be used.", regressionByDiscretization0.classifierTipText());
      assertEquals("Number of bins for discretization.", regressionByDiscretization0.numBinsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", regressionByDiscretization0.debugTipText());
      assertEquals("Whether to minimize absolute error.", regressionByDiscretization0.minimizeAbsoluteErrorTipText());
      assertEquals("If set to true, equal-frequency binning will be used instead of equal-width binning.", regressionByDiscretization0.useEqualFrequencyTipText());
      assertEquals(10, regressionByDiscretization0.getNumBins());
      
      regressionByDiscretization0.setClassifier(sGDText0);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(1, RegressionByDiscretization.ESTIMATOR_KERNEL);
      assertEquals(0, RegressionByDiscretization.ESTIMATOR_HISTOGRAM);
      assertEquals(2, RegressionByDiscretization.ESTIMATOR_NORMAL);
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getDebug());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(regressionByDiscretization0.getDeleteEmptyBins());
      assertFalse(regressionByDiscretization0.getMinimizeAbsoluteError());
      assertEquals("The density estimator to use.", regressionByDiscretization0.estimatorTypeTipText());
      assertEquals("Whether to delete empty bins after discretization.", regressionByDiscretization0.deleteEmptyBinsTipText());
      assertFalse(regressionByDiscretization0.getUseEqualFrequency());
      assertFalse(regressionByDiscretization0.getDebug());
      assertEquals("The base classifier to be used.", regressionByDiscretization0.classifierTipText());
      assertEquals("Number of bins for discretization.", regressionByDiscretization0.numBinsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", regressionByDiscretization0.debugTipText());
      assertEquals("Whether to minimize absolute error.", regressionByDiscretization0.minimizeAbsoluteErrorTipText());
      assertEquals("If set to true, equal-frequency binning will be used instead of equal-width binning.", regressionByDiscretization0.useEqualFrequencyTipText());
      assertEquals(10, regressionByDiscretization0.getNumBins());
      
      DenseInstance denseInstance0 = new DenseInstance(0.0, doubleArray0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(denseInstance0);
      assertEquals(5, denseInstance0.numAttributes());
      assertEquals(0.0, denseInstance0.weight(), 0.01);
      assertEquals(5, denseInstance0.numValues());
      assertEquals(5, doubleArray0.length);
      assertArrayEquals(new double[] {(-1.0), 0.0, 0.0, 1.0, 1.0}, doubleArray0, 0.01);
      
      try { 
        evaluation0.updateStatsForConditionalDensityEstimator(regressionByDiscretization0, denseInstance0, (-2));
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.meta.RegressionByDiscretization", e);
      }
  }

  /**
  //Test case number: 73
  /*Coverage entropy=1.6094379124341005
  */
  @Test(timeout = 4000)
  public void test073()  throws Throwable  {
      M5Rules m5Rules0 = new M5Rules();
      assertNotNull(m5Rules0);
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      
      Capabilities capabilities0 = m5Rules0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(4, instances0.numAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(3, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(4, instances0.numAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(3, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      
      double double0 = evaluation0.errorRate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(4, instances0.numAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(3, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
  }

  /**
  //Test case number: 74
  /*Coverage entropy=-0.0
  */
  @Test(timeout = 4000)
  public void test074()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      
      Instances instances0 = textDirectoryLoader0.getStructure();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      
      IIOMetadataNode iIOMetadataNode0 = new IIOMetadataNode();
      assertNotNull(iIOMetadataNode0);
      
      TreeModel treeModel0 = new TreeModel(iIOMetadataNode0, instances0, (MiningSchema) null);
      assertNotNull(treeModel0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(1, treeModel0.graphType());
      assertEquals("?", treeModel0.getCreatorApplication());
      assertFalse(treeModel0.getDebug());
      assertEquals("?", treeModel0.getPMMLVersion());
      assertEquals("If set to true, classifier may output additional info to the console.", treeModel0.debugTipText());
      
      String string0 = Evaluation.getGlobalInfo(treeModel0);
      assertNotNull(string0);
      assertEquals("\nSynopsis for weka.classifiers.pmml.consumer.TreeModel:\n\n", string0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(1, treeModel0.graphType());
      assertEquals("?", treeModel0.getCreatorApplication());
      assertFalse(treeModel0.getDebug());
      assertEquals("?", treeModel0.getPMMLVersion());
      assertEquals("If set to true, classifier may output additional info to the console.", treeModel0.debugTipText());
  }

  /**
  //Test case number: 75
  /*Coverage entropy=1.945910149055313
  */
  @Test(timeout = 4000)
  public void test075()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getStructure();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      
      evaluation0.useNoPriors();
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      
      DenseInstance denseInstance0 = new DenseInstance(15.0, (double[]) null);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(denseInstance0);
      assertEquals(15.0, denseInstance0.weight(), 0.01);
      
      double double0 = evaluation0.SFEntropyGain();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      
      String string0 = evaluation0.toSummaryString("@data", true);
      assertNotNull(string0);
      assertEquals("@data\nTotal Number of Instances                0     \n", string0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
  }

  /**
  //Test case number: 76
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test076()  throws Throwable  {
      M5Rules m5Rules0 = new M5Rules();
      assertNotNull(m5Rules0);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      
      LinearRegression linearRegression0 = new LinearRegression();
      assertEquals(1, LinearRegression.SELECTION_NONE);
      assertEquals(0, LinearRegression.SELECTION_M5);
      assertEquals(2, LinearRegression.SELECTION_GREEDY);
      assertNotNull(linearRegression0);
      assertEquals("If enabled, dataset header, means and stdevs get discarded to conserve memory; also, the model cannot be printed out.", linearRegression0.minimalTipText());
      assertEquals("Class for using linear regression for prediction. Uses the Akaike criterion for model selection, and is able to deal with weighted instances.", linearRegression0.globalInfo());
      assertEquals("The value of the Ridge parameter.", linearRegression0.ridgeTipText());
      assertEquals("Eliminate colinear attributes.", linearRegression0.eliminateColinearAttributesTipText());
      assertEquals("Set the method used to select attributes for use in the linear regression. Available methods are: no attribute selection, attribute selection using M5's method (step through the attributes removing the one with the smallest standardised coefficient until no improvement is observed in the estimate of the error given by the Akaike information criterion), and a greedy selection using the Akaike information metric.", linearRegression0.attributeSelectionMethodTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", linearRegression0.debugTipText());
      assertFalse(linearRegression0.getMinimal());
      assertEquals(1.0E-8, linearRegression0.getRidge(), 0.01);
      assertTrue(linearRegression0.getEliminateColinearAttributes());
      assertFalse(linearRegression0.getDebug());
      
      Capabilities capabilities0 = linearRegression0.getCapabilities();
      assertEquals(1, LinearRegression.SELECTION_NONE);
      assertEquals(0, LinearRegression.SELECTION_M5);
      assertEquals(2, LinearRegression.SELECTION_GREEDY);
      assertNotNull(capabilities0);
      assertEquals("If enabled, dataset header, means and stdevs get discarded to conserve memory; also, the model cannot be printed out.", linearRegression0.minimalTipText());
      assertEquals("Class for using linear regression for prediction. Uses the Akaike criterion for model selection, and is able to deal with weighted instances.", linearRegression0.globalInfo());
      assertEquals("The value of the Ridge parameter.", linearRegression0.ridgeTipText());
      assertEquals("Eliminate colinear attributes.", linearRegression0.eliminateColinearAttributesTipText());
      assertEquals("Set the method used to select attributes for use in the linear regression. Available methods are: no attribute selection, attribute selection using M5's method (step through the attributes removing the one with the smallest standardised coefficient until no improvement is observed in the estimate of the error given by the Akaike information criterion), and a greedy selection using the Akaike information metric.", linearRegression0.attributeSelectionMethodTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", linearRegression0.debugTipText());
      assertFalse(linearRegression0.getMinimal());
      assertEquals(1.0E-8, linearRegression0.getRidge(), 0.01);
      assertTrue(linearRegression0.getEliminateColinearAttributes());
      assertFalse(linearRegression0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals(1, LinearRegression.SELECTION_NONE);
      assertEquals(0, LinearRegression.SELECTION_M5);
      assertEquals(2, LinearRegression.SELECTION_GREEDY);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals("If enabled, dataset header, means and stdevs get discarded to conserve memory; also, the model cannot be printed out.", linearRegression0.minimalTipText());
      assertEquals("Class for using linear regression for prediction. Uses the Akaike criterion for model selection, and is able to deal with weighted instances.", linearRegression0.globalInfo());
      assertEquals("The value of the Ridge parameter.", linearRegression0.ridgeTipText());
      assertEquals("Eliminate colinear attributes.", linearRegression0.eliminateColinearAttributesTipText());
      assertEquals("Set the method used to select attributes for use in the linear regression. Available methods are: no attribute selection, attribute selection using M5's method (step through the attributes removing the one with the smallest standardised coefficient until no improvement is observed in the estimate of the error given by the Akaike information criterion), and a greedy selection using the Akaike information metric.", linearRegression0.attributeSelectionMethodTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", linearRegression0.debugTipText());
      assertFalse(linearRegression0.getMinimal());
      assertEquals(1.0E-8, linearRegression0.getRidge(), 0.01);
      assertTrue(linearRegression0.getEliminateColinearAttributes());
      assertFalse(linearRegression0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      
      Instances instances0 = testInstances0.generate((String) null);
      assertEquals(1, LinearRegression.SELECTION_NONE);
      assertEquals(0, LinearRegression.SELECTION_M5);
      assertEquals(2, LinearRegression.SELECTION_GREEDY);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals("If enabled, dataset header, means and stdevs get discarded to conserve memory; also, the model cannot be printed out.", linearRegression0.minimalTipText());
      assertEquals("Class for using linear regression for prediction. Uses the Akaike criterion for model selection, and is able to deal with weighted instances.", linearRegression0.globalInfo());
      assertEquals("The value of the Ridge parameter.", linearRegression0.ridgeTipText());
      assertEquals("Eliminate colinear attributes.", linearRegression0.eliminateColinearAttributesTipText());
      assertEquals("Set the method used to select attributes for use in the linear regression. Available methods are: no attribute selection, attribute selection using M5's method (step through the attributes removing the one with the smallest standardised coefficient until no improvement is observed in the estimate of the error given by the Akaike information criterion), and a greedy selection using the Akaike information metric.", linearRegression0.attributeSelectionMethodTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", linearRegression0.debugTipText());
      assertFalse(linearRegression0.getMinimal());
      assertEquals(1.0E-8, linearRegression0.getRidge(), 0.01);
      assertTrue(linearRegression0.getEliminateColinearAttributes());
      assertFalse(linearRegression0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(4, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(3, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      
      testInstances0.setNumString(1520);
      assertEquals(1, LinearRegression.SELECTION_NONE);
      assertEquals(0, LinearRegression.SELECTION_M5);
      assertEquals(2, LinearRegression.SELECTION_GREEDY);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("If enabled, dataset header, means and stdevs get discarded to conserve memory; also, the model cannot be printed out.", linearRegression0.minimalTipText());
      assertEquals("Class for using linear regression for prediction. Uses the Akaike criterion for model selection, and is able to deal with weighted instances.", linearRegression0.globalInfo());
      assertEquals("The value of the Ridge parameter.", linearRegression0.ridgeTipText());
      assertEquals("Eliminate colinear attributes.", linearRegression0.eliminateColinearAttributesTipText());
      assertEquals("Set the method used to select attributes for use in the linear regression. Available methods are: no attribute selection, attribute selection using M5's method (step through the attributes removing the one with the smallest standardised coefficient until no improvement is observed in the estimate of the error given by the Akaike information criterion), and a greedy selection using the Akaike information metric.", linearRegression0.attributeSelectionMethodTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", linearRegression0.debugTipText());
      assertFalse(linearRegression0.getMinimal());
      assertEquals(1.0E-8, linearRegression0.getRidge(), 0.01);
      assertTrue(linearRegression0.getEliminateColinearAttributes());
      assertFalse(linearRegression0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1524, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1520, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals(1, LinearRegression.SELECTION_NONE);
      assertEquals(0, LinearRegression.SELECTION_M5);
      assertEquals(2, LinearRegression.SELECTION_GREEDY);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals("If enabled, dataset header, means and stdevs get discarded to conserve memory; also, the model cannot be printed out.", linearRegression0.minimalTipText());
      assertEquals("Class for using linear regression for prediction. Uses the Akaike criterion for model selection, and is able to deal with weighted instances.", linearRegression0.globalInfo());
      assertEquals("The value of the Ridge parameter.", linearRegression0.ridgeTipText());
      assertEquals("Eliminate colinear attributes.", linearRegression0.eliminateColinearAttributesTipText());
      assertEquals("Set the method used to select attributes for use in the linear regression. Available methods are: no attribute selection, attribute selection using M5's method (step through the attributes removing the one with the smallest standardised coefficient until no improvement is observed in the estimate of the error given by the Akaike information criterion), and a greedy selection using the Akaike information metric.", linearRegression0.attributeSelectionMethodTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", linearRegression0.debugTipText());
      assertFalse(linearRegression0.getMinimal());
      assertEquals(1.0E-8, linearRegression0.getRidge(), 0.01);
      assertTrue(linearRegression0.getEliminateColinearAttributes());
      assertFalse(linearRegression0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1524, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1520, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(4, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(3, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      
      try { 
        evaluation0.toCumulativeMarginDistributionString();
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Class must be nominal for margin distributions
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 77
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test077()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      
      Instances instances0 = testInstances0.generate("  public String getRevision() {\n");
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      
      testInstances0.setNumString(234);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(234, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(236, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      
      MockRandom mockRandom0 = new MockRandom(234);
      assertNotNull(mockRandom0);
      
      instances0.randomize(mockRandom0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(234, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(236, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      
      SparseInstance sparseInstance0 = new SparseInstance(25);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(sparseInstance0);
      assertEquals(25, sparseInstance0.numAttributes());
      assertEquals(25, sparseInstance0.numValues());
      assertEquals(1.0, sparseInstance0.weight(), 0.01);
      
      boolean boolean0 = instances0.add((Instance) sparseInstance0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertTrue(boolean0);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(234, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(236, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(21.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(21, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(21, instances0.size());
      assertEquals(25, sparseInstance0.numAttributes());
      assertEquals(25, sparseInstance0.numValues());
      assertEquals(1.0, sparseInstance0.weight(), 0.01);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(234, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(236, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(21.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(21, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(21, instances0.size());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      double double0 = evaluation0.SFPriorEntropy();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0.0, double0, 0.01);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(234, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(236, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(21.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(21, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(21, instances0.size());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      Version.MINOR = 9;
      System.setCurrentTimeMillis((-2));
  }

  /**
  //Test case number: 78
  /*Coverage entropy=1.1269287948006759
  */
  @Test(timeout = 4000)
  public void test078()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(sGDText0);
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(capabilities0);
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumString());
      
      capabilities0.enableAll();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(5, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(4, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      
      sGDText0.setUseStopList(true);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getDebug());
      assertTrue(sGDText0.getUseStopList());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getDebug());
      assertTrue(sGDText0.getUseStopList());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(5, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(4, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      
      Instances instances1 = new Instances(instances0);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances1);
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getDebug());
      assertTrue(sGDText0.getUseStopList());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(5, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(4, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances1.numClasses());
      assertTrue(instances1.checkForStringAttributes());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(5, instances1.numAttributes());
      assertEquals(20, instances1.numInstances());
      assertEquals(4, instances1.classIndex());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(20, instances1.size());
      assertFalse(instances1.equals((Object)instances0));
      
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (double) (-1);
      doubleArray0[2] = (double) 0;
      doubleArray0[3] = (double) 1;
      double double0 = evaluation0.SFMeanSchemeEntropy();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(Double.NaN, double0, 0.01);
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getDebug());
      assertTrue(sGDText0.getUseStopList());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(5, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(4, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      
      char[] charArray0 = new char[0];
      String string0 = evaluation0.num2ShortID((-1279), charArray0, 0);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(string0);
      assertEquals("", string0);
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getDebug());
      assertTrue(sGDText0.getUseStopList());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(5, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(4, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      assertEquals(0, charArray0.length);
      assertArrayEquals(new char[] {}, charArray0);
  }

  /**
  //Test case number: 79
  /*Coverage entropy=1.2214016632869722
  */
  @Test(timeout = 4000)
  public void test079()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = (double) (-1);
      doubleArray0[1] = (-2556.873197555631);
      Evaluation.main(testInstances0.DEFAULT_WORDS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      
      doubleArray0[2] = (double) (-1);
      doubleArray0[5] = (double) (-2);
      char[] charArray0 = new char[9];
      charArray0[0] = 'i';
      charArray0[1] = 'v';
      charArray0[2] = 'm';
      charArray0[3] = '.';
      charArray0[4] = 'R';
      charArray0[5] = 'N';
      charArray0[6] = '&';
      charArray0[7] = 'u';
      charArray0[8] = 'O';
      String string0 = evaluation0.num2ShortID(2659, charArray0, 12);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(string0);
      assertEquals("        mR&R", string0);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(9, charArray0.length);
      assertArrayEquals(new char[] {'i', 'v', 'm', '.', 'R', 'N', '&', 'u', 'O'}, charArray0);
      
      doubleArray0[5] = (double) (-1);
      boolean boolean0 = false;
      boolean boolean1 = evaluation0.equals(evaluation0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(boolean1);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(boolean1 == boolean0);
      
      try { 
        Capabilities.main(testInstances0.DEFAULT_WORDS);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // No file provided with option '-file'!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 80
  /*Coverage entropy=1.7917594692280547
  */
  @Test(timeout = 4000)
  public void test080()  throws Throwable  {
      M5Rules m5Rules0 = new M5Rules();
      assertNotNull(m5Rules0);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getDebug());
      
      Capabilities capabilities0 = m5Rules0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(3, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numClasses());
      
      Instances instances1 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances1);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(4, instances1.numAttributes());
      assertEquals(3, instances1.classIndex());
      assertEquals(20, instances1.size());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(20, instances1.numInstances());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(1, instances1.numClasses());
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(instances1, instances0);
      
      Evaluation evaluation0 = new Evaluation(instances1);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(4, instances1.numAttributes());
      assertEquals(3, instances1.classIndex());
      assertEquals(20, instances1.size());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(20, instances1.numInstances());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(1, instances1.numClasses());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(instances1.equals((Object)instances0));
      
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = (double) (-1);
      doubleArray0[1] = (double) (-2);
      doubleArray0[3] = (double) (-2);
      evaluation0.updateNumericScores(doubleArray0, doubleArray0, (-2.0));
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(4, instances1.numAttributes());
      assertEquals(3, instances1.classIndex());
      assertEquals(20, instances1.size());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(20, instances1.numInstances());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(1, instances1.numClasses());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NEGATIVE_INFINITY, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(instances1, instances0);
      assertEquals(4, doubleArray0.length);
      assertArrayEquals(new double[] {(-1.0), (-2.0), 0.0, (-2.0)}, doubleArray0, 0.01);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation1);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(3, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numClasses());
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertTrue(evaluation1.equals((Object)evaluation0));
      
      try { 
        evaluation1.toMatrixString("@data");
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Evaluation: No confusion matrix possible!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 81
  /*Coverage entropy=2.1972245773362196
  */
  @Test(timeout = 4000)
  public void test081()  throws Throwable  {
      boolean boolean0 = FileSystemHandling.shouldAllThrowIOExceptions();
      assertTrue(boolean0);
      
      M5Rules m5Rules0 = new M5Rules();
      assertNotNull(m5Rules0);
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      
      Capabilities capabilities0 = m5Rules0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(4, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(4, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      
      evaluation0.addNumericTrainClass((-2), (-1));
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(4, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      
      double double0 = evaluation0.correlationCoefficient();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(4, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      
      double double1 = evaluation0.relativeAbsoluteError();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double1, 0.01);
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertFalse(m5Rules0.getDebug());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(4, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(double1, double0, 0.01);
      
      try { 
        evaluation0.KBMeanInformation();
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't compute K&B Info score: class numeric!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 82
  /*Coverage entropy=1.7917594692280547
  */
  @Test(timeout = 4000)
  public void test082()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      
      SGDText sGDText0 = new SGDText();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(sGDText0);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(capabilities0);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances1);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances1.getNumString());
      assertEquals(5, testInstances1.getNumAttributes());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(1, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(1, testInstances1.getSeed());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertFalse(testInstances1.getNoClass());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(1, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals((-1), testInstances1.getClassIndex());
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      
      Instances instances0 = testInstances1.generate();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances1.getNumString());
      assertEquals(5, testInstances1.getNumAttributes());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(1, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(1, testInstances1.getSeed());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertFalse(testInstances1.getNoClass());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(1, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(5, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances1.getNumString());
      assertEquals(5, testInstances1.getNumAttributes());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(1, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(1, testInstances1.getSeed());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertFalse(testInstances1.getNoClass());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(1, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(5, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(testInstances1.equals((Object)testInstances0));
      
      byte[] byteArray0 = new byte[4];
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      byteArray0[1] = (byte)10;
      byteArray0[2] = (byte)5;
      byteArray0[3] = (byte)46;
      boolean boolean0 = FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      assertFalse(boolean0);
      assertEquals(4, byteArray0.length);
      assertArrayEquals(new byte[] {(byte)0, (byte)10, (byte)5, (byte)46}, byteArray0);
      
      double double0 = evaluation0.trueNegativeRate((-1975));
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0.0, double0, 0.01);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances1.getNumString());
      assertEquals(5, testInstances1.getNumAttributes());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(1, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(1, testInstances1.getSeed());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertFalse(testInstances1.getNoClass());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(1, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(5, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      
      evaluation0.useNoPriors();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances1.getNumString());
      assertEquals(5, testInstances1.getNumAttributes());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(1, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(1, testInstances1.getSeed());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertFalse(testInstances1.getNoClass());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(1, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(5, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      
      DenseInstance denseInstance0 = new DenseInstance((-2), (double[]) null);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(denseInstance0);
      assertEquals((-2.0), denseInstance0.weight(), 0.01);
      
      double double1 = evaluation0.SFEntropyGain();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(Double.NaN, double1, 0.01);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances1.getNumString());
      assertEquals(5, testInstances1.getNumAttributes());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(1, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(1, testInstances1.getSeed());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertFalse(testInstances1.getNoClass());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(1, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(5, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotEquals(double1, double0, 0.01);
      assertNotSame(testInstances1, testInstances0);
      
      System.setCurrentTimeMillis(0L);
      double double2 = evaluation0.relativeAbsoluteError();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(Double.NaN, double2, 0.01);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances1.getNumString());
      assertEquals(5, testInstances1.getNumAttributes());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(0, testInstances1.getNumRelational());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(1, testInstances1.getClassType());
      assertEquals(1, testInstances1.getNumRelationalDate());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(1, testInstances1.getSeed());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertFalse(testInstances1.getNoClass());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertEquals(1, testInstances1.getNumDate());
      assertEquals(1, testInstances1.getNumRelationalString());
      assertEquals(1, testInstances1.getNumRelationalNumeric());
      assertEquals(1, testInstances1.getNumNumeric());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(5, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(double2, double1, 0.01);
      assertNotEquals(double2, double0, 0.01);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
  }

  /**
  //Test case number: 83
  /*Coverage entropy=2.3025850929940455
  */
  @Test(timeout = 4000)
  public void test083()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      
      TestInstances testInstances1 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances1);
      assertEquals(0, testInstances1.getNumString());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(0, testInstances1.getNumRelationalDate());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(2, testInstances1.getNumAttributes());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getClassType());
      assertEquals(0, testInstances1.getNumRelational());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(0, testInstances1.getNumDate());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertFalse(testInstances1.getNoClass());
      assertEquals(0, testInstances1.getNumNumeric());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertEquals(0, testInstances1.getNumRelationalNumeric());
      assertFalse(testInstances1.equals((Object)testInstances0));
      
      Instances instances0 = testInstances1.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(0, testInstances1.getNumString());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(0, testInstances1.getNumRelationalDate());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(2, testInstances1.getNumAttributes());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getClassType());
      assertEquals(0, testInstances1.getNumRelational());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(0, testInstances1.getNumDate());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertFalse(testInstances1.getNoClass());
      assertEquals(0, testInstances1.getNumNumeric());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertEquals(0, testInstances1.getNumRelationalNumeric());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      
      Vector<BinarySparseInstance> vector0 = new Vector<BinarySparseInstance>();
      assertNotNull(vector0);
      assertEquals("[]", vector0.toString());
      assertEquals(10, vector0.capacity());
      assertEquals(0, vector0.size());
      assertTrue(vector0.isEmpty());
      
      boolean boolean0 = instances0.addAll((Collection<? extends Instance>) vector0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertFalse(boolean0);
      assertEquals(0, testInstances1.getNumString());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(0, testInstances1.getNumRelationalDate());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(2, testInstances1.getNumAttributes());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getClassType());
      assertEquals(0, testInstances1.getNumRelational());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(0, testInstances1.getNumDate());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertFalse(testInstances1.getNoClass());
      assertEquals(0, testInstances1.getNumNumeric());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertEquals(0, testInstances1.getNumRelationalNumeric());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals("[]", vector0.toString());
      assertEquals(10, vector0.capacity());
      assertEquals(0, vector0.size());
      assertTrue(vector0.isEmpty());
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertNotSame(testInstances1, testInstances0);
      
      Instances instances1 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances1);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, instances1.numClasses());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(20, instances1.size());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(20, instances1.numInstances());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(1, instances1.classIndex());
      assertEquals(2, instances1.numAttributes());
      assertFalse(testInstances0.equals((Object)testInstances1));
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(testInstances0, testInstances1);
      assertNotSame(instances1, instances0);
      
      SGDText sGDText0 = new SGDText();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(sGDText0);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(capabilities0);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances1.getNumString());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(0, testInstances1.getNumRelationalDate());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(2, testInstances1.getNumAttributes());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getClassType());
      assertEquals(0, testInstances1.getNumRelational());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(0, testInstances1.getNumDate());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertFalse(testInstances1.getNoClass());
      assertEquals(0, testInstances1.getNumNumeric());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertEquals(0, testInstances1.getNumRelationalNumeric());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertFalse(instances0.equals((Object)instances1));
      
      Object[] objectArray0 = new Object[0];
      double[] doubleArray0 = evaluation0.evaluateModel((Classifier) sGDText0, instances0, objectArray0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(doubleArray0);
      assertEquals(0, testInstances1.getNumString());
      assertEquals((-1), testInstances1.getClassIndex());
      assertEquals(1, testInstances1.getSeed());
      assertEquals(0, testInstances1.getNumRelationalDate());
      assertEquals(1, testInstances1.getNumNominal());
      assertEquals(2, testInstances1.getNumAttributes());
      assertEquals(2, testInstances1.getNumClasses());
      assertEquals(20, testInstances1.getNumInstances());
      assertEquals("Testdata", testInstances1.getRelation());
      assertEquals(" ", testInstances1.getWordSeparators());
      assertEquals(1, testInstances1.getClassType());
      assertEquals(0, testInstances1.getNumRelational());
      assertFalse(testInstances1.getMultiInstance());
      assertEquals(10, testInstances1.getNumInstancesRelational());
      assertEquals(2, testInstances1.getNumNominalValues());
      assertEquals(0, testInstances1.getNumDate());
      assertEquals(2, testInstances1.getNumRelationalNominalValues());
      assertFalse(testInstances1.getNoClass());
      assertEquals(0, testInstances1.getNumNumeric());
      assertEquals(1, testInstances1.getNumRelationalNominal());
      assertEquals(0, testInstances1.getNumRelationalString());
      assertEquals(0, testInstances1.getNumRelationalNumeric());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.45, evaluation0.errorRate(), 0.01);
      assertEquals(50.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(45.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.49751448336407733, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.45, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(90.82568807339449, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.4954545454545455, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.6708203932499369, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(55.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(20.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.30250000000000005, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.55, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.55, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(55.0, evaluation0.pctCorrect(), 0.01);
      assertEquals((-482.3071653994586), evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(9666.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(19.856692010826972, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.kappa(), 0.01);
      assertEquals(134.8343446634971, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.45, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals((-9646.143307989172), evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.45, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.55, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.3903225806451613, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.9928346005413486, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(9.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(11.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.55, evaluation0.weightedRecall(), 0.01);
      assertEquals(483.3, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertFalse(testInstances1.equals((Object)testInstances0));
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(testInstances1, testInstances0);
      assertNotSame(instances0, instances1);
      assertEquals(0, objectArray0.length);
      assertEquals(20, doubleArray0.length);
  }

  /**
  //Test case number: 84
  /*Coverage entropy=1.945910149055313
  */
  @Test(timeout = 4000)
  public void test084()  throws Throwable  {
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertNotNull(costSensitiveClassifier0);
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      
      CostMatrix costMatrix0 = costSensitiveClassifier0.getCostMatrix();
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertNotNull(costMatrix0);
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertEquals(1, costMatrix0.numRows());
      assertEquals(1, costMatrix0.numColumns());
      assertEquals(1, costMatrix0.size());
      
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances0 = textDirectoryLoader0.getStructure();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      
      MockFile mockFile0 = new MockFile("@data");
      assertNotNull(mockFile0);
      
      DenseInstance denseInstance0 = new DenseInstance(2);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(denseInstance0);
      assertEquals(2, denseInstance0.numAttributes());
      assertEquals(1.0, denseInstance0.weight(), 0.01);
      assertEquals(2, denseInstance0.numValues());
      
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/evosuite_readability_gen/projects/107_weka");
      byte[] byteArray0 = new byte[9];
      instances0.setClassIndex(1);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      
      byteArray0[0] = (byte) (-104);
      byteArray0[3] = (byte) (-32);
      byteArray0[4] = (byte)2;
      byteArray0[5] = (byte)124;
      evaluation0.m_PriorEstimator = null;
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      
      byteArray0[6] = (byte)8;
      byteArray0[7] = (byte)29;
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = (double) (byte)8;
      doubleArray0[1] = (double) (byte)29;
      doubleArray0[2] = (double) (byte)2;
      doubleArray0[3] = (double) (byte) (-104);
      doubleArray0[4] = (double) (byte)124;
      doubleArray0[5] = (double) (byte)8;
      doubleArray0[6] = (double) (byte) (-32);
      evaluation0.m_MarginCounts = doubleArray0;
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      
      byteArray0[8] = (byte) (-110);
      boolean boolean0 = FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      assertFalse(boolean0);
      assertEquals(9, byteArray0.length);
      assertArrayEquals(new byte[] {(byte) (-104), (byte)0, (byte)0, (byte) (-32), (byte)2, (byte)124, (byte)8, (byte)29, (byte) (-110)}, byteArray0);
      
      denseInstance0.setDataset(instances0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, denseInstance0.numAttributes());
      assertEquals(1.0, denseInstance0.weight(), 0.01);
      assertEquals(2, denseInstance0.numValues());
      assertEquals(1, denseInstance0.classIndex());
      assertEquals(0, denseInstance0.numClasses());
      
      double double0 = evaluation0.evaluateModelOnceAndRecordPrediction((Classifier) costSensitiveClassifier0, (Instance) denseInstance0);
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(2, denseInstance0.numAttributes());
      assertEquals(1.0, denseInstance0.weight(), 0.01);
      assertEquals(2, denseInstance0.numValues());
      assertEquals(1, denseInstance0.classIndex());
      assertEquals(0, denseInstance0.numClasses());
      
      evaluation0.addNumericTrainClass((byte) (-104), (byte)8);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      
      evaluation0.addNumericTrainClass((byte)8, (-3557.1428576865205));
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
  }

  /**
  //Test case number: 85
  /*Coverage entropy=3.186472477016841
  */
  @Test(timeout = 4000)
  public void test085()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      
      SGDText sGDText0 = new SGDText();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(sGDText0);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      
      Enumeration enumeration0 = testInstances0.listOptions();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(enumeration0);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(capabilities0);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      
      Object[] objectArray0 = new Object[4];
      objectArray0[0] = (Object) null;
      Object object0 = new Object();
      assertNotNull(object0);
      
      objectArray0[2] = (Object) evaluation0;
      boolean boolean0 = FileSystemHandling.createFolder((EvoSuiteFile) null);
      assertFalse(boolean0);
      
      objectArray0[3] = (Object) sGDText0;
      double[] doubleArray0 = evaluation0.evaluateModel((Classifier) sGDText0, instances0, objectArray0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(doubleArray0);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(9666.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(9.0, evaluation0.incorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(20.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.55, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(134.8343446634971, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.45, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.3903225806451613, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(90.82568807339449, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.9928346005413486, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.55, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.6708203932499369, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.kappa(), 0.01);
      assertEquals(483.3, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.55, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(55.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.49751448336407733, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(11.0, evaluation0.correct(), 0.01);
      assertEquals(0.45, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(55.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(50.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.30250000000000005, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals((-9646.143307989172), evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.4954545454545455, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.45, evaluation0.errorRate(), 0.01);
      assertEquals((-482.3071653994586), evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(19.856692010826972, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(45.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.45, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.55, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(4, objectArray0.length);
      assertEquals(20, doubleArray0.length);
      
      double double0 = evaluation0.weightedAreaUnderROC();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0.5, double0, 0.01);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals(9666.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(9.0, evaluation0.incorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(20.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.55, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(134.8343446634971, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.45, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.3903225806451613, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(90.82568807339449, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.9928346005413486, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.55, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.6708203932499369, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.kappa(), 0.01);
      assertEquals(483.3, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.55, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(55.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.49751448336407733, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(11.0, evaluation0.correct(), 0.01);
      assertEquals(0.45, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(55.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(50.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.30250000000000005, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals((-9646.143307989172), evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.4954545454545455, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.45, evaluation0.errorRate(), 0.01);
      assertEquals((-482.3071653994586), evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(19.856692010826972, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(45.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.45, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.55, evaluation0.weightedTruePositiveRate(), 0.01);
      
      String string0 = evaluation0.toSummaryString("V", true);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(string0);
      assertEquals("V\nCorrectly Classified Instances          11               55      %\nIncorrectly Classified Instances         9               45      %\nKappa statistic                          0     \nK&B Relative Info Score                175.9442 %\nK&B Information Score                    1.7489 bits      0.0874 bits/instance\nClass complexity | order 0              19.8567 bits      0.9928 bits/instance\nClass complexity | scheme             9666      bits    483.3    bits/instance\nComplexity improvement     (Sf)      -9646.1433 bits   -482.3072 bits/instance\nMean absolute error                      0.45  \nRoot mean squared error                  0.6708\nRelative absolute error                 90.8257 %\nRoot relative squared error            134.8343 %\nCoverage of cases (0.95 level)          55      %\nMean rel. region size (0.95 level)      50      %\nTotal Number of Instances               20     \n", string0);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals(9666.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(9.0, evaluation0.incorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(20.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.55, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(134.8343446634971, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.45, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.3903225806451613, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(90.82568807339449, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.9928346005413486, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.55, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.6708203932499369, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.kappa(), 0.01);
      assertEquals(483.3, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.55, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(55.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.49751448336407733, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(11.0, evaluation0.correct(), 0.01);
      assertEquals(0.45, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(55.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(50.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.30250000000000005, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals((-9646.143307989172), evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.4954545454545455, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.45, evaluation0.errorRate(), 0.01);
      assertEquals((-482.3071653994586), evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(19.856692010826972, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(45.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.45, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.55, evaluation0.weightedTruePositiveRate(), 0.01);
      
      C45Loader c45Loader0 = new C45Loader();
      assertNotNull(c45Loader0);
      assertEquals("Reads a file that is C45 format. Can take a filestem or filestem with .names or .data appended. Assumes that path/<filestem>.names and path/<filestem>.data exist and contain the names and data respectively.", c45Loader0.globalInfo());
      assertEquals(".names", c45Loader0.getFileExtension());
      assertEquals("C4.5 data files", c45Loader0.getFileDescription());
      assertEquals("Use relative rather than absolute paths", c45Loader0.useRelativePathTipText());
      assertFalse(c45Loader0.getUseRelativePath());
      
      try { 
        c45Loader0.getNextInstance(instances0);
        fail("Expecting exception: IOException");
      
      } catch(IOException e) {
         //
         // No source has been specified
         //
         verifyException("weka.core.converters.C45Loader", e);
      }
  }

  /**
  //Test case number: 86
  /*Coverage entropy=2.0794415416798357
  */
  @Test(timeout = 4000)
  public void test086()  throws Throwable  {
      M5Rules m5Rules0 = new M5Rules();
      assertNotNull(m5Rules0);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      
      Capabilities capabilities0 = m5Rules0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(4, instances0.numAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      
      Instances instances1 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances1);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, instances1.size());
      assertEquals(1, instances1.numClasses());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(20, instances1.numInstances());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(4, instances1.numAttributes());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(3, instances1.classIndex());
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(instances1, instances0);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(4, instances0.numAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      
      evaluation0.addNumericTrainClass((-2), (-2));
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(4, instances0.numAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      
      double double0 = evaluation0.correlationCoefficient();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(4, instances0.numAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      
      RegressionByDiscretization regressionByDiscretization0 = new RegressionByDiscretization();
      assertEquals(0, RegressionByDiscretization.ESTIMATOR_HISTOGRAM);
      assertEquals(2, RegressionByDiscretization.ESTIMATOR_NORMAL);
      assertEquals(1, RegressionByDiscretization.ESTIMATOR_KERNEL);
      assertNotNull(regressionByDiscretization0);
      assertEquals("If set to true, classifier may output additional info to the console.", regressionByDiscretization0.debugTipText());
      assertEquals("Number of bins for discretization.", regressionByDiscretization0.numBinsTipText());
      assertEquals("If set to true, equal-frequency binning will be used instead of equal-width binning.", regressionByDiscretization0.useEqualFrequencyTipText());
      assertEquals(10, regressionByDiscretization0.getNumBins());
      assertEquals("Whether to minimize absolute error.", regressionByDiscretization0.minimizeAbsoluteErrorTipText());
      assertFalse(regressionByDiscretization0.getMinimizeAbsoluteError());
      assertEquals("Whether to delete empty bins after discretization.", regressionByDiscretization0.deleteEmptyBinsTipText());
      assertFalse(regressionByDiscretization0.getDeleteEmptyBins());
      assertFalse(regressionByDiscretization0.getUseEqualFrequency());
      assertEquals("The density estimator to use.", regressionByDiscretization0.estimatorTypeTipText());
      assertFalse(regressionByDiscretization0.getDebug());
      assertEquals("The base classifier to be used.", regressionByDiscretization0.classifierTipText());
      
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      instances0.randomize(mockRandom0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(4, instances0.numAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      
      SparseInstance sparseInstance0 = new SparseInstance(86);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(sparseInstance0);
      assertEquals(1.0, sparseInstance0.weight(), 0.01);
      assertEquals(86, sparseInstance0.numValues());
      assertEquals(86, sparseInstance0.numAttributes());
      
      boolean boolean0 = instances0.add((Instance) sparseInstance0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertTrue(boolean0);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(4, instances0.numAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(21, instances0.size());
      assertEquals(21.0, instances0.sumOfWeights(), 0.01);
      assertEquals(21, instances0.numInstances());
      assertEquals(1.0, sparseInstance0.weight(), 0.01);
      assertEquals(86, sparseInstance0.numValues());
      assertEquals(86, sparseInstance0.numAttributes());
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation1);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(4, instances0.numAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(21, instances0.size());
      assertEquals(21.0, instances0.sumOfWeights(), 0.01);
      assertEquals(21, instances0.numInstances());
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertTrue(evaluation1.equals((Object)evaluation0));
      
      double double1 = evaluation1.rootRelativeSquaredError();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double1, 0.01);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(4, instances0.numAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(21, instances0.size());
      assertEquals(21.0, instances0.sumOfWeights(), 0.01);
      assertEquals(21, instances0.numInstances());
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertTrue(evaluation1.equals((Object)evaluation0));
      assertEquals(double1, double0, 0.01);
      assertNotSame(instances0, instances1);
      assertNotSame(evaluation1, evaluation0);
      
      System.setCurrentTimeMillis(9);
  }

  /**
  //Test case number: 87
  /*Coverage entropy=3.2188758248681983
  */
  @Test(timeout = 4000)
  public void test087()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      
      SGDText sGDText0 = new SGDText();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(sGDText0);
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      
      Enumeration enumeration0 = testInstances0.listOptions();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(enumeration0);
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(capabilities0);
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      Object[] objectArray0 = new Object[4];
      objectArray0[0] = (Object) null;
      objectArray0[2] = (Object) evaluation0;
      double[] doubleArray0 = evaluation0.evaluateModel((Classifier) sGDText0, instances0, objectArray0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(doubleArray0);
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(0.30250000000000005, evaluation0.weightedPrecision(), 0.01);
      assertEquals(45.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(55.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.55, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.kappa(), 0.01);
      assertEquals(50.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.4954545454545455, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.55, evaluation0.weightedRecall(), 0.01);
      assertEquals((-9646.143307989172), evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.49751448336407733, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(20.0, evaluation0.numInstances(), 0.01);
      assertEquals(11.0, evaluation0.correct(), 0.01);
      assertEquals(9.0, evaluation0.incorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(134.8343446634971, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(9666.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.55, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.45, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(483.3, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(19.856692010826972, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals((-482.3071653994586), evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.9928346005413486, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.45, evaluation0.errorRate(), 0.01);
      assertEquals(90.82568807339449, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.45, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.55, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.3903225806451613, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(55.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.6708203932499369, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.45, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(4, objectArray0.length);
      assertEquals(20, doubleArray0.length);
      
      testInstances0.setWordSeparators("debug");
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals("debug", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      
      double double0 = evaluation0.m_Unclassified;
      assertEquals(0.0, double0, 0.01);
      
      String string0 = evaluation0.toSummaryString("weka/core/Capabilities.props", false);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(string0);
      assertEquals("weka/core/Capabilities.props\nCorrectly Classified Instances          11               55      %\nIncorrectly Classified Instances         9               45      %\nKappa statistic                          0     \nMean absolute error                      0.45  \nRoot mean squared error                  0.6708\nRelative absolute error                 90.8257 %\nRoot relative squared error            134.8343 %\nCoverage of cases (0.95 level)          55      %\nMean rel. region size (0.95 level)      50      %\nTotal Number of Instances               20     \n", string0);
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals("debug", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.30250000000000005, evaluation0.weightedPrecision(), 0.01);
      assertEquals(45.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(55.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.55, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.kappa(), 0.01);
      assertEquals(50.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.4954545454545455, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.55, evaluation0.weightedRecall(), 0.01);
      assertEquals((-9646.143307989172), evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.49751448336407733, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(20.0, evaluation0.numInstances(), 0.01);
      assertEquals(11.0, evaluation0.correct(), 0.01);
      assertEquals(9.0, evaluation0.incorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(134.8343446634971, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(9666.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.55, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.45, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(483.3, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(19.856692010826972, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals((-482.3071653994586), evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.9928346005413486, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.45, evaluation0.errorRate(), 0.01);
      assertEquals(90.82568807339449, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.45, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.55, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.3903225806451613, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(55.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.6708203932499369, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.45, evaluation0.weightedFalseNegativeRate(), 0.01);
  }

  /**
  //Test case number: 88
  /*Coverage entropy=2.70805020110221
  */
  @Test(timeout = 4000)
  public void test088()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(sGDText0);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(capabilities0);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      capabilities0.enableAll();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      
      CostMatrix costMatrix0 = new CostMatrix(0);
      assertNotNull(costMatrix0);
      assertEquals(0, costMatrix0.numColumns());
      assertEquals(0, costMatrix0.size());
      assertEquals(0, costMatrix0.numRows());
      
      boolean boolean0 = FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "]}e;#X*UC1BJc|%6");
      assertFalse(boolean0);
      
      Evaluation evaluation0 = new Evaluation(instances0, costMatrix0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, costMatrix0.numColumns());
      assertEquals(0, costMatrix0.size());
      assertEquals(0, costMatrix0.numRows());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      
      double double0 = evaluation0.priorEntropy();
      assertEquals(0.0, double0, 0.01);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, costMatrix0.numColumns());
      assertEquals(0, costMatrix0.size());
      assertEquals(0, costMatrix0.numRows());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      
      String string0 = evaluation0.toClassDetailsString("-v\n");
      assertNotNull(string0);
      assertEquals("-v\n\n                 TP Rate  FP Rate  Precision  Recall  F-Measure  MCC    ROC Area  PRC Area  Class\nWeighted Avg.  NaN      NaN      NaN        NaN     NaN        NaN    NaN       NaN    \n", string0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, costMatrix0.numColumns());
      assertEquals(0, costMatrix0.size());
      assertEquals(0, costMatrix0.numRows());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      
      double double1 = evaluation0.errorRate();
      assertEquals(Double.NaN, double1, 0.01);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, costMatrix0.numColumns());
      assertEquals(0, costMatrix0.size());
      assertEquals(0, costMatrix0.numRows());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertNotEquals(double1, double0, 0.01);
      
      evaluation0.addNumericTrainClass(Double.NaN, 1);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, costMatrix0.numColumns());
      assertEquals(0, costMatrix0.size());
      assertEquals(0, costMatrix0.numRows());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
  }

  /**
  //Test case number: 89
  /*Coverage entropy=2.5649493574615376
  */
  @Test(timeout = 4000)
  public void test089()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      
      SGDText sGDText0 = new SGDText();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(sGDText0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      
      Enumeration enumeration0 = testInstances0.listOptions();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(enumeration0);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(capabilities0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      
      Object[] objectArray0 = new Object[4];
      objectArray0[0] = (Object) null;
      Object object0 = new Object();
      assertNotNull(object0);
      
      objectArray0[2] = (Object) evaluation0;
      boolean boolean0 = FileSystemHandling.createFolder((EvoSuiteFile) null);
      assertFalse(boolean0);
      
      objectArray0[3] = (Object) sGDText0;
      double[] doubleArray0 = evaluation0.evaluateModel((Classifier) sGDText0, instances0, objectArray0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(doubleArray0);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0.55, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.3903225806451613, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(11.0, evaluation0.correct(), 0.01);
      assertEquals(0.9928346005413486, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.55, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals((-9646.143307989172), evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.49751448336407733, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.kappa(), 0.01);
      assertEquals(483.3, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.6708203932499369, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(90.82568807339449, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(50.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(9.0, evaluation0.incorrect(), 0.01);
      assertEquals(20.0, evaluation0.numInstances(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.4954545454545455, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.55, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.30250000000000005, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.45, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(134.8343446634971, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(55.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(9666.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(45.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.45, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.55, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.45, evaluation0.errorRate(), 0.01);
      assertEquals((-482.3071653994586), evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(19.856692010826972, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.45, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(55.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(4, objectArray0.length);
      assertEquals(20, doubleArray0.length);
      
      double double0 = evaluation0.weightedAreaUnderROC();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0.5, double0, 0.01);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.55, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.3903225806451613, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(11.0, evaluation0.correct(), 0.01);
      assertEquals(0.9928346005413486, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.55, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals((-9646.143307989172), evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.49751448336407733, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.kappa(), 0.01);
      assertEquals(483.3, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.6708203932499369, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(90.82568807339449, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(50.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(9.0, evaluation0.incorrect(), 0.01);
      assertEquals(20.0, evaluation0.numInstances(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.4954545454545455, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.55, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.30250000000000005, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.45, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(134.8343446634971, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(55.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(9666.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(45.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.45, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.55, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.45, evaluation0.errorRate(), 0.01);
      assertEquals((-482.3071653994586), evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(19.856692010826972, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.45, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(55.0, evaluation0.pctCorrect(), 0.01);
      
      String string0 = evaluation0.toCumulativeMarginDistributionString();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(string0);
      assertEquals(" -1      45    \n  1     100    \n", string0);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.55, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.3903225806451613, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(11.0, evaluation0.correct(), 0.01);
      assertEquals(0.9928346005413486, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.55, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals((-9646.143307989172), evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.49751448336407733, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.kappa(), 0.01);
      assertEquals(483.3, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.6708203932499369, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(90.82568807339449, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(50.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(9.0, evaluation0.incorrect(), 0.01);
      assertEquals(20.0, evaluation0.numInstances(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.4954545454545455, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.55, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.30250000000000005, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.45, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(134.8343446634971, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(55.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(9666.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(45.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.45, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.55, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.45, evaluation0.errorRate(), 0.01);
      assertEquals((-482.3071653994586), evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(19.856692010826972, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.45, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(55.0, evaluation0.pctCorrect(), 0.01);
      
      C45Loader c45Loader0 = new C45Loader();
      assertNotNull(c45Loader0);
      assertEquals("Reads a file that is C45 format. Can take a filestem or filestem with .names or .data appended. Assumes that path/<filestem>.names and path/<filestem>.data exist and contain the names and data respectively.", c45Loader0.globalInfo());
      assertEquals(".names", c45Loader0.getFileExtension());
      assertEquals("Use relative rather than absolute paths", c45Loader0.useRelativePathTipText());
      assertFalse(c45Loader0.getUseRelativePath());
      assertEquals("C4.5 data files", c45Loader0.getFileDescription());
      
      try { 
        c45Loader0.getNextInstance(instances0);
        fail("Expecting exception: IOException");
      
      } catch(IOException e) {
         //
         // No source has been specified
         //
         verifyException("weka.core.converters.C45Loader", e);
      }
  }

  /**
  //Test case number: 90
  /*Coverage entropy=3.4339872044851467
  */
  @Test(timeout = 4000)
  public void test090()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      
      SGDText sGDText0 = new SGDText();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(sGDText0);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      
      Enumeration enumeration0 = testInstances0.listOptions();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(enumeration0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(capabilities0);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      
      Object[] objectArray0 = new Object[4];
      objectArray0[0] = (Object) null;
      Object object0 = new Object();
      assertNotNull(object0);
      
      objectArray0[2] = (Object) evaluation0;
      boolean boolean0 = FileSystemHandling.createFolder((EvoSuiteFile) null);
      assertFalse(boolean0);
      
      objectArray0[3] = (Object) sGDText0;
      double[] doubleArray0 = evaluation0.evaluateModel((Classifier) sGDText0, instances0, objectArray0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(doubleArray0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.45, evaluation0.errorRate(), 0.01);
      assertEquals(0.49751448336407733, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.45, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(55.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(50.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(483.3, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.55, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.30250000000000005, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(55.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(11.0, evaluation0.correct(), 0.01);
      assertEquals(20.0, evaluation0.numInstances(), 0.01);
      assertEquals((-482.3071653994586), evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.4954545454545455, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.45, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(45.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals((-9646.143307989172), evaluation0.SFEntropyGain(), 0.01);
      assertEquals(19.856692010826972, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.45, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.55, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.55, evaluation0.weightedRecall(), 0.01);
      assertEquals(9666.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(134.8343446634971, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(9.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.6708203932499369, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(90.82568807339449, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.9928346005413486, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.3903225806451613, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.55, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(4, objectArray0.length);
      assertEquals(20, doubleArray0.length);
      
      double double0 = evaluation0.weightedAreaUnderROC();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0.5, double0, 0.01);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.45, evaluation0.errorRate(), 0.01);
      assertEquals(0.49751448336407733, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.45, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(55.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(50.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(483.3, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.55, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.30250000000000005, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(55.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(11.0, evaluation0.correct(), 0.01);
      assertEquals(20.0, evaluation0.numInstances(), 0.01);
      assertEquals((-482.3071653994586), evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.4954545454545455, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.45, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(45.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals((-9646.143307989172), evaluation0.SFEntropyGain(), 0.01);
      assertEquals(19.856692010826972, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.45, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.55, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.55, evaluation0.weightedRecall(), 0.01);
      assertEquals(9666.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(134.8343446634971, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(9.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.6708203932499369, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(90.82568807339449, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.9928346005413486, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.3903225806451613, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.55, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      
      String string0 = evaluation0.toClassDetailsString("weka/core/Capabilities.props");
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(string0);
      assertEquals("weka/core/Capabilities.props\n                 TP Rate  FP Rate  Precision  Recall  F-Measure  MCC    ROC Area  PRC Area  Class\n                 1        1        0.55       1       0.71       0      0.5       0.55      class1\n                 0        0        0          0       0          0      0.5       0.45      class2\nWeighted Avg.    0.55     0.55     0.303      0.55    0.39       0      0.5       0.505\n", string0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.45, evaluation0.errorRate(), 0.01);
      assertEquals(0.49751448336407733, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.45, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(55.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(50.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(483.3, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.55, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.30250000000000005, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(55.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(11.0, evaluation0.correct(), 0.01);
      assertEquals(20.0, evaluation0.numInstances(), 0.01);
      assertEquals((-482.3071653994586), evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.4954545454545455, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.45, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(45.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals((-9646.143307989172), evaluation0.SFEntropyGain(), 0.01);
      assertEquals(19.856692010826972, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.45, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.55, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.55, evaluation0.weightedRecall(), 0.01);
      assertEquals(9666.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(134.8343446634971, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(9.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.6708203932499369, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(90.82568807339449, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.9928346005413486, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.3903225806451613, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.55, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
  }

  /**
  //Test case number: 91
  /*Coverage entropy=1.6152209706275102
  */
  @Test(timeout = 4000)
  public void test091()  throws Throwable  {
      M5Rules m5Rules0 = new M5Rules();
      assertNotNull(m5Rules0);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      
      Capabilities capabilities0 = m5Rules0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numClasses());
      
      Instances instances1 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances1);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals(4, instances1.numAttributes());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(3, instances1.classIndex());
      assertEquals(20, instances1.size());
      assertEquals(20, instances1.numInstances());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(1, instances1.numClasses());
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(instances1, instances0);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      
      evaluation0.addNumericTrainClass((-2), (-2));
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      
      double double0 = evaluation0.correlationCoefficient();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      
      RegressionByDiscretization regressionByDiscretization0 = new RegressionByDiscretization();
      assertEquals(1, RegressionByDiscretization.ESTIMATOR_KERNEL);
      assertEquals(0, RegressionByDiscretization.ESTIMATOR_HISTOGRAM);
      assertEquals(2, RegressionByDiscretization.ESTIMATOR_NORMAL);
      assertNotNull(regressionByDiscretization0);
      assertFalse(regressionByDiscretization0.getDeleteEmptyBins());
      assertFalse(regressionByDiscretization0.getMinimizeAbsoluteError());
      assertEquals("The density estimator to use.", regressionByDiscretization0.estimatorTypeTipText());
      assertEquals("Whether to minimize absolute error.", regressionByDiscretization0.minimizeAbsoluteErrorTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", regressionByDiscretization0.debugTipText());
      assertEquals("Number of bins for discretization.", regressionByDiscretization0.numBinsTipText());
      assertEquals("If set to true, equal-frequency binning will be used instead of equal-width binning.", regressionByDiscretization0.useEqualFrequencyTipText());
      assertEquals(10, regressionByDiscretization0.getNumBins());
      assertFalse(regressionByDiscretization0.getUseEqualFrequency());
      assertEquals("The base classifier to be used.", regressionByDiscretization0.classifierTipText());
      assertEquals("Whether to delete empty bins after discretization.", regressionByDiscretization0.deleteEmptyBinsTipText());
      assertFalse(regressionByDiscretization0.getDebug());
      
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      instances0.randomize(mockRandom0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(4, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numClasses());
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      
      SparseInstance sparseInstance0 = new SparseInstance(86);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(sparseInstance0);
      assertEquals(86, sparseInstance0.numValues());
      assertEquals(1.0, sparseInstance0.weight(), 0.01);
      assertEquals(86, sparseInstance0.numAttributes());
      
      double[] doubleArray0 = new double[2];
      doubleArray0[1] = (double) 86;
      try { 
        evaluation0.evaluationForSingleInstance(doubleArray0, sparseInstance0, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 92
  /*Coverage entropy=1.7917594692280547
  */
  @Test(timeout = 4000)
  public void test092()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(sGDText0);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertNotNull(capabilities0);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      
      capabilities0.enableAll();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(5, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(5, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      
      evaluation0.m_SumSchemeEntropy = (double) (-1);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(5, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.POSITIVE_INFINITY, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals((-1.0), evaluation0.SFSchemeEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(1.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NEGATIVE_INFINITY, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      
      java.util.Random random0 = instances0.getRandomNumberGenerator(0);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(random0);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(5, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      
      evaluation0.useNoPriors();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(5, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals((-1.0), evaluation0.SFSchemeEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NEGATIVE_INFINITY, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      
      DenseInstance denseInstance0 = new DenseInstance((-2), (double[]) null);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(denseInstance0);
      assertEquals((-2.0), denseInstance0.weight(), 0.01);
      
      double double0 = evaluation0.SFMeanPriorEntropy();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(5, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals((-1.0), evaluation0.SFSchemeEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NEGATIVE_INFINITY, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      
      double double1 = evaluation0.coverageOfTestCasesByPredictedRegions();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(Double.NaN, double1, 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(5, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals((-1.0), evaluation0.SFSchemeEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NEGATIVE_INFINITY, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(double1, double0, 0.01);
      
      double double2 = evaluation0.KBInformation();
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(Double.NaN, double2, 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(5, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals((-1.0), evaluation0.SFSchemeEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NEGATIVE_INFINITY, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(double2, double1, 0.01);
      assertEquals(double2, double0, 0.01);
  }

  /**
  //Test case number: 93
  /*Coverage entropy=2.6390573296152584
  */
  @Test(timeout = 4000)
  public void test093()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      
      SGDText sGDText0 = new SGDText();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(sGDText0);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(capabilities0);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      
      Object[] objectArray0 = new Object[4];
      objectArray0[0] = (Object) null;
      boolean boolean0 = FileSystemHandling.createFolder((EvoSuiteFile) null);
      assertFalse(boolean0);
      
      objectArray0[3] = (Object) sGDText0;
      double[] doubleArray0 = evaluation0.evaluateModel((Classifier) sGDText0, instances0, objectArray0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(doubleArray0);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(90.82568807339449, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(483.3, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.4954545454545455, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.6708203932499369, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(20.0, evaluation0.numInstances(), 0.01);
      assertEquals(45.0, evaluation0.pctIncorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(11.0, evaluation0.correct(), 0.01);
      assertEquals(0.49751448336407733, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(50.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.55, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.9928346005413486, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.3903225806451613, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.55, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.45, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals((-9646.143307989172), evaluation0.SFEntropyGain(), 0.01);
      assertEquals(55.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(9666.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.55, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(9.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.45, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.55, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals((-482.3071653994586), evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(19.856692010826972, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(55.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.45, evaluation0.errorRate(), 0.01);
      assertEquals(134.8343446634971, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.30250000000000005, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.45, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(4, objectArray0.length);
      assertEquals(20, doubleArray0.length);
      
      byte[] byteArray0 = new byte[2];
      byteArray0[0] = (byte)31;
      String string0 = evaluation0.toMatrixString(" ");
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(string0);
      assertEquals(" \n  a  b   <-- classified as\n 11  0 |  a = class1\n  9  0 |  b = class2\n", string0);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(90.82568807339449, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(483.3, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.4954545454545455, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.6708203932499369, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(20.0, evaluation0.numInstances(), 0.01);
      assertEquals(45.0, evaluation0.pctIncorrect(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(11.0, evaluation0.correct(), 0.01);
      assertEquals(0.49751448336407733, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(50.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.55, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.9928346005413486, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.3903225806451613, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.55, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.45, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals((-9646.143307989172), evaluation0.SFEntropyGain(), 0.01);
      assertEquals(55.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(9666.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.55, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(9.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.45, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.55, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals((-482.3071653994586), evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(19.856692010826972, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(55.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.45, evaluation0.errorRate(), 0.01);
      assertEquals(134.8343446634971, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.30250000000000005, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.45, evaluation0.meanAbsoluteError(), 0.01);
      
      J48 j48_0 = new J48();
      assertNotNull(j48_0);
      assertFalse(j48_0.getUseLaplace());
      assertFalse(j48_0.getBinarySplits());
      assertEquals("The minimum number of instances per leaf.", j48_0.minNumObjTipText());
      assertTrue(j48_0.getCollapseTree());
      assertEquals(2, j48_0.getMinNumObj());
      assertEquals("Whether pruning is performed.", j48_0.unprunedTipText());
      assertEquals("Whether counts at leaves are smoothed based on Laplace.", j48_0.useLaplaceTipText());
      assertEquals("Whether to save the training data for visualization.", j48_0.saveInstanceDataTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", j48_0.debugTipText());
      assertEquals(3, j48_0.getNumFolds());
      assertTrue(j48_0.getUseMDLcorrection());
      assertEquals("Whether reduced-error pruning is used instead of C.4.5 pruning.", j48_0.reducedErrorPruningTipText());
      assertEquals("The confidence factor used for pruning (smaller values incur more pruning).", j48_0.confidenceFactorTipText());
      assertEquals("Whether MDL correction is used when finding splits on numeric attributes.", j48_0.useMDLcorrectionTipText());
      assertTrue(j48_0.getSubtreeRaising());
      assertEquals(1, j48_0.graphType());
      assertFalse(j48_0.getDebug());
      assertFalse(j48_0.getSaveInstanceData());
      assertFalse(j48_0.getUnpruned());
      assertEquals(1, j48_0.getSeed());
      assertEquals(0.25F, j48_0.getConfidenceFactor(), 0.01F);
      assertEquals("Whether parts are removed that do not reduce training error.", j48_0.collapseTreeTipText());
      assertFalse(j48_0.getReducedErrorPruning());
      assertEquals("Whether to use binary splits on nominal attributes when building the trees.", j48_0.binarySplitsTipText());
      assertEquals("Determines the amount of data used for reduced-error pruning.  One fold is used for pruning, the rest for growing the tree.", j48_0.numFoldsTipText());
      assertEquals("The seed used for randomizing the data when reduced-error pruning is used.", j48_0.seedTipText());
      assertEquals("Whether to consider the subtree raising operation when pruning.", j48_0.subtreeRaisingTipText());
      
      MockRandom mockRandom0 = new MockRandom((-1158L));
      assertNotNull(mockRandom0);
      
      Evaluation evaluation1 = new Evaluation(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation1);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertFalse(evaluation1.equals((Object)evaluation0));
      
      double double0 = evaluation1.SFMeanPriorEntropy();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(0, testInstances0.getNumDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(0.0, evaluation1.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation1.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation1.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation1.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation1.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation1.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation1.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation1.avgCost(), 0.01);
      assertEquals(0.0, evaluation1.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation1.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation1.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation1.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation1.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation1.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation1.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation1.correct(), 0.01);
      assertFalse(evaluation1.getDiscardPredictions());
      assertFalse(evaluation1.equals((Object)evaluation0));
      assertNotSame(evaluation1, evaluation0);
  }

  /**
  //Test case number: 94
  /*Coverage entropy=1.945910149055313
  */
  @Test(timeout = 4000)
  public void test094()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      double double0 = evaluation0.m_Correct;
      assertEquals(0.0, double0, 0.01);
      
      double double1 = evaluation0.kappa();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(1.0, double1, 0.01);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertNotEquals(double1, double0, 0.01);
      
      double double2 = evaluation0.priorEntropy();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0.9940302114769565, double2, 0.01);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(double2, double1, 0.01);
      assertNotEquals(double2, double0, 0.01);
      
      evaluation0.useNoPriors();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      double[] doubleArray0 = new double[2];
      doubleArray0[0] = (double) (-1);
      doubleArray0[1] = 0.9940302114769565;
      DenseInstance denseInstance0 = new DenseInstance((-2), doubleArray0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(denseInstance0);
      assertEquals(2, denseInstance0.numValues());
      assertEquals(2, denseInstance0.numAttributes());
      assertEquals((-2.0), denseInstance0.weight(), 0.01);
      assertEquals(2, doubleArray0.length);
      assertArrayEquals(new double[] {(-1.0), 0.9940302114769565}, doubleArray0, 0.01);
      
      double double3 = evaluation0.SFEntropyGain();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double3, 0.01);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertNotEquals(double3, double2, 0.01);
      assertNotEquals(double3, double0, 0.01);
      assertNotEquals(double3, double1, 0.01);
      
      double double4 = evaluation0.priorEntropy();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double4, 0.01);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(double4, double3, 0.01);
      assertNotEquals(double4, double0, 0.01);
      assertNotEquals(double4, double1, 0.01);
      assertNotEquals(double4, double2, 0.01);
  }

  /**
  //Test case number: 95
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test095()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      
      SGDText sGDText0 = new SGDText();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(sGDText0);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      
      byte[] byteArray0 = new byte[0];
      boolean boolean0 = FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      assertFalse(boolean0);
      assertEquals(0, byteArray0.length);
      assertArrayEquals(new byte[] {}, byteArray0);
      
      Enumeration enumeration0 = testInstances0.listOptions();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(enumeration0);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(capabilities0);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      Object[] objectArray0 = new Object[4];
      objectArray0[0] = (Object) null;
      RegressionByDiscretization regressionByDiscretization0 = new RegressionByDiscretization();
      assertEquals(0, RegressionByDiscretization.ESTIMATOR_HISTOGRAM);
      assertEquals(2, RegressionByDiscretization.ESTIMATOR_NORMAL);
      assertEquals(1, RegressionByDiscretization.ESTIMATOR_KERNEL);
      assertNotNull(regressionByDiscretization0);
      assertFalse(regressionByDiscretization0.getDeleteEmptyBins());
      assertFalse(regressionByDiscretization0.getMinimizeAbsoluteError());
      assertEquals("Whether to delete empty bins after discretization.", regressionByDiscretization0.deleteEmptyBinsTipText());
      assertFalse(regressionByDiscretization0.getUseEqualFrequency());
      assertFalse(regressionByDiscretization0.getDebug());
      assertEquals("The density estimator to use.", regressionByDiscretization0.estimatorTypeTipText());
      assertEquals("Whether to minimize absolute error.", regressionByDiscretization0.minimizeAbsoluteErrorTipText());
      assertEquals("If set to true, equal-frequency binning will be used instead of equal-width binning.", regressionByDiscretization0.useEqualFrequencyTipText());
      assertEquals(10, regressionByDiscretization0.getNumBins());
      assertEquals("The base classifier to be used.", regressionByDiscretization0.classifierTipText());
      assertEquals("Number of bins for discretization.", regressionByDiscretization0.numBinsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", regressionByDiscretization0.debugTipText());
      
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      mockRandom0.setSeed((-2));
      instances0.randomize(mockRandom0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      
      REPTree rEPTree0 = new REPTree();
      assertNotNull(rEPTree0);
      assertEquals("Determines the amount of data used for pruning. One fold is used for pruning, the rest for growing the rules.", rEPTree0.numFoldsTipText());
      assertEquals((-1), rEPTree0.getMaxDepth());
      assertFalse(rEPTree0.getDebug());
      assertEquals("Fast decision tree learner. Builds a decision/regression tree using information gain/variance and prunes it using reduced-error pruning (with backfitting).  Only sorts values for numeric attributes once. Missing values are dealt with by splitting the corresponding instances into pieces (i.e. as in C4.5).", rEPTree0.globalInfo());
      assertEquals(2.0, rEPTree0.getMinNum(), 0.01);
      assertEquals("Whether pruning is performed.", rEPTree0.noPruningTipText());
      assertEquals("The minimum total weight of the instances in a leaf.", rEPTree0.minNumTipText());
      assertEquals("The seed used for randomizing the data.", rEPTree0.seedTipText());
      assertFalse(rEPTree0.getSpreadInitialCount());
      assertEquals(1, rEPTree0.graphType());
      assertEquals(3, rEPTree0.getNumFolds());
      assertEquals(0.0, rEPTree0.getInitialCount(), 0.01);
      assertEquals(1, rEPTree0.getSeed());
      assertEquals("If set to true, classifier may output additional info to the console.", rEPTree0.debugTipText());
      assertEquals(0.001, rEPTree0.getMinVarianceProp(), 0.01);
      assertEquals("Spread initial count across all values instead of using the count per value.", rEPTree0.spreadInitialCountTipText());
      assertEquals("The minimum proportion of the variance on all the data that needs to be present at a node in order for splitting to be performed in regression trees.", rEPTree0.minVariancePropTipText());
      assertEquals("The maximum tree depth (-1 for no restriction).", rEPTree0.maxDepthTipText());
      assertEquals("Initial class value count.", rEPTree0.initialCountTipText());
      assertFalse(rEPTree0.getNoPruning());
      
      Predicate<Object> predicate0 = Predicate.isEqual((Object) rEPTree0);
      assertNotNull(predicate0);
      assertEquals("Determines the amount of data used for pruning. One fold is used for pruning, the rest for growing the rules.", rEPTree0.numFoldsTipText());
      assertEquals((-1), rEPTree0.getMaxDepth());
      assertFalse(rEPTree0.getDebug());
      assertEquals("Fast decision tree learner. Builds a decision/regression tree using information gain/variance and prunes it using reduced-error pruning (with backfitting).  Only sorts values for numeric attributes once. Missing values are dealt with by splitting the corresponding instances into pieces (i.e. as in C4.5).", rEPTree0.globalInfo());
      assertEquals(2.0, rEPTree0.getMinNum(), 0.01);
      assertEquals("Whether pruning is performed.", rEPTree0.noPruningTipText());
      assertEquals("The minimum total weight of the instances in a leaf.", rEPTree0.minNumTipText());
      assertEquals("The seed used for randomizing the data.", rEPTree0.seedTipText());
      assertFalse(rEPTree0.getSpreadInitialCount());
      assertEquals(1, rEPTree0.graphType());
      assertEquals(3, rEPTree0.getNumFolds());
      assertEquals(0.0, rEPTree0.getInitialCount(), 0.01);
      assertEquals(1, rEPTree0.getSeed());
      assertEquals("If set to true, classifier may output additional info to the console.", rEPTree0.debugTipText());
      assertEquals(0.001, rEPTree0.getMinVarianceProp(), 0.01);
      assertEquals("Spread initial count across all values instead of using the count per value.", rEPTree0.spreadInitialCountTipText());
      assertEquals("The minimum proportion of the variance on all the data that needs to be present at a node in order for splitting to be performed in regression trees.", rEPTree0.minVariancePropTipText());
      assertEquals("The maximum tree depth (-1 for no restriction).", rEPTree0.maxDepthTipText());
      assertEquals("Initial class value count.", rEPTree0.initialCountTipText());
      assertFalse(rEPTree0.getNoPruning());
      
      Predicate<Object> predicate1 = predicate0.negate();
      assertNotNull(predicate1);
      assertEquals("Determines the amount of data used for pruning. One fold is used for pruning, the rest for growing the rules.", rEPTree0.numFoldsTipText());
      assertEquals((-1), rEPTree0.getMaxDepth());
      assertFalse(rEPTree0.getDebug());
      assertEquals("Fast decision tree learner. Builds a decision/regression tree using information gain/variance and prunes it using reduced-error pruning (with backfitting).  Only sorts values for numeric attributes once. Missing values are dealt with by splitting the corresponding instances into pieces (i.e. as in C4.5).", rEPTree0.globalInfo());
      assertEquals(2.0, rEPTree0.getMinNum(), 0.01);
      assertEquals("Whether pruning is performed.", rEPTree0.noPruningTipText());
      assertEquals("The minimum total weight of the instances in a leaf.", rEPTree0.minNumTipText());
      assertEquals("The seed used for randomizing the data.", rEPTree0.seedTipText());
      assertFalse(rEPTree0.getSpreadInitialCount());
      assertEquals(1, rEPTree0.graphType());
      assertEquals(3, rEPTree0.getNumFolds());
      assertEquals(0.0, rEPTree0.getInitialCount(), 0.01);
      assertEquals(1, rEPTree0.getSeed());
      assertEquals("If set to true, classifier may output additional info to the console.", rEPTree0.debugTipText());
      assertEquals(0.001, rEPTree0.getMinVarianceProp(), 0.01);
      assertEquals("Spread initial count across all values instead of using the count per value.", rEPTree0.spreadInitialCountTipText());
      assertEquals("The minimum proportion of the variance on all the data that needs to be present at a node in order for splitting to be performed in regression trees.", rEPTree0.minVariancePropTipText());
      assertEquals("The maximum tree depth (-1 for no restriction).", rEPTree0.maxDepthTipText());
      assertEquals("Initial class value count.", rEPTree0.initialCountTipText());
      assertFalse(rEPTree0.getNoPruning());
      assertFalse(predicate1.equals((Object)predicate0));
      
      Predicate<Object> predicate2 = predicate1.or(predicate0);
      assertNotNull(predicate2);
      assertEquals("Determines the amount of data used for pruning. One fold is used for pruning, the rest for growing the rules.", rEPTree0.numFoldsTipText());
      assertEquals((-1), rEPTree0.getMaxDepth());
      assertFalse(rEPTree0.getDebug());
      assertEquals("Fast decision tree learner. Builds a decision/regression tree using information gain/variance and prunes it using reduced-error pruning (with backfitting).  Only sorts values for numeric attributes once. Missing values are dealt with by splitting the corresponding instances into pieces (i.e. as in C4.5).", rEPTree0.globalInfo());
      assertEquals(2.0, rEPTree0.getMinNum(), 0.01);
      assertEquals("Whether pruning is performed.", rEPTree0.noPruningTipText());
      assertEquals("The minimum total weight of the instances in a leaf.", rEPTree0.minNumTipText());
      assertEquals("The seed used for randomizing the data.", rEPTree0.seedTipText());
      assertFalse(rEPTree0.getSpreadInitialCount());
      assertEquals(1, rEPTree0.graphType());
      assertEquals(3, rEPTree0.getNumFolds());
      assertEquals(0.0, rEPTree0.getInitialCount(), 0.01);
      assertEquals(1, rEPTree0.getSeed());
      assertEquals("If set to true, classifier may output additional info to the console.", rEPTree0.debugTipText());
      assertEquals(0.001, rEPTree0.getMinVarianceProp(), 0.01);
      assertEquals("Spread initial count across all values instead of using the count per value.", rEPTree0.spreadInitialCountTipText());
      assertEquals("The minimum proportion of the variance on all the data that needs to be present at a node in order for splitting to be performed in regression trees.", rEPTree0.minVariancePropTipText());
      assertEquals("The maximum tree depth (-1 for no restriction).", rEPTree0.maxDepthTipText());
      assertEquals("Initial class value count.", rEPTree0.initialCountTipText());
      assertFalse(rEPTree0.getNoPruning());
      assertFalse(predicate1.equals((Object)predicate0));
      assertFalse(predicate2.equals((Object)predicate0));
      assertFalse(predicate2.equals((Object)predicate1));
      assertFalse(predicate0.equals((Object)predicate1));
      
      boolean boolean1 = instances0.removeIf(predicate2);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertTrue(boolean1);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Determines the amount of data used for pruning. One fold is used for pruning, the rest for growing the rules.", rEPTree0.numFoldsTipText());
      assertEquals((-1), rEPTree0.getMaxDepth());
      assertFalse(rEPTree0.getDebug());
      assertEquals("Fast decision tree learner. Builds a decision/regression tree using information gain/variance and prunes it using reduced-error pruning (with backfitting).  Only sorts values for numeric attributes once. Missing values are dealt with by splitting the corresponding instances into pieces (i.e. as in C4.5).", rEPTree0.globalInfo());
      assertEquals(2.0, rEPTree0.getMinNum(), 0.01);
      assertEquals("Whether pruning is performed.", rEPTree0.noPruningTipText());
      assertEquals("The minimum total weight of the instances in a leaf.", rEPTree0.minNumTipText());
      assertEquals("The seed used for randomizing the data.", rEPTree0.seedTipText());
      assertFalse(rEPTree0.getSpreadInitialCount());
      assertEquals(1, rEPTree0.graphType());
      assertEquals(3, rEPTree0.getNumFolds());
      assertEquals(0.0, rEPTree0.getInitialCount(), 0.01);
      assertEquals(1, rEPTree0.getSeed());
      assertEquals("If set to true, classifier may output additional info to the console.", rEPTree0.debugTipText());
      assertEquals(0.001, rEPTree0.getMinVarianceProp(), 0.01);
      assertEquals("Spread initial count across all values instead of using the count per value.", rEPTree0.spreadInitialCountTipText());
      assertEquals("The minimum proportion of the variance on all the data that needs to be present at a node in order for splitting to be performed in regression trees.", rEPTree0.minVariancePropTipText());
      assertEquals("The maximum tree depth (-1 for no restriction).", rEPTree0.maxDepthTipText());
      assertEquals("Initial class value count.", rEPTree0.initialCountTipText());
      assertFalse(rEPTree0.getNoPruning());
      assertFalse(predicate1.equals((Object)predicate0));
      assertFalse(predicate1.equals((Object)predicate2));
      assertFalse(predicate2.equals((Object)predicate0));
      assertFalse(predicate2.equals((Object)predicate1));
      assertFalse(boolean1 == boolean0);
      assertFalse(predicate0.equals((Object)predicate1));
      assertFalse(predicate0.equals((Object)predicate2));
      
      SparseInstance sparseInstance0 = new SparseInstance(0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(sparseInstance0);
      assertEquals(0, sparseInstance0.numAttributes());
      assertEquals(0, sparseInstance0.numValues());
      assertEquals(1.0, sparseInstance0.weight(), 0.01);
      
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = (double) 1;
      doubleArray0[1] = (double) 86;
      doubleArray0[2] = 2498.2184;
      doubleArray0[3] = (double) 2;
      double double0 = evaluation0.m_SumAbsErr;
      assertEquals(0.0, double0, 0.01);
      
      evaluation0.useNoPriors();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      DenseInstance denseInstance0 = new DenseInstance(2, doubleArray0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(denseInstance0);
      assertEquals(4, denseInstance0.numValues());
      assertEquals(4, denseInstance0.numAttributes());
      assertEquals(2.0, denseInstance0.weight(), 0.01);
      assertEquals(4, doubleArray0.length);
      assertArrayEquals(new double[] {1.0, 86.0, 2498.2184, 2.0}, doubleArray0, 0.01);
      
      double double1 = evaluation0.m_SumKBInfo;
      assertEquals(0.0, double1, 0.01);
      assertEquals(double1, double0, 0.01);
      
      double double2 = evaluation0.sizeOfPredictedRegions();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(Double.NaN, double2, 0.01);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertNotEquals(double2, double1, 0.01);
      assertNotEquals(double2, double0, 0.01);
  }

  /**
  //Test case number: 96
  /*Coverage entropy=1.7917594692280547
  */
  @Test(timeout = 4000)
  public void test096()  throws Throwable  {
      M5Rules m5Rules0 = new M5Rules();
      assertNotNull(m5Rules0);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      
      Capabilities capabilities0 = m5Rules0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNumeric());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.classIndex());
      assertEquals(4, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      
      Instances instances1 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances1);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances1.relationName());
      assertEquals(20, instances1.numInstances());
      assertEquals(1, instances1.numClasses());
      assertEquals(3, instances1.classIndex());
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(20, instances1.size());
      assertEquals(4, instances1.numAttributes());
      assertFalse(instances1.equals((Object)instances0));
      assertNotSame(instances1, instances0);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.classIndex());
      assertEquals(4, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      
      evaluation0.addNumericTrainClass((-2), (-2));
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.classIndex());
      assertEquals(4, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      
      double double0 = evaluation0.correlationCoefficient();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.classIndex());
      assertEquals(4, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertFalse(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      
      RegressionByDiscretization regressionByDiscretization0 = new RegressionByDiscretization();
      assertEquals(1, RegressionByDiscretization.ESTIMATOR_KERNEL);
      assertEquals(2, RegressionByDiscretization.ESTIMATOR_NORMAL);
      assertEquals(0, RegressionByDiscretization.ESTIMATOR_HISTOGRAM);
      assertNotNull(regressionByDiscretization0);
      assertEquals("The density estimator to use.", regressionByDiscretization0.estimatorTypeTipText());
      assertFalse(regressionByDiscretization0.getUseEqualFrequency());
      assertFalse(regressionByDiscretization0.getDeleteEmptyBins());
      assertEquals("The base classifier to be used.", regressionByDiscretization0.classifierTipText());
      assertEquals("Whether to delete empty bins after discretization.", regressionByDiscretization0.deleteEmptyBinsTipText());
      assertFalse(regressionByDiscretization0.getDebug());
      assertEquals("Number of bins for discretization.", regressionByDiscretization0.numBinsTipText());
      assertEquals("If set to true, equal-frequency binning will be used instead of equal-width binning.", regressionByDiscretization0.useEqualFrequencyTipText());
      assertEquals(10, regressionByDiscretization0.getNumBins());
      assertEquals("If set to true, classifier may output additional info to the console.", regressionByDiscretization0.debugTipText());
      assertEquals("Whether to minimize absolute error.", regressionByDiscretization0.minimizeAbsoluteErrorTipText());
      assertFalse(regressionByDiscretization0.getMinimizeAbsoluteError());
      
      int int0 = 86;
      GaussianProcesses gaussianProcesses0 = new GaussianProcesses();
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertNotNull(gaussianProcesses0);
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertFalse(gaussianProcesses0.getDebug());
      
      Capabilities capabilities1 = gaussianProcesses0.getCapabilities();
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertNotNull(capabilities1);
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals(1, capabilities1.getMinimumNumberInstances());
      assertTrue(capabilities1.hasDependencies());
      assertFalse(capabilities1.equals((Object)capabilities0));
      assertNotSame(capabilities1, capabilities0);
      
      boolean boolean0 = capabilities0.supports(capabilities1);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertTrue(boolean0);
      assertEquals("Whether to use unsmoothed predictions.", m5Rules0.useUnsmoothedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5Rules0.minNumInstancesTipText());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5Rules0.unprunedTipText());
      assertEquals(4.0, m5Rules0.getMinNumInstances(), 0.01);
      assertFalse(m5Rules0.getDebug());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5Rules0.generateRulesTipText());
      assertFalse(m5Rules0.getUnpruned());
      assertFalse(m5Rules0.getUseUnsmoothed());
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5Rules0.buildRegressionTreeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", m5Rules0.debugTipText());
      assertFalse(m5Rules0.getBuildRegressionTree());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals(1, capabilities1.getMinimumNumberInstances());
      assertTrue(capabilities1.hasDependencies());
      assertFalse(capabilities0.equals((Object)capabilities1));
      assertFalse(capabilities1.equals((Object)capabilities0));
      assertNotSame(capabilities0, capabilities1);
      assertNotSame(capabilities1, capabilities0);
      
      SparseInstance sparseInstance0 = new SparseInstance(86);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(sparseInstance0);
      assertEquals(86, sparseInstance0.numAttributes());
      assertEquals(1.0, sparseInstance0.weight(), 0.01);
      assertEquals(86, sparseInstance0.numValues());
      
      double[] doubleArray0 = new double[2];
      try { 
        evaluation0.priorEntropy();
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't compute entropy of class prior: class numeric!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  /**
  //Test case number: 97
  /*Coverage entropy=1.6094379124341005
  */
  @Test(timeout = 4000)
  public void test097()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(sGDText0);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(capabilities0);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      
      capabilities0.enableAll();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(4, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(4, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      
      java.util.Random random0 = instances0.getRandomNumberGenerator(0);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(random0);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(4, instances0.classIndex());
      
      String string0 = capabilities0.getRevision();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertNotNull(string0);
      assertEquals("9134", string0);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      
      evaluation0.useNoPriors();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(4, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      
      double double0 = evaluation0.rootMeanPriorSquaredError();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(4, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      
      DenseInstance denseInstance0 = new DenseInstance((-2), (double[]) null);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(denseInstance0);
      assertEquals((-2.0), denseInstance0.weight(), 0.01);
      
      double double1 = evaluation0.SFEntropyGain();
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(Double.NaN, double1, 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getDebug());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(5, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(4, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(double1, double0, 0.01);
  }

  /**
  //Test case number: 98
  /*Coverage entropy=2.0679759122939765
  */
  @Test(timeout = 4000)
  public void test098()  throws Throwable  {
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      assertNotNull(costSensitiveClassifier0);
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      
      CostMatrix costMatrix0 = costSensitiveClassifier0.getCostMatrix();
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      assertNotNull(costMatrix0);
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals(1, costMatrix0.size());
      assertEquals(1, costMatrix0.numRows());
      assertEquals(1, costMatrix0.numColumns());
      
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getStructure();
      assertNotNull(instances0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertNotNull(evaluation0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      
      File file0 = textDirectoryLoader0.getDirectory();
      assertNotNull(file0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("107_weka", file0.getName());
      assertEquals(0L, file0.length());
      assertTrue(file0.exists());
      assertEquals(1392409281320L, file0.lastModified());
      assertEquals("/home/ubuntu/evosuite_readability_gen/projects", file0.getParent());
      assertTrue(file0.canExecute());
      assertEquals(0L, file0.getTotalSpace());
      assertFalse(file0.isFile());
      assertTrue(file0.isAbsolute());
      assertTrue(file0.canRead());
      assertEquals(0L, file0.getFreeSpace());
      assertFalse(file0.isHidden());
      assertTrue(file0.canWrite());
      assertEquals("/home/ubuntu/evosuite_readability_gen/projects/107_weka", file0.toString());
      assertTrue(file0.isDirectory());
      assertEquals(0L, file0.getUsableSpace());
      
      AllFilter allFilter0 = new AllFilter();
      assertNotNull(allFilter0);
      assertTrue(allFilter0.isNewBatch());
      assertFalse(allFilter0.mayRemoveInstanceAfterFirstBatchDone());
      assertEquals("An instance filter that passes all instances through unmodified. Primarily for testing purposes.", allFilter0.globalInfo());
      assertFalse(allFilter0.isFirstBatchDone());
      assertFalse(allFilter0.isOutputFormatDefined());
      
      DenseInstance denseInstance0 = new DenseInstance(2);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(denseInstance0);
      assertEquals(2, denseInstance0.numAttributes());
      assertEquals(2, denseInstance0.numValues());
      assertEquals(1.0, denseInstance0.weight(), 0.01);
      
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/evosuite_readability_gen/projects/107_weka");
      byte[] byteArray0 = new byte[9];
      instances0.setClassIndex(1);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      
      byteArray0[0] = (byte) (-104);
      byteArray0[1] = (byte) (-101);
      byteArray0[3] = (byte) (-32);
      byteArray0[4] = (byte)2;
      byteArray0[5] = (byte)124;
      byteArray0[6] = (byte)8;
      byteArray0[7] = (byte)29;
      byteArray0[8] = (byte) (-118);
      boolean boolean0 = FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      assertFalse(boolean0);
      assertEquals(9, byteArray0.length);
      assertArrayEquals(new byte[] {(byte) (-104), (byte) (-101), (byte)0, (byte) (-32), (byte)2, (byte)124, (byte)8, (byte)29, (byte) (-118)}, byteArray0);
      
      Instances instances1 = ConverterUtils.DataSource.read((Loader) textDirectoryLoader0);
      assertNotNull(instances1);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0.0, instances1.sumOfWeights(), 0.01);
      assertEquals(0, instances1.size());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances1.relationName());
      assertEquals(0, instances1.numInstances());
      assertEquals(2, instances1.numAttributes());
      assertTrue(instances1.checkForStringAttributes());
      assertEquals(1, instances1.classIndex());
      assertEquals(0, instances1.numClasses());
      assertTrue(instances1.equals((Object)instances0));
      assertNotSame(instances1, instances0);
      
      denseInstance0.setDataset(instances1);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0.0, instances1.sumOfWeights(), 0.01);
      assertEquals(0, instances1.size());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances1.relationName());
      assertEquals(0, instances1.numInstances());
      assertEquals(2, instances1.numAttributes());
      assertTrue(instances1.checkForStringAttributes());
      assertEquals(1, instances1.classIndex());
      assertEquals(0, instances1.numClasses());
      assertEquals(1, denseInstance0.classIndex());
      assertEquals(0, denseInstance0.numClasses());
      assertEquals(2, denseInstance0.numAttributes());
      assertEquals(2, denseInstance0.numValues());
      assertEquals(1.0, denseInstance0.weight(), 0.01);
      assertTrue(instances1.equals((Object)instances0));
      assertNotSame(instances1, instances0);
      
      evaluation0.updatePriors(denseInstance0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(1, denseInstance0.classIndex());
      assertEquals(0, denseInstance0.numClasses());
      assertEquals(2, denseInstance0.numAttributes());
      assertEquals(2, denseInstance0.numValues());
      assertEquals(1.0, denseInstance0.weight(), 0.01);
      assertTrue(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      
      boolean boolean1 = FileSystemHandling.appendDataToFile(evoSuiteFile0, byteArray0);
      assertFalse(boolean1);
      assertTrue(boolean1 == boolean0);
      assertEquals(9, byteArray0.length);
      assertArrayEquals(new byte[] {(byte) (-104), (byte) (-101), (byte)0, (byte) (-32), (byte)2, (byte)124, (byte)8, (byte)29, (byte) (-118)}, byteArray0);
      
      ArffLoader arffLoader0 = new ArffLoader();
      assertNotNull(arffLoader0);
      assertEquals(".arff", arffLoader0.getFileExtension());
      assertEquals("Arff data files", arffLoader0.getFileDescription());
      assertEquals("Use relative rather than absolute paths", arffLoader0.useRelativePathTipText());
      assertFalse(arffLoader0.getUseRelativePath());
      assertEquals("Reads a source that is in arff (attribute relation file format) format. ", arffLoader0.globalInfo());
      assertEquals("http://", arffLoader0.retrieveURL());
      
      arffLoader0.setRetrieval(1237);
      assertEquals(".arff", arffLoader0.getFileExtension());
      assertEquals("Arff data files", arffLoader0.getFileDescription());
      assertEquals("Use relative rather than absolute paths", arffLoader0.useRelativePathTipText());
      assertFalse(arffLoader0.getUseRelativePath());
      assertEquals("Reads a source that is in arff (attribute relation file format) format. ", arffLoader0.globalInfo());
      assertEquals("http://", arffLoader0.retrieveURL());
      
      double double0 = evaluation0.evaluationForSingleInstance((Classifier) costSensitiveClassifier0, (Instance) denseInstance0, false);
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(1, denseInstance0.classIndex());
      assertEquals(0, denseInstance0.numClasses());
      assertEquals(2, denseInstance0.numAttributes());
      assertEquals(2, denseInstance0.numValues());
      assertEquals(1.0, denseInstance0.weight(), 0.01);
      assertTrue(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      
      evaluation0.updateStatsForPredictor((byte)2, denseInstance0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(1, denseInstance0.classIndex());
      assertEquals(0, denseInstance0.numClasses());
      assertEquals(2, denseInstance0.numAttributes());
      assertEquals(2, denseInstance0.numValues());
      assertEquals(1.0, denseInstance0.weight(), 0.01);
      assertTrue(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
      
      String string0 = evaluation0.toSummaryString(".arff", false);
      assertNotNull(string0);
      assertEquals(".arff\nTotal Number of Instances                0     \nIgnored Class Unknown Instances                  2     \n", string0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_ubuntu_evosuite_readability_gen_projects_107_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertTrue(instances0.equals((Object)instances1));
      assertNotSame(instances0, instances1);
  }

  /**
  //Test case number: 99
  /*Coverage entropy=1.2047933096947843
  */
  @Test(timeout = 4000)
  public void test099()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(testInstances0);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      
      testInstances0.setMultiInstance(false);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(instances0);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertNotNull(evaluation0);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      double[] doubleArray0 = new double[5];
      EvoSuiteFile evoSuiteFile0 = null;
      byte[] byteArray0 = null;
      boolean boolean0 = FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      assertFalse(boolean0);
      
      DenseInstance denseInstance0 = new DenseInstance((byte)8, doubleArray0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(denseInstance0);
      assertEquals(5, denseInstance0.numAttributes());
      assertEquals(8.0, denseInstance0.weight(), 0.01);
      assertEquals(5, denseInstance0.numValues());
      assertEquals(5, doubleArray0.length);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0, 0.0, 0.0}, doubleArray0, 0.01);
      
      boolean boolean1 = FileSystemHandling.createFolder((EvoSuiteFile) null);
      assertFalse(boolean1);
      assertTrue(boolean1 == boolean0);
      
      denseInstance0.setDataset(instances0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, denseInstance0.classIndex());
      assertEquals(5, denseInstance0.numAttributes());
      assertEquals(8.0, denseInstance0.weight(), 0.01);
      assertEquals(2, denseInstance0.numClasses());
      assertEquals(5, denseInstance0.numValues());
      assertEquals(5, doubleArray0.length);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0, 0.0, 0.0}, doubleArray0, 0.01);
      
      evaluation0.updatePriors(denseInstance0);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(1, denseInstance0.classIndex());
      assertEquals(5, denseInstance0.numAttributes());
      assertEquals(8.0, denseInstance0.weight(), 0.01);
      assertEquals(2, denseInstance0.numClasses());
      assertEquals(5, denseInstance0.numValues());
      assertEquals(5, doubleArray0.length);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0, 0.0, 0.0}, doubleArray0, 0.01);
      
      Attribute attribute0 = null;
      try {
        attribute0 = new Attribute("-U <username>", instances0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Header for relation-valued attribute should not contain any instances
         //
         verifyException("weka.core.Attribute", e);
      }
  }

  /**
  //Test case number: 100
  /*Coverage entropy=1.711547286286353
  */
  @Test(timeout = 4000)
  public void test100()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(testInstances0);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      
      boolean boolean0 = FileSystemHandling.setPermissions((EvoSuiteFile) null, true, true, true);
      assertFalse(boolean0);
      
      Instances instances0 = testInstances0.generate();
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(instances0);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertNotNull(evaluation0);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = (double) (-1);
      doubleArray0[1] = (-2556.873197555631);
      Evaluation.main(testInstances0.DEFAULT_WORDS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      
      doubleArray0[2] = (double) (-1);
      doubleArray0[5] = (double) (-2);
      doubleArray0[5] = (double) (-1);
      byte[] byteArray0 = new byte[1];
      byteArray0[0] = (byte) (-110);
      boolean boolean1 = FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      assertFalse(boolean1);
      assertTrue(boolean1 == boolean0);
      assertEquals(1, byteArray0.length);
      assertArrayEquals(new byte[] {(byte) (-110)}, byteArray0);
      
      DenseInstance denseInstance0 = new DenseInstance((-1.0), doubleArray0);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertNotNull(denseInstance0);
      assertEquals(7, denseInstance0.numValues());
      assertEquals(7, denseInstance0.numAttributes());
      assertEquals((-1.0), denseInstance0.weight(), 0.01);
      assertEquals(7, doubleArray0.length);
      assertArrayEquals(new double[] {(-1.0), (-2556.873197555631), (-1.0), 0.0, 0.0, (-1.0), 0.0}, doubleArray0, 0.01);
      
      denseInstance0.setDataset(instances0);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.size());
      assertEquals(7, denseInstance0.numValues());
      assertEquals(1, denseInstance0.classIndex());
      assertEquals(7, denseInstance0.numAttributes());
      assertEquals(2, denseInstance0.numClasses());
      assertEquals((-1.0), denseInstance0.weight(), 0.01);
      assertEquals(7, doubleArray0.length);
      assertArrayEquals(new double[] {(-1.0), (-2556.873197555631), (-1.0), 0.0, 0.0, (-1.0), 0.0}, doubleArray0, 0.01);
      
      boolean boolean2 = FileSystemHandling.appendDataToFile((EvoSuiteFile) null, byteArray0);
      assertFalse(boolean2);
      assertTrue(boolean2 == boolean1);
      assertTrue(boolean2 == boolean0);
      assertEquals(1, byteArray0.length);
      assertArrayEquals(new byte[] {(byte) (-110)}, byteArray0);
      
      ArffLoader arffLoader0 = new ArffLoader();
      assertNotNull(arffLoader0);
      assertEquals("http://", arffLoader0.retrieveURL());
      assertEquals("Arff data files", arffLoader0.getFileDescription());
      assertEquals("Use relative rather than absolute paths", arffLoader0.useRelativePathTipText());
      assertFalse(arffLoader0.getUseRelativePath());
      assertEquals("Reads a source that is in arff (attribute relation file format) format. ", arffLoader0.globalInfo());
      assertEquals(".arff", arffLoader0.getFileExtension());
      
      arffLoader0.setRetrieval((byte) (-110));
      assertEquals("http://", arffLoader0.retrieveURL());
      assertEquals("Arff data files", arffLoader0.getFileDescription());
      assertEquals("Use relative rather than absolute paths", arffLoader0.useRelativePathTipText());
      assertFalse(arffLoader0.getUseRelativePath());
      assertEquals("Reads a source that is in arff (attribute relation file format) format. ", arffLoader0.globalInfo());
      assertEquals(".arff", arffLoader0.getFileExtension());
      
      double double0 = evaluation0.m_SumPredicted;
      assertEquals(0.0, double0, 0.01);
      
      try { 
        evaluation0.updateStatsForPredictor(1584.834214, denseInstance0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 1584
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }
}
