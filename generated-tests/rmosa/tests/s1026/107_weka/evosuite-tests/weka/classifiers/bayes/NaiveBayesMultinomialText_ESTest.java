/*
 * This file was automatically generated by EvoSuite
 * Thu Aug 23 17:27:41 GMT 2018
 */

package weka.classifiers.bayes;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.io.File;
import java.util.LinkedHashMap;
import java.util.Map;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.Random;
import org.evosuite.runtime.System;
import org.evosuite.runtime.mock.java.io.MockFile;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.evosuite.runtime.util.SystemInUtil;
import org.junit.runner.RunWith;
import weka.attributeSelection.CfsSubsetEval;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.bayes.NaiveBayesMultinomial;
import weka.classifiers.bayes.NaiveBayesMultinomialText;
import weka.classifiers.functions.SGDText;
import weka.classifiers.functions.supportVector.PrecomputedKernelMatrixKernel;
import weka.classifiers.meta.MultiClassClassifierUpdateable;
import weka.classifiers.meta.Vote;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.DenseInstance;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.SparseInstance;
import weka.core.Stopwords;
import weka.core.TestInstances;
import weka.core.neighboursearch.BallTree;
import weka.core.neighboursearch.LinearNNSearch;
import weka.core.stemmers.SnowballStemmer;
import weka.core.stemmers.Stemmer;
import weka.core.tokenizers.WordTokenizer;
import weka.filters.supervised.attribute.Discretize;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class NaiveBayesMultinomialText_ESTest extends NaiveBayesMultinomialText_ESTest_scaffolding {

  /**
  //Test case number: 0
  /*Coverage entropy=0.6931471805599453
  */
  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      AbstractClassifier.runClassifier(naiveBayesMultinomialText0, (String[]) null);
      SparseInstance sparseInstance0 = null;
      try {
        sparseInstance0 = new SparseInstance((-2366));
        fail("Expecting exception: NegativeArraySizeException");
      
      } catch(NegativeArraySizeException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.SparseInstance", e);
      }
  }

  /**
  //Test case number: 1
  /*Coverage entropy=0.6931471805599453
  */
  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.getRevision();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals("9122", string0);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 2
  /*Coverage entropy=0.6931471805599453
  */
  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.useWordFrequenciesTipText();
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", string0);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 3
  /*Coverage entropy=0.6931471805599453
  */
  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.useStopListTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", string0);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 4
  /*Coverage entropy=0.6931471805599453
  */
  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.stopwordsTipText();
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", string0);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 5
  /*Coverage entropy=0.6931471805599453
  */
  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.lowercaseTokensTipText();
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", string0);
  }

  /**
  //Test case number: 6
  /*Coverage entropy=0.6931471805599453
  */
  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.minWordFrequencyTipText();
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", string0);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 7
  /*Coverage entropy=0.6931471805599453
  */
  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.globalInfo();
      assertEquals("Multinomial naive bayes for text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification", string0);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
  }

  /**
  //Test case number: 8
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[3];
      stringArray0[0] = "-M";
      stringArray0[1] = "o_j9R33|VS.K23";
      stringArray0[2] = "NaiveBayesMultinomialText: No model built yet.\n";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NumberFormatException");
      
      } catch(NumberFormatException e) {
      }
  }

  /**
  //Test case number: 9
  /*Coverage entropy=1.6094379124341005
  */
  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      TestInstances testInstances0 = new TestInstances();
      String[] stringArray0 = new String[3];
      stringArray0[0] = " ";
      stringArray0[1] = "-norm";
      stringArray0[2] = "-norm";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NumberFormatException");
      
      } catch(NumberFormatException e) {
      }
  }

  /**
  //Test case number: 10
  /*Coverage entropy=1.6094379124341005
  */
  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      FileSystemHandling.appendDataToFile((EvoSuiteFile) null, (byte[]) null);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[9];
      stringArray0[0] = "-lnorm";
      stringArray0[1] = "6>p?-r9.]";
      stringArray0[2] = "";
      stringArray0[3] = "weka.core.NormalizableDistance";
      stringArray0[4] = "Ny})Jq";
      stringArray0[5] = "@au:C{Q2lN";
      stringArray0[6] = "Option a: attribute index out of range.";
      stringArray0[7] = "cw";
      stringArray0[8] = "user.dir";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: NumberFormatException");
      
      } catch(NumberFormatException e) {
      }
  }

  /**
  //Test case number: 11
  /*Coverage entropy=1.715263227902811
  */
  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/evosuite_readability_gen/projects/107_weka");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "k+;L2_[H8iI4qB");
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-tokenizer";
      stringArray0[1] = "k+;L2_[H8iI4qB";
      stringArray0[2] = "k+;L2_[H8iI4qB";
      stringArray0[3] = "-tokenizer";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: ClassNotFoundException");
      
      } catch(ClassNotFoundException e) {
      }
  }

  /**
  //Test case number: 12
  /*Coverage entropy=1.858445013999836
  */
  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "weka/core/Capabilities.props";
      stringArray0[1] = "weka/core/Capabilities.props";
      stringArray0[2] = "weka/core/Capabilities.props";
      stringArray0[3] = "weka/core/Capabilities.props";
      stringArray0[4] = "weka/core/Capabilities.props";
      stringArray0[5] = "weka/core/Capabilities.props";
      stringArray0[6] = "weka/core/Capabilities.props";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      BallTree ballTree0 = new BallTree(instances0);
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = (double) (-1);
      doubleArray0[1] = (double) (-2);
      doubleArray0[2] = (double) (-2);
      doubleArray0[3] = (double) (-2);
      doubleArray0[4] = (double) (-1);
      doubleArray0[5] = (double) (-1);
      doubleArray0[6] = (double) (-1);
      DenseInstance denseInstance0 = new DenseInstance((-1), doubleArray0);
      try { 
        ballTree0.nearestNeighbour(denseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.neighboursearch.BallTree", e);
      }
  }

  /**
  //Test case number: 13
  /*Coverage entropy=0.6931471805599453
  */
  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.tokenizerTipText();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", string0);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 14
  /*Coverage entropy=0.6931471805599453
  */
  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.stemmerTipText();
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", string0);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 15
  /*Coverage entropy=0.6931471805599453
  */
  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.normTipText();
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", string0);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
  }

  /**
  //Test case number: 16
  /*Coverage entropy=0.6931471805599453
  */
  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.normalizeDocLengthTipText();
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", string0);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 17
  /*Coverage entropy=0.6931471805599453
  */
  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.LNormTipText();
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", string0);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 18
  /*Coverage entropy=1.0986122886681096
  */
  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Vote vote0 = new Vote();
      double double0 = naiveBayesMultinomialText0.getLNorm();
      assertEquals(2.0, double0, 0.01);
      
      String string0 = naiveBayesMultinomialText0.toString();
      assertEquals("NaiveBayesMultinomialText: No model built yet.\n", string0);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 19
  /*Coverage entropy=0.6931471805599453
  */
  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String string0 = naiveBayesMultinomialText0.periodicPruningTipText();
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", string0);
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
  }

  /**
  //Test case number: 20
  /*Coverage entropy=1.3862943611198906
  */
  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      String[] stringArray0 = new String[17];
      stringArray0[2] = stringArray0[1];
      NaiveBayesMultinomialText.main(stringArray0);
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      LinkedHashMap<Integer, LinkedHashMap<String, NaiveBayesMultinomialText.Count>> linkedHashMap0 = new LinkedHashMap<Integer, LinkedHashMap<String, NaiveBayesMultinomialText.Count>>(21, 21);
      naiveBayesMultinomialText0.m_probOfWordGivenClass = (Map<Integer, LinkedHashMap<String, NaiveBayesMultinomialText.Count>>) linkedHashMap0;
      naiveBayesMultinomialText0.reset();
      naiveBayesMultinomialText0.getPeriodicPruning();
      System.setCurrentTimeMillis(0L);
  }

  /**
  //Test case number: 21
  /*Coverage entropy=2.4122102014318156
  */
  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_wordFrequencies = true;
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.getOptions();
      assertTrue(naiveBayesMultinomialText0.getLowercaseTokens());
      assertTrue(naiveBayesMultinomialText0.getUseStopList());
      
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = (-10.0);
      doubleArray0[1] = (-10.0);
      doubleArray0[2] = (-10.0);
      doubleArray0[3] = (-10.0);
      DenseInstance denseInstance0 = new DenseInstance((-10.0), doubleArray0);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(denseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 22
  /*Coverage entropy=2.1895631155000843
  */
  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances.forCapabilities(capabilities0);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      TestInstances testInstances0 = new TestInstances();
      Capabilities capabilities1 = naiveBayesMultinomialText0.getCapabilities();
      capabilities1.disableAllClasses();
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities1);
      Instances instances0 = testInstances1.generate("");
      testInstances1.setNumRelationalDate((-1));
      SystemInUtil.addInputLine(".arff");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      LinearNNSearch linearNNSearch0 = new LinearNNSearch(instances0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      Instance instance0 = linearNNSearch0.nearestNeighbour(binarySparseInstance0);
      naiveBayesMultinomialText0.distributionForInstance(instance0);
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.toString();
      assertTrue(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 23
  /*Coverage entropy=2.2523542313691998
  */
  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("-Fh&^R92Y");
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) snowballStemmer0;
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.getOptions();
      System.setCurrentTimeMillis((-777L));
  }

  /**
  //Test case number: 24
  /*Coverage entropy=2.6462159223459745
  */
  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      BallTree ballTree0 = new BallTree(instances0);
      double[] doubleArray0 = new double[7];
      Stopwords stopwords0 = naiveBayesMultinomialText0.m_stopwords;
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      String string0 = "Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value";
      // Undeclared exception!
      try { 
        instances0.add((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  /**
  //Test case number: 25
  /*Coverage entropy=2.1972245773362196
  */
  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "";
      stringArray0[1] = "";
      stringArray0[2] = "";
      stringArray0[3] = "Invalid attribute evaluator specification string";
      stringArray0[4] = "aYa#ak22";
      stringArray0[5] = "-stemmer";
      stringArray0[6] = "e DguAjm.k#U3KB_U`~";
      try { 
        naiveBayesMultinomialText0.setOptions(stringArray0);
        fail("Expecting exception: ClassNotFoundException");
      
      } catch(ClassNotFoundException e) {
      }
  }

  /**
  //Test case number: 26
  /*Coverage entropy=2.3025850929940455
  */
  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      NaiveBayesMultinomial naiveBayesMultinomial0 = new NaiveBayesMultinomial();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "-stopwords";
      stringArray0[1] = "-stopwords";
      stringArray0[2] = "INBOOK";
      stringArray0[3] = "-stopwords";
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertFalse(naiveBayesMultinomialText0.getUseStopList());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
  }

  /**
  //Test case number: 27
  /*Coverage entropy=1.5082255166247032
  */
  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      TestInstances testInstances0 = new TestInstances();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances1.generate("X@\"Nv>kg!ijw$c[");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      LinearNNSearch linearNNSearch0 = new LinearNNSearch(instances0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      Instance instance0 = linearNNSearch0.nearestNeighbour(binarySparseInstance0);
      DenseInstance.main(testInstances0.DEFAULT_WORDS);
      naiveBayesMultinomialText0.distributionForInstance(instance0);
      naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
      naiveBayesMultinomialText0.toString();
      assertTrue(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 28
  /*Coverage entropy=1.7826121223721445
  */
  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      TestInstances testInstances0 = new TestInstances();
      testInstances0.listOptions();
      String[] stringArray0 = new String[3];
      stringArray0[0] = " ";
      stringArray0[1] = "-norm";
      stringArray0[2] = "-norm";
      testInstances0.setOptions(stringArray0);
      testInstances0.setNumRelationalNumeric((-1));
      naiveBayesMultinomialText0.getCapabilities();
      Instances instances0 = testInstances0.generate("-norm");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(2.0, (int[]) null, (-1));
      naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
      assertTrue(naiveBayesMultinomialText0.getNormalizeDocLength());
  }

  /**
  //Test case number: 29
  /*Coverage entropy=1.452745491812182
  */
  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      naiveBayesMultinomialText0.buildClassifier(instances0);
      BallTree ballTree0 = new BallTree(instances0);
      LinearNNSearch linearNNSearch0 = new LinearNNSearch(instances0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1);
      DenseInstance denseInstance0 = (DenseInstance)linearNNSearch0.nearestNeighbour(binarySparseInstance0);
      double[] doubleArray0 = naiveBayesMultinomialText0.distributionForInstance(denseInstance0);
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("/home/ubuntu/wekafiles/props");
      FileSystemHandling.appendStringToFile(evoSuiteFile0, "weka/core/Capabilities.props");
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      denseInstance0.toString();
      DenseInstance denseInstance1 = new DenseInstance(1, doubleArray0);
      try { 
        ballTree0.nearestNeighbour(denseInstance1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.neighboursearch.BallTree", e);
      }
  }

  /**
  //Test case number: 30
  /*Coverage entropy=1.0986122886681096
  */
  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_t = 2965.0;
      WordTokenizer wordTokenizer0 = new WordTokenizer();
      naiveBayesMultinomialText0.setPeriodicPruning(31);
      naiveBayesMultinomialText0.pruneDictionary();
      System.setCurrentTimeMillis(31);
      System.setCurrentTimeMillis(31);
  }

  /**
  //Test case number: 31
  /*Coverage entropy=2.777590996431983
  */
  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_leplace = (-600.77768447049);
      SnowballStemmer snowballStemmer0 = new SnowballStemmer("zhO[lp)");
      naiveBayesMultinomialText0.m_stemmer = (Stemmer) snowballStemmer0;
      Stopwords stopwords0 = new Stopwords();
      naiveBayesMultinomialText0.m_stopwords = stopwords0;
      String[] stringArray0 = naiveBayesMultinomialText0.getOptions();
      naiveBayesMultinomialText0.setOptions(stringArray0);
      assertEquals(2.0, naiveBayesMultinomialText0.getLNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getNormalizeDocLength());
      assertFalse(naiveBayesMultinomialText0.getLowercaseTokens());
      assertEquals(0, naiveBayesMultinomialText0.getPeriodicPruning());
      assertEquals(1.0, naiveBayesMultinomialText0.getNorm(), 0.01);
      assertFalse(naiveBayesMultinomialText0.getUseWordFrequencies());
      assertEquals(3.0, naiveBayesMultinomialText0.getMinWordFrequency(), 0.01);
      assertEquals(12, stringArray0.length);
  }

  /**
  //Test case number: 32
  /*Coverage entropy=2.0794415416798357
  */
  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      TestInstances testInstances0 = new TestInstances();
      FileSystemHandling.appendStringToFile((EvoSuiteFile) null, "lB6nO tV<EG*a?");
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      String[] stringArray0 = new String[8];
      stringArray0[0] = "lB6nO tV<EG*a?";
      stringArray0[1] = "-tokenizer";
      stringArray0[2] = " ";
      stringArray0[3] = "d}'{A@U26!R9fhvc";
      stringArray0[4] = "d}'{A@U26!R9fhvc";
      stringArray0[5] = "lB6nO tV<EG*a?";
      stringArray0[6] = "";
      stringArray0[7] = "-tokenizer";
      try { 
        naiveBayesMultinomialText1.setOptions(stringArray0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Invalid tokenizer specification string
         //
         verifyException("weka.classifiers.bayes.NaiveBayesMultinomialText", e);
      }
  }

  /**
  //Test case number: 33
  /*Coverage entropy=1.4871594946497422
  */
  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setPeriodicPruning(1);
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      testInstances0.setNumRelationalString(2);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      naiveBayesMultinomialText0.buildClassifier(instances0);
  }

  /**
  //Test case number: 34
  /*Coverage entropy=1.0986122886681096
  */
  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[8];
      intArray0[1] = 40;
      intArray0[3] = 0;
      SGDText sGDText0 = new SGDText();
      File file0 = sGDText0.getStopwords();
      File file1 = MockFile.createTempFile("]BtMmF/k)M$H9cgZhP=", "]BtMmF/k)M$H9cgZhP=", file0);
      naiveBayesMultinomialText0.m_stopwordsFile = file1;
      naiveBayesMultinomialText0.m_useStopList = true;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(2909.0, intArray0, 0);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 35
  /*Coverage entropy=2.3025850929940455
  */
  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[8];
      intArray0[1] = 40;
      intArray0[2] = 40;
      intArray0[3] = 0;
      naiveBayesMultinomialText0.m_useStopList = true;
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("0s{\"2sQ,8Sd6(V>n_");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      CfsSubsetEval cfsSubsetEval0 = new CfsSubsetEval();
      try { 
        cfsSubsetEval0.buildEvaluator(instances0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // weka.attributeSelection.CfsSubsetEval: Cannot handle string attributes!
         //
         verifyException("weka.core.Capabilities", e);
      }
  }

  /**
  //Test case number: 36
  /*Coverage entropy=3.401197381662154
  */
  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setPeriodicPruning(1);
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.m_leplace = 20.0;
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("AO_dW;=5$e'*/.O");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      CfsSubsetEval cfsSubsetEval0 = new CfsSubsetEval();
      NaiveBayesMultinomialText naiveBayesMultinomialText1 = new NaiveBayesMultinomialText();
      Stopwords stopwords0 = naiveBayesMultinomialText1.m_stopwords;
      NaiveBayesMultinomialText naiveBayesMultinomialText2 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText2.getOptions();
      naiveBayesMultinomialText1.setOptions(testInstances0.DEFAULT_WORDS);
      File file0 = MockFile.createTempFile(".arff", (String) null);
      naiveBayesMultinomialText1.setStopwords(file0);
      double[] doubleArray0 = new double[6];
      naiveBayesMultinomialText1.setStopwords(file0);
      doubleArray0[0] = (double) 1;
      doubleArray0[1] = (double) (-1);
      doubleArray0[2] = (-1576.8182704789);
      doubleArray0[3] = (double) (-1);
      doubleArray0[4] = 17.0;
      doubleArray0[5] = (-1852.74071740721);
  }

  /**
  //Test case number: 37
  /*Coverage entropy=2.1972245773362196
  */
  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      CfsSubsetEval cfsSubsetEval0 = new CfsSubsetEval();
      Capabilities capabilities0 = cfsSubsetEval0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      testInstances0.listOptions();
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances1.generate("-norm");
      SparseInstance sparseInstance0 = new SparseInstance(61);
      instances0.add((Instance) sparseInstance0);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      int[] intArray0 = new int[5];
      cfsSubsetEval0.setMissingSeparate(true);
      intArray0[0] = (-1);
      intArray0[1] = (-1);
      naiveBayesMultinomialText0.toString();
      intArray0[4] = (-1);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(sparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 38
  /*Coverage entropy=2.3978952727983707
  */
  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      TestInstances testInstances0 = new TestInstances();
      CfsSubsetEval cfsSubsetEval0 = new CfsSubsetEval();
      Capabilities capabilities0 = cfsSubsetEval0.getCapabilities();
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      naiveBayesMultinomialText0.m_inputVector = null;
      testInstances1.listOptions();
      testInstances0.setOptions(testInstances1.DEFAULT_WORDS);
      testInstances0.setNumRelationalNumeric((-1));
      Capabilities capabilities1 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances2 = TestInstances.forCapabilities(capabilities1);
      naiveBayesMultinomialText0.m_wordFrequencies = true;
      Instances instances0 = testInstances2.generate("-norm");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      int[] intArray0 = new int[5];
      capabilities1.dependencies();
      cfsSubsetEval0.setMissingSeparate(true);
      intArray0[0] = (-1);
      intArray0[1] = (-1);
      naiveBayesMultinomialText0.debugTipText();
      intArray0[2] = (-2);
      intArray0[3] = (-2);
      testInstances2.setClassType(107);
      intArray0[4] = (-1);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-2), intArray0, (-2));
      naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
      // Undeclared exception!
      try { 
        naiveBayesMultinomialText0.tokenizeInstance(binarySparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 39
  /*Coverage entropy=2.3025850929940455
  */
  @Test(timeout = 4000)
  public void test39()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      naiveBayesMultinomialText0.setUseWordFrequencies(true);
      naiveBayesMultinomialText0.buildClassifier(instances0);
      BallTree ballTree0 = new BallTree(instances0);
      double[] doubleArray0 = new double[7];
      doubleArray0[0] = (double) (-1);
      doubleArray0[1] = (double) (-2);
      doubleArray0[2] = (double) (-2);
      doubleArray0[3] = (double) (-2);
      doubleArray0[4] = (double) (-1);
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("Capabilities.props");
      FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      doubleArray0[5] = (double) (-1);
      doubleArray0[6] = (double) (-1);
  }

  /**
  //Test case number: 40
  /*Coverage entropy=2.3978952727983707
  */
  @Test(timeout = 4000)
  public void test40()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_lowercaseTokens = true;
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      TestInstances testInstances0 = new TestInstances();
      CfsSubsetEval cfsSubsetEval0 = new CfsSubsetEval();
      testInstances0.setNumRelationalNumeric(19);
      Capabilities capabilities0 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances1.generate(" ");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      int[] intArray0 = new int[5];
      cfsSubsetEval0.setMissingSeparate(true);
      intArray0[1] = (-1);
      naiveBayesMultinomialText0.toString();
      intArray0[2] = (-2);
      intArray0[3] = (-2);
      Discretize discretize0 = new Discretize();
      // Undeclared exception!
      try { 
        discretize0.getOutputFormat();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // No output format defined.
         //
         verifyException("weka.filters.Filter", e);
      }
  }

  /**
  //Test case number: 41
  /*Coverage entropy=2.6390573296152584
  */
  @Test(timeout = 4000)
  public void test41()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.m_stemmer = null;
      naiveBayesMultinomialText0.getCapabilities();
      naiveBayesMultinomialText0.getOptions();
  }

  /**
  //Test case number: 42
  /*Coverage entropy=2.4849066497880012
  */
  @Test(timeout = 4000)
  public void test42()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      int[] intArray0 = new int[8];
      intArray0[1] = 40;
      intArray0[2] = 0;
      intArray0[3] = 0;
      boolean boolean0 = true;
      naiveBayesMultinomialText0.m_useStopList = true;
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      File file0 = precomputedKernelMatrixKernel0.getKernelMatrixFile();
      naiveBayesMultinomialText0.setStopwords(file0);
      naiveBayesMultinomialText0.getCapabilities();
      MultiClassClassifierUpdateable multiClassClassifierUpdateable0 = new MultiClassClassifierUpdateable();
      Capabilities capabilities0 = multiClassClassifierUpdateable0.getCapabilities();
      TestInstances.forCapabilities(capabilities0);
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      CfsSubsetEval cfsSubsetEval0 = new CfsSubsetEval();
      cfsSubsetEval0.setMissingSeparate(true);
      naiveBayesMultinomialText0.toString();
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-1945.02846), intArray0, 18);
      try { 
        naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  /**
  //Test case number: 43
  /*Coverage entropy=2.3978952727983707
  */
  @Test(timeout = 4000)
  public void test43()  throws Throwable  {
      NaiveBayesMultinomialText naiveBayesMultinomialText0 = new NaiveBayesMultinomialText();
      naiveBayesMultinomialText0.setNormalizeDocLength(true);
      TestInstances testInstances0 = new TestInstances();
      naiveBayesMultinomialText0.m_periodicP = 16;
      CfsSubsetEval cfsSubsetEval0 = new CfsSubsetEval();
      Capabilities capabilities0 = cfsSubsetEval0.getCapabilities();
      TestInstances testInstances1 = TestInstances.forCapabilities(capabilities0);
      testInstances1.listOptions();
      testInstances0.setOptions(testInstances1.DEFAULT_WORDS);
      testInstances0.setNumRelationalNumeric(19);
      Capabilities capabilities1 = naiveBayesMultinomialText0.getCapabilities();
      TestInstances testInstances2 = TestInstances.forCapabilities(capabilities1);
      Instances instances0 = testInstances2.generate("-norm");
      SystemInUtil.addInputLine("weka/core/Capabilities.props");
      naiveBayesMultinomialText0.buildClassifier(instances0);
      LinearNNSearch linearNNSearch0 = new LinearNNSearch(instances0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      Instance instance0 = linearNNSearch0.nearestNeighbour(binarySparseInstance0);
      naiveBayesMultinomialText0.distributionForInstance(instance0);
      naiveBayesMultinomialText0.distributionForInstance(binarySparseInstance0);
  }
}
